{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score, f1_score, precision_score\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble, preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from my_functions import *\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('Data/bci/TrainLabels.csv')\n",
    "submission = pd.read_csv('Data/bci/SampleSubmission.csv')\n",
    "true_labels = pd.read_csv('Data/bci/true_labels.csv')\n",
    "X_train = np.load('Data/bci/X_train_final.npy')\n",
    "X_test = np.load('Data/bci/X_test_final.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_labels.Prediction.values\n",
    "Y_test = true_labels['1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5440,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3399,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8839,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate((Y_train,Y_test))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5440, 210)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400, 210)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train,X_test))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    clf = ensemble.RandomForestClassifier(n_jobs = -1, n_estimators=200, \n",
    "                                          random_state=42)\n",
    "    clf.fit(x_train1, y_train1)\n",
    "    probs = clf.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.6651,y_test1, probs)\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)\n",
    "\n",
    "def MLPfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    start = time.time()\n",
    "    mlp = MLPClassifiermlp = MLPClassifier(solver='adam', activation='relu', alpha=0.0001, \n",
    "                                           hidden_layer_sizes = (64, 1), max_iter = 10000)\n",
    "    mlp.fit(x_train1, y_train1)\n",
    "    probs = mlp.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.77, y_test1, probs)\n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)\n",
    "\n",
    "def SVMfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    start = time.time()\n",
    "    svc = SVC(kernel = 'rbf', C = 5, degree = 10, gamma = 0.04, \n",
    "              max_iter =  100000, probability = True, n_jobs = -1)\n",
    "    svc.fit(x_train1, y_train1)\n",
    "    probs = svc.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.7521,y_test1, probs)\n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)\n",
    "\n",
    "def LSVMfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    start=time.time()\n",
    "    svc = LinearSVC(C = 5, loss = 'hinge', max_iter=10000)\n",
    "    svc = CalibratedClassifierCV(svc)\n",
    "    svc.fit(x_train1,y_train1)\n",
    "    probs = svc.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.7521,y_test1, probs)\n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0\n",
      "f1_score:\n",
      "0.6524113234714373\n",
      "precision_score:\n",
      "0.6636478638376171\n",
      "accuracy_score:\n",
      "0.6700367647058824\n",
      "Confusion Matrix:\n",
      "[[242  74]\n",
      " [285 487]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.77      0.57       316\n",
      "           1       0.87      0.63      0.73       772\n",
      "\n",
      "    accuracy                           0.67      1088\n",
      "   macro avg       0.66      0.70      0.65      1088\n",
      "weighted avg       0.75      0.67      0.69      1088\n",
      "\n",
      "f1_score:\n",
      "0.6520957566329617\n",
      "precision_score:\n",
      "0.6633568696675493\n",
      "accuracy_score:\n",
      "0.7279411764705882\n",
      "Confusion Matrix:\n",
      "[[142 174]\n",
      " [122 650]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.45      0.49       316\n",
      "           1       0.79      0.84      0.81       772\n",
      "\n",
      "    accuracy                           0.73      1088\n",
      "   macro avg       0.66      0.65      0.65      1088\n",
      "weighted avg       0.72      0.73      0.72      1088\n",
      "\n",
      "Elapsed Time: 12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.680922483259562\n",
      "precision_score:\n",
      "0.6825443230582483\n",
      "accuracy_score:\n",
      "0.703125\n",
      "Confusion Matrix:\n",
      "[[239  77]\n",
      " [246 526]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.76      0.60       316\n",
      "           1       0.87      0.68      0.77       772\n",
      "\n",
      "    accuracy                           0.70      1088\n",
      "   macro avg       0.68      0.72      0.68      1088\n",
      "weighted avg       0.76      0.70      0.72      1088\n",
      "\n",
      "Elapsed Time: 12 seconds\n",
      "0.2 1\n",
      "f1_score:\n",
      "0.6118167546738975\n",
      "precision_score:\n",
      "0.6372658159109422\n",
      "accuracy_score:\n",
      "0.6231617647058824\n",
      "Confusion Matrix:\n",
      "[[246  76]\n",
      " [334 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.76      0.55       322\n",
      "           1       0.85      0.56      0.68       766\n",
      "\n",
      "    accuracy                           0.62      1088\n",
      "   macro avg       0.64      0.66      0.61      1088\n",
      "weighted avg       0.72      0.62      0.64      1088\n",
      "\n",
      "f1_score:\n",
      "0.6478014022570793\n",
      "precision_score:\n",
      "0.6458221619405103\n",
      "accuracy_score:\n",
      "0.6792279411764706\n",
      "Confusion Matrix:\n",
      "[[207 115]\n",
      " [234 532]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.64      0.54       322\n",
      "           1       0.82      0.69      0.75       766\n",
      "\n",
      "    accuracy                           0.68      1088\n",
      "   macro avg       0.65      0.67      0.65      1088\n",
      "weighted avg       0.72      0.68      0.69      1088\n",
      "\n",
      "Elapsed Time: 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6221373650107991\n",
      "precision_score:\n",
      "0.6549039461441628\n",
      "accuracy_score:\n",
      "0.6305147058823529\n",
      "Confusion Matrix:\n",
      "[[262  60]\n",
      " [342 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.81      0.57       322\n",
      "           1       0.88      0.55      0.68       766\n",
      "\n",
      "    accuracy                           0.63      1088\n",
      "   macro avg       0.65      0.68      0.62      1088\n",
      "weighted avg       0.75      0.63      0.65      1088\n",
      "\n",
      "Elapsed Time: 14 seconds\n",
      "0.2 2\n",
      "f1_score:\n",
      "0.6854283017530507\n",
      "precision_score:\n",
      "0.6804671516253694\n",
      "accuracy_score:\n",
      "0.7150735294117647\n",
      "Confusion Matrix:\n",
      "[[222 108]\n",
      " [202 556]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.67      0.59       330\n",
      "           1       0.84      0.73      0.78       758\n",
      "\n",
      "    accuracy                           0.72      1088\n",
      "   macro avg       0.68      0.70      0.69      1088\n",
      "weighted avg       0.74      0.72      0.72      1088\n",
      "\n",
      "f1_score:\n",
      "0.6485531990321969\n",
      "precision_score:\n",
      "0.651701370040729\n",
      "accuracy_score:\n",
      "0.6700367647058824\n",
      "Confusion Matrix:\n",
      "[[230 100]\n",
      " [259 499]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.56       330\n",
      "           1       0.83      0.66      0.74       758\n",
      "\n",
      "    accuracy                           0.67      1088\n",
      "   macro avg       0.65      0.68      0.65      1088\n",
      "weighted avg       0.72      0.67      0.68      1088\n",
      "\n",
      "Elapsed Time: 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6916073461672274\n",
      "precision_score:\n",
      "0.685969277329754\n",
      "accuracy_score:\n",
      "0.7251838235294118\n",
      "Confusion Matrix:\n",
      "[[215 115]\n",
      " [184 574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.65      0.59       330\n",
      "           1       0.83      0.76      0.79       758\n",
      "\n",
      "    accuracy                           0.73      1088\n",
      "   macro avg       0.69      0.70      0.69      1088\n",
      "weighted avg       0.74      0.73      0.73      1088\n",
      "\n",
      "Elapsed Time: 19 seconds\n",
      "0.5 0\n",
      "f1_score:\n",
      "0.6543527243726239\n",
      "precision_score:\n",
      "0.6501316641484999\n",
      "accuracy_score:\n",
      "0.6922794117647059\n",
      "Confusion Matrix:\n",
      "[[ 491  303]\n",
      " [ 534 1392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.62      0.54       794\n",
      "           1       0.82      0.72      0.77      1926\n",
      "\n",
      "    accuracy                           0.69      2720\n",
      "   macro avg       0.65      0.67      0.65      2720\n",
      "weighted avg       0.72      0.69      0.70      2720\n",
      "\n",
      "f1_score:\n",
      "0.6281061356670099\n",
      "precision_score:\n",
      "0.647732467708122\n",
      "accuracy_score:\n",
      "0.6422794117647059\n",
      "Confusion Matrix:\n",
      "[[ 608  186]\n",
      " [ 787 1139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.77      0.56       794\n",
      "           1       0.86      0.59      0.70      1926\n",
      "\n",
      "    accuracy                           0.64      2720\n",
      "   macro avg       0.65      0.68      0.63      2720\n",
      "weighted avg       0.74      0.64      0.66      2720\n",
      "\n",
      "Elapsed Time: 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6428408049297456\n",
      "precision_score:\n",
      "0.658701632367062\n",
      "accuracy_score:\n",
      "0.6580882352941176\n",
      "Confusion Matrix:\n",
      "[[ 614  180]\n",
      " [ 750 1176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.77      0.57       794\n",
      "           1       0.87      0.61      0.72      1926\n",
      "\n",
      "    accuracy                           0.66      2720\n",
      "   macro avg       0.66      0.69      0.64      2720\n",
      "weighted avg       0.75      0.66      0.67      2720\n",
      "\n",
      "Elapsed Time: 8 seconds\n",
      "0.5 1\n",
      "f1_score:\n",
      "0.6451176552083441\n",
      "precision_score:\n",
      "0.6434033182541024\n",
      "accuracy_score:\n",
      "0.6790441176470589\n",
      "Confusion Matrix:\n",
      "[[ 503  277]\n",
      " [ 596 1344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.64      0.54       780\n",
      "           1       0.83      0.69      0.75      1940\n",
      "\n",
      "    accuracy                           0.68      2720\n",
      "   macro avg       0.64      0.67      0.65      2720\n",
      "weighted avg       0.72      0.68      0.69      2720\n",
      "\n",
      "f1_score:\n",
      "0.664626270983206\n",
      "precision_score:\n",
      "0.6592888676768882\n",
      "accuracy_score:\n",
      "0.7058823529411765\n",
      "Confusion Matrix:\n",
      "[[ 483  297]\n",
      " [ 503 1437]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.62      0.55       780\n",
      "           1       0.83      0.74      0.78      1940\n",
      "\n",
      "    accuracy                           0.71      2720\n",
      "   macro avg       0.66      0.68      0.66      2720\n",
      "weighted avg       0.73      0.71      0.71      2720\n",
      "\n",
      "Elapsed Time: 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6690615918676572\n",
      "precision_score:\n",
      "0.6648100080847623\n",
      "accuracy_score:\n",
      "0.7033088235294118\n",
      "Confusion Matrix:\n",
      "[[ 519  261]\n",
      " [ 546 1394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.67      0.56       780\n",
      "           1       0.84      0.72      0.78      1940\n",
      "\n",
      "    accuracy                           0.70      2720\n",
      "   macro avg       0.66      0.69      0.67      2720\n",
      "weighted avg       0.74      0.70      0.71      2720\n",
      "\n",
      "Elapsed Time: 8 seconds\n",
      "0.5 2\n",
      "f1_score:\n",
      "0.6345748736850918\n",
      "precision_score:\n",
      "0.6524788872974496\n",
      "accuracy_score:\n",
      "0.6507352941176471\n",
      "Confusion Matrix:\n",
      "[[ 599  178]\n",
      " [ 772 1171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.77      0.56       777\n",
      "           1       0.87      0.60      0.71      1943\n",
      "\n",
      "    accuracy                           0.65      2720\n",
      "   macro avg       0.65      0.69      0.63      2720\n",
      "weighted avg       0.74      0.65      0.67      2720\n",
      "\n",
      "f1_score:\n",
      "0.6130260679937312\n",
      "precision_score:\n",
      "0.6358399934170601\n",
      "accuracy_score:\n",
      "0.6279411764705882\n",
      "Confusion Matrix:\n",
      "[[ 587  190]\n",
      " [ 822 1121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.76      0.54       777\n",
      "           1       0.86      0.58      0.69      1943\n",
      "\n",
      "    accuracy                           0.63      2720\n",
      "   macro avg       0.64      0.67      0.61      2720\n",
      "weighted avg       0.73      0.63      0.65      2720\n",
      "\n",
      "Elapsed Time: 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6621038352447898\n",
      "precision_score:\n",
      "0.6581004309837584\n",
      "accuracy_score:\n",
      "0.6977941176470588\n",
      "Confusion Matrix:\n",
      "[[ 507  270]\n",
      " [ 552 1391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.65      0.55       777\n",
      "           1       0.84      0.72      0.77      1943\n",
      "\n",
      "    accuracy                           0.70      2720\n",
      "   macro avg       0.66      0.68      0.66      2720\n",
      "weighted avg       0.73      0.70      0.71      2720\n",
      "\n",
      "Elapsed Time: 8 seconds\n",
      "0.8 0\n",
      "f1_score:\n",
      "0.6097635867317396\n",
      "precision_score:\n",
      "0.6269524006639999\n",
      "accuracy_score:\n",
      "0.6263786764705882\n",
      "Confusion Matrix:\n",
      "[[ 914  358]\n",
      " [1268 1812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.72      0.53      1272\n",
      "           1       0.84      0.59      0.69      3080\n",
      "\n",
      "    accuracy                           0.63      4352\n",
      "   macro avg       0.63      0.65      0.61      4352\n",
      "weighted avg       0.71      0.63      0.64      4352\n",
      "\n",
      "f1_score:\n",
      "0.6350686032306103\n",
      "precision_score:\n",
      "0.6324365611568583\n",
      "accuracy_score:\n",
      "0.6725643382352942\n",
      "Confusion Matrix:\n",
      "[[ 766  506]\n",
      " [ 919 2161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.60      0.52      1272\n",
      "           1       0.81      0.70      0.75      3080\n",
      "\n",
      "    accuracy                           0.67      4352\n",
      "   macro avg       0.63      0.65      0.64      4352\n",
      "weighted avg       0.71      0.67      0.68      4352\n",
      "\n",
      "Elapsed Time: 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6279687963632341\n",
      "precision_score:\n",
      "0.6270201097694359\n",
      "accuracy_score:\n",
      "0.6624540441176471\n",
      "Confusion Matrix:\n",
      "[[ 779  493]\n",
      " [ 976 2104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.61      0.51      1272\n",
      "           1       0.81      0.68      0.74      3080\n",
      "\n",
      "    accuracy                           0.66      4352\n",
      "   macro avg       0.63      0.65      0.63      4352\n",
      "weighted avg       0.70      0.66      0.68      4352\n",
      "\n",
      "Elapsed Time: 4 seconds\n",
      "0.8 1\n",
      "f1_score:\n",
      "0.6332878662356126\n",
      "precision_score:\n",
      "0.6316591999053544\n",
      "accuracy_score:\n",
      "0.6668198529411765\n",
      "Confusion Matrix:\n",
      "[[ 793  500]\n",
      " [ 950 2109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.61      0.52      1293\n",
      "           1       0.81      0.69      0.74      3059\n",
      "\n",
      "    accuracy                           0.67      4352\n",
      "   macro avg       0.63      0.65      0.63      4352\n",
      "weighted avg       0.70      0.67      0.68      4352\n",
      "\n",
      "f1_score:\n",
      "0.636021784264168\n",
      "precision_score:\n",
      "0.6330166596838516\n",
      "accuracy_score:\n",
      "0.6865808823529411\n",
      "Confusion Matrix:\n",
      "[[ 683  610]\n",
      " [ 754 2305]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.50      1293\n",
      "           1       0.79      0.75      0.77      3059\n",
      "\n",
      "    accuracy                           0.69      4352\n",
      "   macro avg       0.63      0.64      0.64      4352\n",
      "weighted avg       0.70      0.69      0.69      4352\n",
      "\n",
      "Elapsed Time: 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6220443439955636\n",
      "precision_score:\n",
      "0.6209840794183403\n",
      "accuracy_score:\n",
      "0.6567095588235294\n",
      "Confusion Matrix:\n",
      "[[ 770  523]\n",
      " [ 971 2088]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.60      0.51      1293\n",
      "           1       0.80      0.68      0.74      3059\n",
      "\n",
      "    accuracy                           0.66      4352\n",
      "   macro avg       0.62      0.64      0.62      4352\n",
      "weighted avg       0.69      0.66      0.67      4352\n",
      "\n",
      "Elapsed Time: 5 seconds\n",
      "0.8 2\n",
      "f1_score:\n",
      "0.6378574546022678\n",
      "precision_score:\n",
      "0.6355823614928319\n",
      "accuracy_score:\n",
      "0.6734834558823529\n",
      "Confusion Matrix:\n",
      "[[ 783  488]\n",
      " [ 933 2148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.62      0.52      1271\n",
      "           1       0.81      0.70      0.75      3081\n",
      "\n",
      "    accuracy                           0.67      4352\n",
      "   macro avg       0.64      0.66      0.64      4352\n",
      "weighted avg       0.71      0.67      0.69      4352\n",
      "\n",
      "f1_score:\n",
      "0.6209557234318845\n",
      "precision_score:\n",
      "0.6344463403682084\n",
      "accuracy_score:\n",
      "0.6392463235294118\n",
      "Confusion Matrix:\n",
      "[[ 913  358]\n",
      " [1212 1869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.72      0.54      1271\n",
      "           1       0.84      0.61      0.70      3081\n",
      "\n",
      "    accuracy                           0.64      4352\n",
      "   macro avg       0.63      0.66      0.62      4352\n",
      "weighted avg       0.72      0.64      0.66      4352\n",
      "\n",
      "Elapsed Time: 8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.626992743271813\n",
      "precision_score:\n",
      "0.6305637750010665\n",
      "accuracy_score:\n",
      "0.6539522058823529\n",
      "Confusion Matrix:\n",
      "[[ 838  433]\n",
      " [1073 2008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.66      0.53      1271\n",
      "           1       0.82      0.65      0.73      3081\n",
      "\n",
      "    accuracy                           0.65      4352\n",
      "   macro avg       0.63      0.66      0.63      4352\n",
      "weighted avg       0.71      0.65      0.67      4352\n",
      "\n",
      "Elapsed Time: 4 seconds\n",
      "Elapsed Time: 175 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = np.empty([9, 7])\n",
    "mlp = np.empty([9, 7])\n",
    "svm = np.empty([9, 7])\n",
    "test_sizes = [0.2,0.5,0.8]\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_train,Y_train = shuffle(X_train, Y_train)\n",
    "j = 0\n",
    "start1 = time.time()\n",
    "for size in test_sizes:\n",
    "    for i in np.arange(3):\n",
    "        print(size, i)\n",
    "        x_train1, x_test1, y_train1, y_test1 = train_test_split(X_train, Y_train, test_size=size)\n",
    "        rf_time = time.time()\n",
    "        rf_f1, rf_apr, rf_acc, rf_auc = RFfunc(x_train1, x_test1, y_train1, y_test1)\n",
    "        rf_time = time.time() - rf_time\n",
    "        \n",
    "        mlp_time = time.time()\n",
    "        mlp_f1, mlp_apr, mlp_acc, mlp_auc = MLPfunc(x_train1, x_test1, y_train1, y_test1)\n",
    "        mlp_time = time.time() - mlp_time\n",
    "        \n",
    "        svm_time = time.time()\n",
    "        svm_f1, svm_apr, svm_acc, svm_auc = LSVMfunc(x_train1, x_test1, y_train1, y_test1)\n",
    "        svm_time = time.time() - svm_time\n",
    "        rf[j] = [rf_f1, rf_apr, rf_acc, rf_auc, i, size, rf_time]\n",
    "        mlp[j] = [mlp_f1, mlp_apr, mlp_acc, mlp_auc, i, size, mlp_time]\n",
    "        svm[j] = [svm_f1, svm_apr, svm_acc, svm_auc, i, size, svm_time]\n",
    "        j = j + 1\n",
    "now1 = time.time()\n",
    "print('Elapsed Time: ' + str(int(now1-start1)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = pd.DataFrame(rf, columns = ['f1', 'apr', 'acc', 'auc', 'trial', 'test_size','time'])\n",
    "mlp_df = pd.DataFrame(mlp, columns = ['f1', 'apr', 'acc', 'auc', 'trial', 'test_size','time'])\n",
    "svm_df = pd.DataFrame(svm, columns = ['f1', 'apr', 'acc', 'auc', 'trial', 'test_size','time'])\n",
    "rf_df['avg'] = round(rf_df.drop(['trial','test_size','time'],axis=1).mean(axis=1),3).values\n",
    "mlp_df['avg'] = round(mlp_df.drop(['trial','test_size','time'],axis=1).mean(axis=1),3).values\n",
    "svm_df['avg'] = round(svm_df.drop(['trial','test_size','time'],axis=1).mean(axis=1),3).values\n",
    "mlp_mean = round(mlp_df.groupby('test_size').mean(),3).drop('trial', axis = 1)\n",
    "rf_mean = round(rf_df.groupby('test_size').mean(),3).drop('trial', axis = 1)\n",
    "svm_mean = round(svm_df.groupby('test_size').mean(),3).drop('trial', axis = 1)\n",
    "rf_mean['avg'] = round(rf_mean.drop('time',axis=1).mean(axis=1),3).values\n",
    "mlp_mean['avg'] = round(mlp_mean.drop('time',axis=1).mean(axis=1),3).values\n",
    "svm_mean['avg'] = round(svm_mean.drop('time',axis=1).mean(axis=1),3).values\n",
    "\n",
    "rf_mean['avg_std'] = round(rf_df.groupby('test_size').std(),3)['avg'].values\n",
    "mlp_mean['avg_std'] = round(mlp_df.groupby('test_size').std(),3)['avg'].values\n",
    "svm_mean['avg_std'] = round(svm_df.groupby('test_size').std(),3)['avg'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5440, 210)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8839, 210)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8839,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([2579, 6260], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6109603676117981\n",
      "precision_score:\n",
      "0.6074508780709671\n",
      "accuracy_score:\n",
      "0.6719457013574661\n",
      "Confusion Matrix:\n",
      "[[244 223]\n",
      " [357 944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.52      0.46       467\n",
      "           1       0.81      0.73      0.76      1301\n",
      "\n",
      "    accuracy                           0.67      1768\n",
      "   macro avg       0.61      0.62      0.61      1768\n",
      "weighted avg       0.70      0.67      0.68      1768\n",
      "\n",
      "f1_score:\n",
      "0.5876325970159437\n",
      "precision_score:\n",
      "0.5870391218688432\n",
      "accuracy_score:\n",
      "0.6442307692307693\n",
      "Confusion Matrix:\n",
      "[[242 225]\n",
      " [404 897]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.52      0.43       467\n",
      "           1       0.80      0.69      0.74      1301\n",
      "\n",
      "    accuracy                           0.64      1768\n",
      "   macro avg       0.59      0.60      0.59      1768\n",
      "weighted avg       0.69      0.64      0.66      1768\n",
      "\n",
      "Elapsed Time: 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.5566016406967047\n",
      "precision_score:\n",
      "0.5573149270275521\n",
      "accuracy_score:\n",
      "0.6210407239819005\n",
      "Confusion Matrix:\n",
      "[[212 255]\n",
      " [415 886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.45      0.39       467\n",
      "           1       0.78      0.68      0.73      1301\n",
      "\n",
      "    accuracy                           0.62      1768\n",
      "   macro avg       0.56      0.57      0.56      1768\n",
      "weighted avg       0.66      0.62      0.64      1768\n",
      "\n",
      "Elapsed Time: 39 seconds\n",
      "Elapsed Time: 55 seconds\n",
      "f1_score:\n",
      "0.6076721210250078\n",
      "precision_score:\n",
      "0.6356083544824568\n",
      "accuracy_score:\n",
      "0.6097285067873304\n",
      "Confusion Matrix:\n",
      "[[475 146]\n",
      " [544 603]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.76      0.58       621\n",
      "           1       0.81      0.53      0.64      1147\n",
      "\n",
      "    accuracy                           0.61      1768\n",
      "   macro avg       0.64      0.65      0.61      1768\n",
      "weighted avg       0.69      0.61      0.62      1768\n",
      "\n",
      "f1_score:\n",
      "0.629682570899108\n",
      "precision_score:\n",
      "0.6783098781681347\n",
      "accuracy_score:\n",
      "0.7036199095022625\n",
      "Confusion Matrix:\n",
      "[[ 227  394]\n",
      " [ 130 1017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.37      0.46       621\n",
      "           1       0.72      0.89      0.80      1147\n",
      "\n",
      "    accuracy                           0.70      1768\n",
      "   macro avg       0.68      0.63      0.63      1768\n",
      "weighted avg       0.69      0.70      0.68      1768\n",
      "\n",
      "Elapsed Time: 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.572817879794624\n",
      "precision_score:\n",
      "0.5740777666999003\n",
      "accuracy_score:\n",
      "0.5927601809954751\n",
      "Confusion Matrix:\n",
      "[[333 288]\n",
      " [432 715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.54      0.48       621\n",
      "           1       0.71      0.62      0.67      1147\n",
      "\n",
      "    accuracy                           0.59      1768\n",
      "   macro avg       0.57      0.58      0.57      1768\n",
      "weighted avg       0.62      0.59      0.60      1768\n",
      "\n",
      "Elapsed Time: 34 seconds\n",
      "Elapsed Time: 51 seconds\n",
      "f1_score:\n",
      "0.6169787414276316\n",
      "precision_score:\n",
      "0.62272497654615\n",
      "accuracy_score:\n",
      "0.6600678733031674\n",
      "Confusion Matrix:\n",
      "[[287 143]\n",
      " [458 880]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.67      0.49       430\n",
      "           1       0.86      0.66      0.75      1338\n",
      "\n",
      "    accuracy                           0.66      1768\n",
      "   macro avg       0.62      0.66      0.62      1768\n",
      "weighted avg       0.74      0.66      0.68      1768\n",
      "\n",
      "f1_score:\n",
      "0.5671946544712054\n",
      "precision_score:\n",
      "0.5886878640901275\n",
      "accuracy_score:\n",
      "0.6018099547511312\n",
      "Confusion Matrix:\n",
      "[[282 148]\n",
      " [556 782]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.66      0.44       430\n",
      "           1       0.84      0.58      0.69      1338\n",
      "\n",
      "    accuracy                           0.60      1768\n",
      "   macro avg       0.59      0.62      0.57      1768\n",
      "weighted avg       0.72      0.60      0.63      1768\n",
      "\n",
      "Elapsed Time: 12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.5407143797157395\n",
      "precision_score:\n",
      "0.5706863633338963\n",
      "accuracy_score:\n",
      "0.5712669683257918\n",
      "Confusion Matrix:\n",
      "[[277 153]\n",
      " [605 733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.64      0.42       430\n",
      "           1       0.83      0.55      0.66      1338\n",
      "\n",
      "    accuracy                           0.57      1768\n",
      "   macro avg       0.57      0.60      0.54      1768\n",
      "weighted avg       0.70      0.57      0.60      1768\n",
      "\n",
      "Elapsed Time: 42 seconds\n",
      "Elapsed Time: 62 seconds\n",
      "f1_score:\n",
      "0.4673863192443275\n",
      "precision_score:\n",
      "0.6314835495232368\n",
      "accuracy_score:\n",
      "0.6340497737556561\n",
      "Confusion Matrix:\n",
      "[[  66  608]\n",
      " [  39 1055]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.10      0.17       674\n",
      "           1       0.63      0.96      0.77      1094\n",
      "\n",
      "    accuracy                           0.63      1768\n",
      "   macro avg       0.63      0.53      0.47      1768\n",
      "weighted avg       0.63      0.63      0.54      1768\n",
      "\n",
      "f1_score:\n",
      "0.5191854531544414\n",
      "precision_score:\n",
      "0.5362407345013477\n",
      "accuracy_score:\n",
      "0.5882352941176471\n",
      "Confusion Matrix:\n",
      "[[185 489]\n",
      " [239 855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.27      0.34       674\n",
      "           1       0.64      0.78      0.70      1094\n",
      "\n",
      "    accuracy                           0.59      1768\n",
      "   macro avg       0.54      0.53      0.52      1768\n",
      "weighted avg       0.56      0.59      0.56      1768\n",
      "\n",
      "Elapsed Time: 12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.5301009553010096\n",
      "precision_score:\n",
      "0.5306349734042553\n",
      "accuracy_score:\n",
      "0.5610859728506787\n",
      "Confusion Matrix:\n",
      "[[269 405]\n",
      " [371 723]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.40      0.41       674\n",
      "           1       0.64      0.66      0.65      1094\n",
      "\n",
      "    accuracy                           0.56      1768\n",
      "   macro avg       0.53      0.53      0.53      1768\n",
      "weighted avg       0.56      0.56      0.56      1768\n",
      "\n",
      "Elapsed Time: 38 seconds\n",
      "Elapsed Time: 58 seconds\n",
      "f1_score:\n",
      "0.5306417338790652\n",
      "precision_score:\n",
      "0.5300892920795609\n",
      "accuracy_score:\n",
      "0.6706281833616299\n",
      "Confusion Matrix:\n",
      "[[ 110  277]\n",
      " [ 305 1075]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.28      0.27       387\n",
      "           1       0.80      0.78      0.79      1380\n",
      "\n",
      "    accuracy                           0.67      1767\n",
      "   macro avg       0.53      0.53      0.53      1767\n",
      "weighted avg       0.68      0.67      0.67      1767\n",
      "\n",
      "f1_score:\n",
      "0.5231161368956644\n",
      "precision_score:\n",
      "0.5242275745178726\n",
      "accuracy_score:\n",
      "0.6842105263157895\n",
      "Confusion Matrix:\n",
      "[[  91  296]\n",
      " [ 262 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       387\n",
      "           1       0.79      0.81      0.80      1380\n",
      "\n",
      "    accuracy                           0.68      1767\n",
      "   macro avg       0.52      0.52      0.52      1767\n",
      "weighted avg       0.67      0.68      0.68      1767\n",
      "\n",
      "Elapsed Time: 8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.18127989175754117\n",
      "precision_score:\n",
      "0.6096317280453258\n",
      "accuracy_score:\n",
      "0.22014714204867006\n",
      "Confusion Matrix:\n",
      "[[ 387    0]\n",
      " [1378    2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36       387\n",
      "           1       1.00      0.00      0.00      1380\n",
      "\n",
      "    accuracy                           0.22      1767\n",
      "   macro avg       0.61      0.50      0.18      1767\n",
      "weighted avg       0.83      0.22      0.08      1767\n",
      "\n",
      "Elapsed Time: 37 seconds\n",
      "Elapsed Time: 53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "rf = np.empty([5, 4])\n",
    "mlp = np.empty([5, 4])\n",
    "svm = np.empty([5, 4])\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X, Y):\n",
    "    x_train = X[train_index]\n",
    "    y_train = Y[train_index]\n",
    "    \n",
    "    x_test = X[test_index]\n",
    "    y_test = Y[test_index]\n",
    "        \n",
    "    start = time.time()\n",
    "    rf_f1, rf_apr, rf_acc, rf_auc = RFfunc(x_train, x_test, y_train, y_test)\n",
    "    mlp_f1, mlp_apr, mlp_acc, mlp_auc = MLPfunc(x_train, x_test, y_train, y_test)\n",
    "    svm_f1, svm_apr, svm_acc, svm_auc = LSVMfunc(x_train, x_test, y_train, y_test)\n",
    " \n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    rf[j] = [rf_f1, rf_apr, rf_acc, rf_auc]\n",
    "    mlp[j] = [mlp_f1, mlp_apr, mlp_acc, mlp_auc]\n",
    "    svm[j] = [svm_f1, svm_apr, svm_acc, svm_auc]\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_stats = pd.DataFrame(rf, columns = ['f1', 'apr', 'acc', 'auc'])\n",
    "mlp_stats = pd.DataFrame(mlp, columns = ['f1', 'apr', 'acc', 'auc'])\n",
    "svm_stats = pd.DataFrame(svm, columns = ['f1', 'apr', 'acc', 'auc'])\n",
    "rf_stats['avg'] = rf_stats.mean(axis=1).values\n",
    "mlp_stats['avg'] = mlp_stats.mean(axis=1).values\n",
    "svm_stats['avg'] = svm_stats.mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.63725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.63475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.65750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.56300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.55650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc      avg\n",
       "0  0.611  0.607  0.672  0.659  0.63725\n",
       "1  0.608  0.636  0.610  0.685  0.63475\n",
       "2  0.617  0.623  0.660  0.730  0.65750\n",
       "3  0.467  0.631  0.634  0.520  0.56300\n",
       "4  0.531  0.530  0.671  0.494  0.55650"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     0.5668\n",
       "apr    0.6054\n",
       "acc    0.6494\n",
       "auc    0.6176\n",
       "avg    0.6098\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_stats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.60800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.66075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.60475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.53975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.56075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc      avg\n",
       "0  0.588  0.587  0.644  0.613  0.60800\n",
       "1  0.630  0.678  0.704  0.631  0.66075\n",
       "2  0.567  0.589  0.602  0.661  0.60475\n",
       "3  0.519  0.536  0.588  0.516  0.53975\n",
       "4  0.523  0.524  0.684  0.512  0.56075"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     0.5654\n",
       "apr    0.5828\n",
       "acc    0.6444\n",
       "auc    0.5866\n",
       "avg    0.5948\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_stats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.57975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.58775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.57675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.53875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.37200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc      avg\n",
       "0  0.557  0.557  0.621  0.584  0.57975\n",
       "1  0.573  0.574  0.593  0.611  0.58775\n",
       "2  0.541  0.571  0.571  0.624  0.57675\n",
       "3  0.530  0.531  0.561  0.533  0.53875\n",
       "4  0.181  0.610  0.220  0.477  0.37200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     0.4764\n",
       "apr    0.5686\n",
       "acc    0.5132\n",
       "auc    0.5658\n",
       "avg    0.5310\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_stats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>time</th>\n",
       "      <th>avg</th>\n",
       "      <th>avg_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.745</td>\n",
       "      <td>4.462</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.737</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.708</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1    apr    acc    auc   time    avg  avg_std\n",
       "test_size                                                   \n",
       "0.2        0.650  0.660  0.669  0.745  4.462  0.681    0.031\n",
       "0.5        0.645  0.648  0.674  0.737  2.710  0.676    0.006\n",
       "0.8        0.627  0.632  0.655  0.708  1.005  0.655    0.011"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>time</th>\n",
       "      <th>avg</th>\n",
       "      <th>avg_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.706</td>\n",
       "      <td>9.207</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.732</td>\n",
       "      <td>7.335</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.685</td>\n",
       "      <td>5.250</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1    apr    acc    auc   time    avg  avg_std\n",
       "test_size                                                   \n",
       "0.2        0.650  0.654  0.692  0.706  9.207  0.675    0.002\n",
       "0.5        0.635  0.648  0.659  0.732  7.335  0.669    0.022\n",
       "0.8        0.631  0.633  0.666  0.685  5.250  0.654    0.002"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>time</th>\n",
       "      <th>avg</th>\n",
       "      <th>avg_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.773</td>\n",
       "      <td>15.604</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.754</td>\n",
       "      <td>8.307</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.700</td>\n",
       "      <td>4.571</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1    apr    acc    auc    time    avg  avg_std\n",
       "test_size                                                    \n",
       "0.2        0.665  0.675  0.686  0.773  15.604  0.700    0.030\n",
       "0.5        0.658  0.661  0.686  0.754   8.307  0.690    0.010\n",
       "0.8        0.626  0.626  0.658  0.700   4.571  0.653    0.005"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing.scale(X_train)\n",
    "X_train,Y_train = shuffle(X_train, Y_train)\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([2579, 6260], dtype=int64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = ensemble.RandomForestClassifier(n_jobs = -1, n_estimators=150, random_state=42)\n",
    "clf.fit(x_train1, y_train1)\n",
    "\n",
    "now = time.time()\n",
    "print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "probs = clf.predict_proba(x_test1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(tpr - fpr) w/ th =  0.6733333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(y_test1, probs, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 8 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp = MLPClassifier(solver='adam', activation='relu', alpha=0.0001, hidden_layer_sizes = (64, 1), max_iter = 10000)\n",
    "mlp.fit(x_train1, y_train1)\n",
    "\n",
    "now = time.time()\n",
    "print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "probs_nn = mlp.predict_proba(x_test1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(tpr - fpr) w/ th =  0.9981069845990855\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3hUZfbA8e9JgQCBQEJNQkkINRAChKqEEqQvRRFRrOiq6/KzrxQX7IsF68LaUFFRAlIVEVEEsaARBCmh1yS0JEBIIW3m/P64IQWSEMpkUt7P88yTW965c2YgOXPf+97ziqpiGIZhGI7k4uwADMMwjIrPJBvDMAzD4UyyMQzDMBzOJBvDMAzD4UyyMQzDMBzOJBvDMAzD4UyyMQzDMBzOJBujQhGRgyJyVkRSROSYiMwREc/z2vQUkR9EJFlEkkTkKxFpe16bWiLyhogczjnW3pz1ukW8rojIgyKyTURSRSRWRL4QkfaOfL+GUV6YZGNURH9TVU8gFOgITD63Q0R6AKuAZYAvEAD8BfwiIoE5baoAq4FgYBBQC+gJJAJdi3jNN4GHgAcBb6AlsBQYeqnBi4jbpT7HMMo6MRUEjIpERA4C96jq9znrLwPBqjo0Z/0nYKuqPnDe874B4lX1dhG5B3gBaK6qKSV4zRbATqCHqkYV0WYtMFdVZ+es35kT57U56wpMAB4G3IBvgRRVfTzfMZYBP6rqayLiC/wXCAdSgNdV9a0SfESG4RTmzMaosETEHxgM7M1Zr451hvJFIc0XANflLPcHVpYk0eSIAGKLSjSXYCTQDWgLfA7cJCICICJ1gAFApIi4AF9hnZH55bz+wyIy8Apf3zAcxiQboyJaKiLJQAxwAngqZ7s31v/5o4U85yhw7nqMTxFtinKp7YsyXVVPqupZ4CdAgV45+0YD61X1CNAFqKeqz6pqpqruB94Hxl6FGAzDIUyyMSqikapaE+gDtCYviZwC7ECjQp7TCEjIWU4sok1RLrV9UWLOLajVvx0J3Jyz6Rbgs5zlpoCviJw+9wCmAA2uQgyG4RAm2RgVlqr+CMwBZuSspwLrgRsLaT4Ga1AAwPfAQBGpUcKXWg34i0hYMW1Sger51hsWFvJ56/OA0SLSFKt7bVHO9hjggKrWzveoqapDShivYZQ6k2yMiu4N4DoRCc1ZnwTckTNMuaaI1BGR54EewDM5bT7F+oO+SERai4iLiPiIyBQRueAPuqruAf4HzBORPiJSRUQ8RGSsiEzKabYZuF5EqotIEHD3xQJX1U1APDAb+FZVT+fsigLOiMhEEakmIq4i0k5EulzOB2QYpcEkG6NCU9V44BNgas76z8BA4Hqs6yyHsIZHX5uTNFDVDKxBAjuB74AzWH/g6wK/F/FSDwIzgVnAaWAfMArrQj7A60AmcBz4mLwusYuZlxPL5/nekw34G9bQ7gNY3X+zAa8SHtMwSp0Z+mwYhmE4nDmzMQzDMBzOJBvDMAzD4UyyMQzDMBzOJBvDMAzD4cpdwb+6detqs2bNnB2GYRhGubJx48YEVa3nrNcvd8mmWbNmbNiwwdlhGIZhlCsicsiZr2+60QzDMAyHM8nGMAzDcDiTbAzDMAyHK3fXbAqTlZVFbGws6enpzg7FqMA8PDzw9/fH3d3d2aEYRrlTIZJNbGwsNWvWpFmzZuTMNWUYV5WqkpiYSGxsLAEBAc4OxzDKHYd1o4nIhyJyQkS2FbFfROQtEdkrIltEpNPlvlZ6ejo+Pj4m0RgOIyL4+PiYs2fDuEyOvGYzBxhUzP7BQIucx73A21fyYibRGI5m/o8ZxuVzWDeaqq4TkWbFNBkBfJIzI+FvIlJbRBqp6tWYXtcwDKP8SzsJJ/eTcWIP6cf34tVhGPh2dHZUl8WZo9H8yDcNLhCbs+0CInKviGwQkQ3x8fGlEtylEhFuu+223PXs7Gzq1avHsGHDAJgzZw4TJky44HnNmjWjffv2dOjQgQEDBnDs2DEAUlJSuO+++2jevDnBwcGEh4fz++/WVCqenp5XLe533nmHTz75BICdO3cSGhpKx44d2bdvHz179rzi48fHx+Pu7s67775bYPv57+H8z+eTTz6hXbt2BAcH07ZtW2bMmHHR15o+fTpBQUG0atWKb7/9ttA2vXr1IjQ0lNDQUHx9fRk5ciQAa9euxcvLK3ffs88+e6lv1TAunSqkJkBMFGyeBz+8AAvvhvf6wotN4eUAmB1B1S/vx+v3Gdhj/3R2xJfNmQMECuuTKHRyHVV9D3gPICwsrExOwFOjRg22bdvG2bNnqVatGt999x1+foXmzgusWbOGunXrMmXKFP7zn//w1ltvcc899xAQEMCePXtwcXFh//797Nix46rHff/99+cuL126lBEjRvDMM9aElb/++muJj6OqqCouLgW/v3zxxRd0796defPmcd9995XoWN988w1vvPEGq1atwtfXl/T0dD799NNinxMdHU1kZCTbt2/nyJEj9O/fn927d+Pq6lqg3U8//ZS7fMMNNzBixIjc9V69erF8+fISxWgYJaYKKSfg5P6cx758ywcg40xeW3EBL3/wDiSjzSi+O1qdpYc9yPJqxgOjIujW0o+VK1fy0EMPYbPZuOeee5g0aVKBl8vIyOD2229n48aN+Pj4MH/+fPKX+BKRJkA08LSqzhARD2AdUBUrJyxU1afyH1NE/gvcpaqeOet3Aq8AcTlNZqrq7OI+Bmcmm1igcb51f+CIk2K5KgYPHszXX3/N6NGjmTdvHjfffHOBP24XEx4ezltvvcW+ffv4/fff+eyzz3L/eAcGBhIYGFigfUpKCiNGjODUqVNkZWXx/PPPM2LECFJTUxkzZgyxsbHYbDamTp3KTTfdxKRJk/jyyy9xc3NjwIABzJgxg6effhpPT0/atm3LG2+8gaurK+vWrWPNmjV4enqSkpICwCuvvMKCBQvIyMhg1KhRPPPMMxw8eJDBgwfTt29f1q9fz9KlS2natGmBGOfNm8err77KLbfcQlxcXIkS8PTp05kxYwa+vr6ANeT473//e7HPWbZsGWPHjqVq1aoEBAQQFBREVFQUPXr0KLR9cnIyP/zwAx999NFF4zGMi7LbIeVYviSyHxL3Wcnk5H7ISs1rK65Quwl4B4J/V/Bpbi17B1rb3apisytD31jH/vgU/h4eyCP9W+Lh7orNZuOf//wn3333Hf7+/nTp0oXhw4fTtm3b3MN/8MEH1KlTh7179xIZGcnEiROZP39+/mhfB77Jt54B9FPVFBFxB34WkW9U9TcAEQkDahfyruer6oXdNUVwZrL5EpggIpFANyDpqlyv+WYSHNt6xYcpoGF7GPziRZuNHTuWZ599lmHDhrFlyxbGjx9/Sclm+fLltG/fnu3btxMaGnrBt/LzeXh4sGTJEmrVqkVCQgLdu3dn+PDhrFy5El9fX77++msAkpKSOHnyJEuWLGHnzp2ICKdPny5wrCFDhnD//ffj6enJ448/XmDfqlWr2LNnD1FRUagqw4cPZ926dTRp0oRdu3bx0Ucf8b///e+C+GJiYjh27Bhdu3ZlzJgxzJ8/n0cfffSin8O2bdvo3LlzofveeecdoOAZGUBcXBzdu3fPXff39ycuLo6iLFmyhIiICGrVqpW7bf369XTo0AFfX19mzJhBcHDwRWM1KhG7Hc7EFUwo+c9Qss/mtXVxgzrNrATS7Jq8ZHIuobgWfq/WqdRMarsqri7C4wNa4VvbgxD/vL/zUVFRBAUF5X7xHDt2LMuWLSuQbJYtW8bTTz8NwOjRo5kwYQLnZmQWkZHAfiA3++VcN0/JWXXPeWhOe1esM5hbsKY5v2wOSzYiMg/oA9QVkVjgKaw3gaq+A6wAhgB7gTTgLkfFUlpCQkI4ePAg8+bNY8iQISV+Xt++fXF1dSUkJITnn3+edevWleh5qsqUKVNYt24dLi4uxMXFcfz4cdq3b8/jjz/OxIkTGTZsGL169SI7OxsPDw/uuecehg4dmnstqSRWrVrFqlWr6NjRujCZkpLCnj17aNKkCU2bNi3wRz6/yMhIxowZA1i/FHfffXexyaYko73OTzLnFDa9eXHHmzdvHvfcc0/ueqdOnTh06BCenp6sWLGCkSNHsmfPnovGY1QwdhskxRRMIvmXbRl5bV2rQJ0AK4EE9gXvgLyE4tUYXEv+51VVWbo5jme+imbioNbc3LUJg9o1vKBdXFwcjRvndQj5+/vnXsstrI2bmxteXl4kJiaCdY1+InAdUOAbZU5S2QgEAbNU9dxBJwBfqurRQn6fbhCRcGA38IiqxpzfID9Hjka7+SL7FfjnVX/hEpyBONLw4cN5/PHHWbt27bl/4Is6d83mnODgYP766y/sdvsF10Dy++yzz4iPj2fjxo24u7vTrFkz0tPTadmyJRs3bmTFihVMnjyZAQMGMG3aNKKioli9ejWRkZHMnDmTH374oUTxqSqTJ0++4JrLwYMHqVGjRpHPmzdvHsePH+ezzz4D4MiRI+zZs4cWLVpQrVo1MjMzqVKlCgAnT57M/QyCg4PZuHEj/fr1K1F8YP3SxcTk/V+PjY3N7YY7X2JiIlFRUSxZsiR3W/4znCFDhvDAAw+QkJBQ4N/FqCBs2ZB0GBILOUM5dRDsWXlt3TyshOITBC2uK3iGUssPXIrvfSiJI6fP8uSSrazZFU/HJrUJa1qnyLYl+VJVTBtf4MGc7rLzn2MDQkWkNrBERNoBJ4EbsU4azvcVME9VM0TkfuBjoNhf2ApRQaAsGT9+PF5eXrRv3561a9de1jGaN29OWFgYTz31FM8++ywiwp49e4iOji5wQTspKYn69evj7u7OmjVrOHTIqiB+5MgRvL29ufXWW/H09GTOnDmkpKSQlpbGkCFD6N69O0FBQSWOZ+DAgUydOpVx48bh6elJXFzcRUu27Nq1i9TU1AJdWU899RSRkZFMnTqV3r17M3fuXMaPH8/Zs2dZsGABL7/8MgCTJ0/miSeeYPny5TRs2JCMjAzeffddHnzwwSJfb/jw4dxyyy08+uijuUmta9euhbb94osvGDZsGB4eHrnbjh07RoMGDRARoqKisNvt+Pj4lPgzMsqY7Ew4fbjwi/KnD4M9O6+te3UredRvDa2HFkwoNRtBMV/4rtSyzXE8uWQbNrsybVhb7ujZDFeXos/IS/Kl6lwbf39/srOzSUpKwtvbG6AG8LKIvIx1DcYuIumqOvPcc1X1tIisxbpHcgfWmc7enORUXUT2qmqQqub/Jv0+8NLF3qtJNleZv78/Dz30UKH75syZw9KlS3PXf/vttyKPM3v2bB577DGCgoKoXr06Pj4+vPLKKwXajBs3jr/97W+EhYURGhpK69atAdi6dSv/+te/cHFxwd3dnbfffpvk5GRGjBhBeno6qsrrr79e4vc0YMAAduzYkXux3dPTk7lz5xZ7TWnevHmMGlWwi/eGG25g7NixTJ06lTfffJP77ruPt956C1Xl9ttvJzw8HLDOLI4fP07//v1RVUSE8ePHA0VfswkODmbMmDG0bdsWNzc3Zs2alRvfkCFDmD17du4vZWRk5AUjeBYuXMjbb7+Nm5sb1apVIzIy0tzEWdZlpcPpQ4VclN9vdYWpPa9tFU8reTQMgbYjC16U92wATvq39qrmTmjj2ky/vj2NvatftH2XLl3Ys2cPBw4cwM/Pj8jISD7//PMCbYYPH87HH39Mjx49WLhwIf369Tv3f3mXqoYBiMjTQIqqzhSRekBWTqKpBvQHXlLVr4HcvjwRSVHVoJzl/PdEDsdKTMWSwk65yrKwsDA9f/K0HTt20KZNGydFZFQm5v+ag9ltkJmSt652OHO08IvySbEUuFuiqhf4BBY8M/HOSSo16jotoeSXbbPzwc8HyLLZmdCvBUDuF6qSWrFiBQ8//DA2m43x48fz5JNPMm3aNMLCwhg+fDjp6encdtttbNq0CW9vbyIjIwkMDERENhaSbGaISAhWN5gr1nWdBap6wY1mOcnm3NDn6VhJJhuru+0fqrqzuLhNsjGMS2D+r10FWTmjtlLjYdNnsH2xdW1EBI7+Vfxzq9XJSyDnP6p7l4mEUpToI2eYuGgLW+OSGBrSiJk3dyzVs+f8ycYZTDeaYRilY/e38PmYove3HASeDcGtCjTJd3+UZwNrpFedACuhlDMZ2TZm/rCXt9fuo3Z1d/43rhOD2zWsdN20FSbZXOqpqGFcqvLWC1CmnNyfl2gad4NWg63lqrWg/Wjw8HJebA52MCGNd37cx/BQX6YObUudGlWcHZJTVIhk4+HhQWJioplmwHCYc/PZ5B/BZpxHFY5tgeRjsO4ViP0jZ4eQe22lSU8Y/01RR6gwUjOy+S76OCM7+tGqYU1WP9qHJj4XHwBQkVWIZOPv709sbCxltUinUTGcm6nTyMeWBT+/Ab+/DWmF3FfW80HregxAg7YQfEU3oZcLP+2JZ/LircSdPks7v1oE1a9Z6RMNVJBk4+7ubmZPNIzSYsuCrx62ksuRPyHluLXdtYqVTNqPgRo+0LCDQ+9RKWuS0rJ4YUU0CzbEEli3BvPv7UFQ/ZrODqvMqBDJxjCMUpCaYN2/8l6fvG0N20PtpjD6Q6jduMinVnQ2u3LDO79yICGVB/o058GIFni4X3l1gYrEJBvDMArKTIU930H6aVg11SoqicLZU3ltajeFv6+xzmAqsZOpmdSu5o6ri/Cvga3wq12Ndn4Vd7DDlTDJxjAqO1sWHPwZzuTM8LHsgYL73apBh7Fgy4S6LcCnBQT1B/fKO1hCVVn8ZxzPLrcKZ97SrQkDgy8snGnkMcnGMCqb5ONwIF9l8eUPF7xrH6yqxTfNhZoNnVrOpSyKPZXGlCXbWLc7ns5N69A1oPzd++MMJtkYRmWzdjpsPG/SOBc3uHWRdeMkWMmmEl3cL6klm2L595JtKPDM8GBu694Ul2IKZxp5TLIxjIou5UTePS87voK/5llnK3euyGtTuzG4VXVOfOWId42qdG7mzX9GtcO/jhnOfClMsjGMisCWZRWxPHsKot6zZqtNioH4ImojXvsI1C35NBOVVZbNzvs/7SfbpjwY0YLeLesR3qKuuXn8MphkYxjlWXYmLH8ENs8tfH9gH8hIgZAx0CRnRtVa/pV+FFlJbItLYuKiLWw/coa/dfDNLYllEs3lMcnGMMqj49Hw1+fWz32rrW2d77SGJFf3gU63m4v6lyk9y8Zbq/fw7rr91KlehXdu7cSgdo2cHVa5Z5KNYZQnmWnwamvISMrb5l4D7l0L9Vo6K6oK5VBiGu//tJ/rO/rx76Ft8ape/Ky0RsmYZGMY5cmGD6xE41EbbpgNzSPMqLGrIDUjm2+3H+P6Tv60aliTHx7rU6KZM42SM8nGMMqLzZ/Dqn9by6M/hKAI58ZTQfy4O54pi7dyJOksIf5eBNWvaRKNA5ivRIZRlv30Kiy4HT4bA0v/YW274QNW7s2iVatWBAUF8eKLL17wtEceeYTQ0FBCQ0Np2bIltWvXBmDz5s306NGD4OBgQkJCmD9/fu5zVq9eTadOnQgNDeXaa69l7969ABw6dIiIiAhCQkLo06cPsbGxuds7d+5MaGgowcHBvPPOOw7+MK6uU6mZPLpgM3d8GIWHuwtf3GcKZzqUqparR+fOndUwKrS4P1U3zFGdd4vqU7Wsx3+7WI/dqzQ7O1sDAwN13759mpGRoSEhIbp9+/YiD/fWW2/pXXfdpaqqu3bt0t27d1svExenDRs21FOnTqmqaosWLTQ6OlpVVWfNmqV33HGHqqqOHj1a58yZo6qqq1ev1ltvvVVVVTMyMjQ9PV1VVZOTk7Vp06YaFxd39T8PB8i22bXvjDUaOPlrfWXlTj2bme3skBwO2KBO/NttutEMoyxI2JN34+W5M5hzbpoLbf6Wuxq1fj1BQUEEBgYCMHbsWJYtW0bbtm0LPfS8efN45plnAGjZMm8Qga+vL/Xr1yc+Pp7atWsjIpw5cwaApKQkfH19AYiOjub1118HoG/fvowcORKAKlXyZpzMyMjAbrdf7rsvNYkpGdSpXgVXF2HSoNb41alGsK8pnFkaTLIxDGdQhaObIWEvxPwOf7xfcH/bkTBoOtRsdMEQ5ri4OBo3zivn7+/vz++//17oyxw6dIgDBw7Qr1+/C/ZFRUWRmZlJ8+bNAZg9ezZDhgyhWrVq1KpVi99++w2ADh06sGjRIh566CGWLFlCcnJy7sy4MTExDB06lL179/LKK6/kJqiyRlX5YmMszy+PZuLg1ozr1pQBpnBmqTLJxjBKkyrsXwOfFjJjZeit0Ptf1rJXY3ApfD4Uq0ekoKJuNIyMjGT06NG4uhY81tGjR7ntttv4+OOPcckZzfb666+zYsUKunXrxiuvvMKjjz7K7NmzmTFjBhMmTGDOnDmEh4fj5+eHm5v1p6Nx48Zs2bKFI0eOMHLkSEaPHk2DBg1K+mmUipiTaUxZspWf9iTQtZk3PQLNDa3OYJKNYZSGo1us0WR/fgJZqdY2zwYw+GVoEGwllxKW7Pf39ycmJiZ3PTY2tsgzisjISGbNmlVg25kzZxg6dCjPP/883btbVQXi4+P566+/6NatGwA33XQTgwYNAqzutsWLFwOQkpLCokWL8PIq2PXk6+tLcHAwP/30E6NHjy7R+ygNi/+M5d9LtyHAcyPbMa5rE1M400lMsjGMqy1+F3z5INgyrPUjm/L2uVcHNw+4bQk07XlZh+/SpQt79uzhwIED+Pn5ERkZyeeff35Bu127dnHq1Cl69OiRuy0zM5NRo0Zx++23c+ONN+Zur1OnDklJSezevZuWLVvy3Xff0aZNGwASEhLw9vbGxcWF6dOnM378eMBKcj4+PlSrVo1Tp07xyy+/8Oijj17We3KUup5V6RrgzQuj2uNXu5qzw6nUTLIxjKvp7GmIvAUS90KzXuBeDVoMgLSTEP4vaDXoil/Czc2NmTNnMnDgQGw2G+PHjyc4OJhp06YRFhbG8OHDAWtgwNixYwt0sS1YsIB169aRmJjInDlzAJgzZw6hoaG8//773HDDDbi4uFCnTh0+/PBDANauXcvkyZMREcLDw3PPlHbs2MFjjz2GiKCqPP7447Rv3/6K39+VyLLZeffHfdjs8FD/FoS3rEd4y3pOjcmwSGH9v2VZWFiYbtiwwdlhGEYeVas+2cK7ramUz5kUAx61nBdXJbMtLol/LdzCjqNnGBHqyxs3hZqimfmIyEZVDXPW65szG8O4Ukf/grk3WMviAhHT4JqHTSHMUpKeZeON7/fw/k/78a5RhXdv62ymaC6DHJpsRGQQ8CbgCsxW1RfP298E+BiondNmkqquuOBAhlGW2LJh4V2w40sruUjOSK8BL0CPf5okU8oOn0zjg5/3M7qTP1OGtDGFM8sohyUbEXEFZgHXAbHAHyLypapG52v2b2CBqr4tIm2BFUAzR8VkGJctNcGaN2bHlwW3tx4G3gFQpSZ0udskmlKSnJ7Fym3HuDGsMS0b1GTN433MzJllnCPPbLoCe1V1P4CIRAIjgPzJRoFzndpewBEHxmMYl2b9LPh2ClT1KljSv1kv8OsMPSaAp7n4XNrW7DzBk0u2cuxMOh2b1Caofk2TaMoBRyYbPyAm33os0O28Nk8Dq0Tk/4AaQP/CDiQi9wL3AjRp0uSqB2oYBfz5KSx/GOzZ1nrtxuA/CnyCIGw8VKnh3PgqqZOpmTy3PJolm+JoUd+Thf/oaQpnliOOTDaF9SecP/TtZmCOqr4qIj2AT0WknaoWKLKkqu8B74E1Gs0h0RqVW+I+iImCX96E+B3WNu9AuOED8Ovk3NgMbHZl9Nu/cvhkGg9GtOCffZtT1a3wCgtG2eTIZBMLNM637s+F3WR3A4MAVHW9iHgAdYETDozLMCyqkBpvLX/5IBz6OW/fHcshoJdz4jJyxSdn4FPDKpw5ZUgb/OpUo00jM5y8PHJksvkDaCEiAUAcMBa45bw2h4EIYI6ItAE8gHgHxmQY1g2WB3+G75+Gk/vytjfpCSP/Z5WOcTV3BTiTqrJgQwzPf72DiYNac2v3pvRvW7ZqrhmXxmG/UaqaLSITgG+xhjV/qKrbReRZrHkVvgQeA94XkUewutju1PJ2l6lRfmQkw3fTYMOHBbcPfdX62fQaa2SZ4VSHE9OYtHgLv+5LpFuAN9cG1XV2SMZV4NCvbzn3zKw4b9u0fMvRwDWOjMEwcv06My/RhI2HLvdYZzHmLv8yY+HGWKYu3Yari/DCqHbc3MUUzqwoTF+BUXlkpVk/H99rhiyXUQ1qVaVncx+eH9WORl6mcGZFYpKNUbm4VTOJpgzJzLbz9tp92FV55LqW9GpRj14tzL9PRWSSjVE5nDkCv7+bd++M4XR/xZzmiYVb2HU8mes7+qGqpnBmBWaSjVHxHf0L3g23lusHOzcWg7OZNl77bhcf/HyA+jU9mH17mBlpVgm4ODsAw3AIVUjYaw0KOJdo2o6E+39m5cqVtGrViqCgIF588cULnnro0CEiIiIICQmhT58+xMbGArBmzRpCQ0NzHx4eHixduhSAXr165W739fVl5MiRgDUXjJeXV+6+Z599Nvd13nzzTdq1a0dwcDBvvPGGgz+QsiPmVBof/3qIsV2bsOrRcJNoKgtVLVePzp07q2EUKylO9ZUWqk/Vynv8/KaqqmZnZ2tgYKDu27dPMzIyNCQkRLdv317g6aNHj9Y5c+aoqurq1av11ltvveAlEhMTtU6dOpqamnrBvuuvv14//vhjVVVds2aNDh069II2W7du1eDgYE1NTdWsrCyNiIjQ3bt3X/FbL6uSzmbq/D8O567HnUpzYjSVE9YtJ077223ObIyKI+2kVQngrY6Qctzadv37cPf3cM2DAERFRREUFERgYCBVqlRh7NixLFu2rMBhoqOjiYiIAKBv374X7AdYuHAhgwcPpnr1ggUgk5OT+eGHH3LPbIqyY8cOunfvTvXq1XFzc6N3794sWbLkct95mfbDzuMMeG0dkxZtYe+JFAB8zRTNlY5JNkb5ted72PgxzO4PLzSClwPgz48hOx38wmDKEQgZA4275D4lLi6Oxo3zqij5+/sTFxdX4LAdOnRg0aJFACxZsoTk5GQSExMLtImMjER2J9cAACAASURBVOTmm2++IKQlS5YQERFBrVp59+6sX7+eDh06MHjwYLZv3w5Au3btcqdnTktLY8WKFcTExFxwvPIsMSWDhyI3MX7OBryqubP4gWsIqu/p7LAMJzEDBIzyKSkWPruh4LaA3lC/DfR/Btw9Cn2aFlKg4vwRUDNmzGDChAnMmTOH8PBw/Pz8cHPL+1U5evQoW7duZeDAgRcca968edxzzz256506deLQoUN4enqyYsUKRo4cyZ49e2jTpg0TJ07kuuuuw9PTkw4dOhR4jfLOZldufGc9MafSeKR/S/7RpzlV3Mx328qsRP+7RaQK0ERV9zo4HsMoniqsewXWvGCtD3ge2o2GWo1K9HR/f/8CZxCxsbH4+voWaOPr68vixYsBSElJYdGiRXh5eeXuX7BgAaNGjcLdveCMkImJiURFRRXoDst/hjNkyBAeeOABEhISqFu3LnfffTd33303AFOmTMHf379E76EsO5GcTt0aVXF1EZ4c2gb/OtVp1dBMA2CUoBtNRIYCW4HvctZDRaRidi4bZdOJnbBrpfXYtigv0TRoD8HXlzjRAHTp0oU9e/Zw4MABMjMziYyMZPjw4QXaJCQkYLdbs1xMnz6d8ePHF9g/b968QrvQvvjiC4YNG4aHR95Z1bFjx3LPpqKiorDb7fj4+Fhv64RV3Pzw4cMsXry40GOWF3a78tnvh+g340c+izoMQESbBibRGLlKcmbzLNakZ2sAVHWziAQ5NCrDOHUINs6B7Yvh1MEL9496FzqMveTDurm5MXPmTAYOHIjNZmP8+PEEBwczbdo0wsLCGD58OGvXrmXy5MmICOHh4cyaNSv3+QcPHiQmJobevXtfcOzIyEgmTZpUYNvChQt5++23cXNzo1q1akRGRuZ2291www0kJibi7u7OrFmzqFOnziW/n7LgYEIqkxZv4bf9J+nZ3IfepgKAUQgprA+7QAOR31S1u4hsUtWOOdu2qGpIqUR4nrCwMN2wYYMzXtooLWeOwmut89Zd3KzussY5E726uls3Z7qYawDOtmBDDFOXbqOKqwtPDm3DTV0amyoAZZSIbFTVMGe9fknObHaIyBjAJWdumoeA3xwbllFppSbAmznfYxqFwviV4G6GyZZVfrWrEd6yHs+NaEdDr8IHZRgGlCzZTACmAXZgMdb8NJMdGZRRScTvgpWTQe1w7tvwvh+sn97N4c6vTaIpYzKybfxvzT5UlUcHtOKaoLpcY+abMUqgJMlmoKpOBCae2yAi12MlHsMoGbsNTuwAtcHpw7D6OUjYlbffP+deGL8wqNcKBr4AVc09GWXJpsOnmLhoC7uPp3BDJ39TONO4JCVJNv/mwsTyZCHbDKOg9DPw40vWGcze7wpvM/ojCB6Vd2ZjlDlpmdm8umo3H/5ygIa1PPjwzjD6tTb1zIxLU2SyEZGBwCDAT0Rey7erFlaXmmEULSkW/tvZupsfwKeF9bP/01ZiqdkIGnUAF1dnRWiUUNyps3z62yHGdWvCxEGtqenhfvEnGcZ5ijuzOQFsA9KB7fm2JwOTCn2GYZxzYJ2VaGo2ggl/QFVzv0V5knQ2i2+2HmVs1ya0aFCTH//Vx8ycaVyRIpONqm4CNonIZ6qaXooxGeVZygnrIn/M79b6+JUm0ZQzq7Yf499Lt5GYmklYM2+C6nuaRGNcsZJcs/ETkReAtkDu2EZVbemwqIzyw5YFXz8K0csgMw3sWXn7XNyhaq2in2uUKQkpGTz95XaWbzlK64Y1mX1HmCmcaVw1JUk2c4DngRnAYOAuzDWbyi12g3VX/3fTIPmYNcIMwL8rVKkBLQZAy4HgURuqezs1VKNkbHZl9Nu/cuR0Oo8PaMl9vZvj7mpumjWunpIkm+qq+q2IzFDVfcC/ReQnRwdmlDF2GxzdDFHvw1/z8rZX9YJWg607/D1NmZLy5viZdOp5WoUzn/pbMP51qtGigen2NK6+kiSbDLEG0+8TkfuBOKC+Y8Myypz/dYeE3Xnr1z0HLQdB3RZm2HI5ZLcrn0Ud5qVvdjJxUCtu69GMvq3Nr7XhOCU5T34E8AQeBK4B/g6ML/YZRsWTsBtc3Gg0yxV55gxy7UO4NmxzQaK59957EZHcx8MPP5y7L//2mjXzvj03bty4wL6bbroJgObNm+duy1/i//xjGZdmf3wKY9//jalLtxHauDZ9WpkkYzjeRZONqv6uqsmqelhVb1PV4cChUojNKEtcqxDf8g6OJZxi3LhxbN++HbvdfsEEYu+//z4eHh6oKk2aNOHNN98EoH596w9aTEwMK1euJCUlhQULFgDWnDKDBw9GVXF3d8/d3rt3b8LDwwsNx9/fP7dUv1Fy8/84zOA3f2Ln0TO8PDqET+/uSmPv6hd/omFcoWKrPotIF8AP+FlVE0QkGKtsTT9VdcpMT6bqs5M8V4+2s2HH4YTc+VlcXa0bMm02W24zEeGhhx7ijTfeICMjIzfxnN/23NnNmTNnEBHat2/Pli1bcHV1xW63F5hRU0SoVasWSUlJBUIKCAjg4MGDhc6+aRTul70JfLL+IM+NaEf9WqZwZmXi7KrPRZ7ZiMh04DNgHLBSRJ7EmtPmL8AMe66E4hLOFFj38PDInWQsv5kzZwLQoEGD3PWGDRtit9tZs2YNr71mFaRIS0sDrO6yrVu3IiLY7Xbmz5/vyLdRqWRk25jx7S5mfGvVobsmqC7v3hZmEo1R6orrRhsBdFDVG4EBwFSgl6q+qqpppRKdUe488cQT2Gw2RCT3TKROnTrExcXh4uJCv379eOyxxwo8Z9++fbRv3x5VxcXFJfeajXFlNh46yZA3f2Lmmr2cSE43Z4CGUxWXbNJV9SyAqp4EdqrqrmLaGxVNRgok7rMeasevbsEbNNPT03E5bwKzl156CVVFVVm+fDkA48aNA6wutHP7AHx8fHj55ZcB2LJlCwD33XefQ99SZZCakc3TX25n9DvrSc+y8/H4rrw8uoMZTGE4VXHJJlBEFuc8lgDN8q2XqOKziAwSkV0isldECq2nJiJjRCRaRLaLyOeX8yYMB8hKtwpp/reT9bBns2qGNQjxzjvvJDo6GrvdTkRERIGnvfbaa5w5Y3W3DRs2LHd7fHx8bvfauSmVN27cyC233ALAqFGjAPjwww8d+74qgSOnz/J51GFu796Ubx8Jp3dLc/+T4XxFDhAQkYhCd+RQ1dXFHljEFdgNXAfEAn8AN6tqdL42LYAFWAMOTolIfVU9UdxxzQCBUvLhIDi8Hqp5w+CXQFwgKIIGzVpz4oT1T+Ti4pLbZebt7U1iYiJeXl65yQZg06ZNhIaG8scff9C1a9fc7T179uSXX34BrG6206dP5+4bN24cc+fOpWPHjmzevLlAWOf+v57/Lb1Ro0YcOXLk6n4G5UhSWhZfbz3KLd2aANbNmg3MdRkjH2cPECiuEGexyaQEugJ7VXU/gIhEYl0His7X5u/ALFU9lfOaxSYao5R895SVaMQV/vEr1GqUu+v48eMXNM//heX8EWPndOnSpchrBqdOnSp0+6ZNm4oM0Vx/yLNy2zGmLtvGydRMugV607yep0k0RpnjyOJHfkBMvvXYnG35tQRaisgvIvKbiAwq7EAicq+IbBCRDfHx8Q4K1wDAbodti6zlWxcVSDRG2XIiOZ0HPtvI/XM3Us+zKsv+eQ3N65nCmUbZVJJyNZersKuR538ddQNaAH0Af+AnEWmnqqcLPEn1PeA9sLrRrn6oBgBnjsK74ZB6wpo9s3lfZ0dkFMFmV8a8s54jSen8a2Ar7g0PNIUzjTKtxMlGRKqqasYlHDsWaJxv3R84v1M9FvhNVbOAAyKyCyv5/HEJr2NcqdgNsHM5/Px63rY+U5wXj1Gko0lnaVDTwyqcOTyYxnWqm2kAjHLhol+FRKSriGwF9uSsdxCR/5bg2H8ALUQkQESqAGOBL89rsxTom3PculjdavsvIX7jSm1dCLMj8hJNs14wOQ7qmft2yxK7XZnzywEiXv2Rub9b1aL6tqpvEo1RbpTkzOYtYBhWYkBV/xKRi/avqGq2iEwAvgVcgQ9VdbuIPAtsUNUvc/YNEJFowAb8S1UTL/O9GJci66x1bWbZP631QS9C9384NyajUHtPpDBp0RY2HDpFeMt69DPVmY1yqCTJxkVVD5031NRWVOP8VHUFsOK8bdPyLSvwaM7DKE0/PA/rrfteaD3MJJoyKjLqMNO+3E41d1devbED13fyMzdnGuVSSZJNjIh0BTTn3pn/w7p/xiivTsfkJZoHN0OdZk4NxyhaE5/q9G9Tn2eGt6NezarODscwLltJks0/sLrSmgDHge9zthnlUewG6xoNWNM4ewc4Nx6jgPQsG2+t3gPAE4Na07N5XXo2r+vkqAzjypUk2WSr6liHR2I4hioc3w5/fgLRSyEl56bMdqNh1LvOjc0oYMPBkzyxaAv741MZ26Uxqmq6zIwKoyTJ5o+cIcnzgcWqmuzgmIyr4egWWPoAHN9acLt7dRjwHHS5xzlxGRdIycjmlZU7+eS3Q/jVrsYn47sSbuqZGRXMRZONqjYXkZ5YQ5efEZHNQKSqRjo8OuPyHPwF5gzJW28xADrdYd2kWaWG8+IyCnUs6SyRf8RwR49m/GtgK2pUdeS91obhHMXO1HlBYxFv4A1gnKq6OiyqYphCnBeRngTv9oZTByDiKehlBvqVRadSM1m+9Si3dW8KwIkz6WZCM8OhymwhznNExBOrgOZYoA2wDOjp4LiMy3X4NyvRIBB2l7OjMc6jqnyz7RjTlm3jdFoWPZv70Lyep0k0RoVXkvP1bcBXwMuq+pOD4zGuhN0OB3+2lv/+A1Sr49x4jAJOnEln6rJtfLv9OO39vPhkfDdTONOoNEqSbAJV9cKJ5o2yJ24D/PqWtezh5dxYjAJsduXGd9dzLCmdyYNbc/e1AbiZwplGJVJkshGRV1X1MWCRiFxwYUdVr3doZMaly0y1fg7/L/g0d24sBmDNmtmwllU489kR7WhcpxqB5mzGqISKO7OZn/NzZmkEYlyB/T/CJ8Pz1uu1dl4sBmCdyXyy/iAvr9zF5CGtub1HMzM9s1GpFTdTZ1TOYhtVLZBwcgpsXulMnsaVys6EudfDwZxLaU16QqtB0CjUuXFVcntPJPPEwi38efg0fVrVI6JNA2eHZBhOV5JrNuO58Ozm7kK2GaUtKSYv0Yx6F9qPARdzHcCZPv/9ME9/uZ0aVV15/aYOjAw1hTMNA4q/ZnMT1nDnABFZnG9XTeB04c8yHM6WbdU2O33IGn0GcP1sCLnRuXEZADSrW50BwQ14engwdT1N4UzDOKe4M5soIBFrhs1Z+bYnA5scGZRRjOyzcHQzNO4OjULArSo07+fsqCqt9Cwbr3+/G0GYNNgUzjSMohR3zeYAcACryrNRFhxaDz++aC23GQY9/8+58VRyv+9PZNLirRxISGVctyamcKZhFKO4brQfVbW3iJwC8g99Fqx5z7wdHp1h+eMD62zmz0/ytvl2dF48lVxyehYvrdzJ3N8O08S7Op/f042eQeZsxjCKU1w32rmpn81vkbPYsmHJvdb0zQDVfaDPZKtis/kG7TTHz2SwcGMs91wbwKMDWlK9iimcaRgXU1w32rmqAY2BI6qaKSLXAiHAXOBMKcRXuX0yHA79Yi3f/R007urceCqxk6mZfL3lCLf1aEZQfU9+eqKfmTnTMC5BScbJLsWaEro58AlWMc7PHRqVYTkdY/18eKtJNE6iqnz11xGue+1Hnl0ezf74FACTaAzjEpXk/N+uqlkicj3whqq+JSJmNJoj/fwG7FwOKccgZCzUbuLsiCql42fSeXLJNr7fcZwQfy8+G93NlJoxjMtUommhReRG4DZgZM42d8eFVImlnYRvp8Bf86z1wL4QPMq5MVVSNrsyJqdw5pND2nDXNc1M4UzDuAIlrSDwANYUA/tFJACY59iwKoGsdDi+DeJ3QvJRQOCH5/L2mxs1nSL2VBqNvKrh6iI8N6IdTbyr06yumd3UMK5UiWbqFBE3IChnda+qZjs0qmJUiJk6D/4Mc4YWvq9ea7jrG6huRpaXJptd+eiXA8xYtYvJg9twR89mzg7JMK4qZ8/UedF+ARHpBewFPgA+BHaLyDWODqxC27Hc+tn0Whi3CP7vT/h3PCu7zKXVW6cJCunKiy++eMHTDh06REREBCEhIfTp04fY2NjcfRMnTqRdu3a0a9eO+fPn527/4Ycf6NSpE+3ateOOO+4gO9v6nnDq1ClGjRpFSEgIXbt2Zdu2bQCkp6fTtWtXOnToQHBwME899ZQDP4iyYdexZK5/+1ee/3oH1zSvy4BgUzjTMK46VS32AWwA2uZbbwNsuNjzHPXo3LmzlnsrJqr+p3GBTdnZ2RoYGKj79u3TjIwMDQkJ0e3btxdoM3r0aJ0zZ46qqq5evVpvvfVWVVVdvny59u/fX7OysjQlJUU7d+6sSUlJarPZ1N/fX3ft2qWqqlOnTtXZs2erqurjjz+uTz/9tKqq7tixQ/v166eqqna7XZOTk1VVNTMzU7t27arr16930AfhfJ+uP6hBU77Wjs+u0qWbYtVutzs7JMNwCGf+3VbVEg19rqKq0fmS0w6gigPyXsV29hRs+gw+GwO/vw32gj2RUVFRBAUFERgYSJUqVRg7dizLli0r0CY6OpqIiAgA+vbtm7s/Ojqa3r174+bmRo0aNejQoQMrV64kMTGRqlWr0rJlSwCuu+46Fi1adMGxWrduzcGDBzl+/DgigqenNeIqKyuLrKysClmCRXO6j4PqezKkfSO+eyScEaZCs2E4TEmSzZ8i8q6IXJvzeBtTiLPkMlNh3Qx4qRksewD2fGttH/h8gWZxcXE0btw4d93f35+4uLgCbTp06JCbLJYsWUJycjKJiYl06NCBb775hrS0NBISElizZg0xMTHUrVuXrKwszl3jWrhwITExMbnHWrzYKuYdFRXFoUOHcrvlbDYboaGh1K9fn+uuu45u3bpd9Y/FWc5m2njh62heXLkTgO6BPrw5tiM+pkKzYThUSUaj3Q88CDyBVRdtHfBfRwZVYSQfg7d7QlqitV6vDYz7wio7U6V6gabnvmnnd/637BkzZjBhwgTmzJlDeHg4fn5+uLm5MWDAAP744w969uxJvXr16NGjB25ubogIkZGRPPLII2RkZDBgwADc3Kx/8kmTJvHQQw8RGhpK+/bt6dixY+4+V1dXNm/ezOnTpxk1ahTbtm2jXbt2DviAStf6fYlMWryFQ4lp3Na9qSmcaRilqNhkIyLtgebAElV9uXRCqkD2rrYSjWtVeGQbeNYvsqm/v3/uWQdAbGwsvr6+Bdr4+vrmno2kpKSwaNEivLy8AHjyySd58sknAbjlllto0aIFAD169OCnn6wJ1latWsXu3bsBqFWrFh999BFgJbqAgAACAgIKvF7t2rXp06cPK1euLNfJ5kx6FtNX7GRe1GGa+lTn8793M9MAGEYpK7IbTUSmYJWqGQd8JyLjSy2qCiPnbOX/NhSbaAC6dOnCnj17OHDgAJmZmURGRjJ8+PACbRISErDnTJg2ffp0xo+3/klsNhuJidbZ05YtW9iyZQsDBgwA4MSJEwBkZGTw0ksvcf/99wNw+vRpMjMzAZg9ezbh4eHUqlWL+Ph4Tp+25sY7e/Ys33//Pa1bt77SD8KpTpzJYOmmOO4ND2TlQ+Em0RiGExR3ZjMOCFHVVBGpB6zAGvpcYiIyCHgTcAVmq+qF43mtdqOBL4AuqlrOb6K5PG5ubsycOZOBAwdis9kYP348wcHBTJs2jbCwMIYPH87atWuZPHkyIkJ4eDizZllz2mVlZdGrVy/AOmOZO3dubpfYK6+8wvLly7Hb7fzjH/+gXz9rorUdO3Zw++234+rqStu2bfnggw8AOHr0KHfccQc2mw273c6YMWMYNmyYEz6RK5OYksFXfx3hzmsCCKrvyc8T+5rrMobhREXe1Ckif6pqp3zrG1W1c4kPLOIK7AauA2KBP4Cb849sy2lXE/gaa4TbhIslm3JzU6fdBl89BJs+tQppmvpmpUJV+fKvIzz95XZSMrL59uFwU8/MMHD+TZ3FndkEisjinGUBmudbR1Wvv8ixu2JVG9gPICKRwAgg+rx2zwEvA49fSuBl2pHN8F7vvHV3U+6kNBw5fZZ/L93GDztPENq4Ni+PDjGJxjDKiOKSzQ3nrc+8xGP7ATH51mOBAmNoRaQj0FhVl4tIkclGRO4F7gVo0qQcnCEk5bzt5hEwaDrU8HFuPJVAts3O2Pd+Iz45g6nD2nJnz2a4upiRZoZRVhQ3edrqKzx2Yb/puX12IuICvA7cebEDqep7wHtgdaNdYVyl57pnoF4rZ0dRocWcTMO3djXcXF34z6j2NPGuThOf6hd/omEYpcqRNdNjsWb5PMcfOJJvvSbQDlgrIgeB7sCXIuK0PkWj/Mi22Xlv3T76v/Yjn64/CMC1LeqaRGMYZZQjJ0//A2iRMyVBHDAWuOXcTlVNAnLHoIrIWuDxcj8aLXEfzL81Z8V04zjCjqNnmLhoC1tik7iubQMGt2/k7JAMw7iIEicbEamqqhklba+q2SIyAfgWa+jzh6q6XUSexSoI9+Wlh1sOnNxv/QzsY00XYFxVn64/yDNfReNVzZ2Zt3RkaPtGpgqAYZQDF002ItIVa3oBL6CJiHQA7lHV/7vYc1V1Bdb9Ofm3TSuibZ+SBFym2W2w4ytrud9UcHXkiWPlcq60TMsGNflbB1+mDmuLdw1TD9YwyouS/DV8CxiGVU0AVf1LRPo6NKryKnYD/PmxtVytjnNjqSDSMrOZ8e1u3FyFKUPa0C3Qh26BZnSfYZQ3JRkg4KKqh87bZnNEMOWeLaeX8cY54NPcqaFUBL/sTWDgG+v48JcDZGbbCy1WahhG+VCSM5uYnK40zakK8H9YlQGM89msWmPUqOfcOMq5pLNZ/OfrHczfEENA3RosuK8HXQPMNNmGUZ6VJNn8A6srrQlwHPg+Z5uR36mDMDfnPlgXc63mSiSkZPDVliPc37s5D/dvgYe7q7NDMgzjCl30r6KqnsAatmwUJ8WqrkzrYeBX4hJyRo74ZKtw5vhrA2hez5OfJ/YzAwAMowIpyWi098l35/85qnqvQyIqTzbOgeTjkJkCv75lbQu7C1zdnRpWeaKqLN0cxzNfRZOWYaNv6/oE1K1hEo1hVDAl6e/5Pt+yBzCKgjXPKqeUE1ZV5/x8gqBhiHPiKYfiTp/lySVbWbsrnk5NrMKZAXVN0VLDqIhK0o02P/+6iHwKfOewiMoLe86AvKGvQee7rGUXR1b/qViswpnrSUzJ5Om/teW2HqZwpmFUZJdzJTsAaHq1AylXbFnwXh9r2cXVJJlLcDgxDb86VuHMF68PoYl3dRp7m3pmhlHRXfSvpIicEpGTOY/TWGc1UxwfWhmWkQwpx6CqF7Qc7OxoyoVsm5231+6j/+s/8sn6gwBcE1TXJBrDqCSKPbMRq+hUB6xCmgB2NXfWwYEfrZ99p0DNBs6NpRzYfiSJiYu2sC3uDAODGzDUFM40jEqn2GSjqioiSy5lOugKLzsDvrjTWvY0N29ezMe/HuS55dHUrl6Ft8d1MhWaDaOSKsk1mygR6aSqfzo8mvIg5nfrZ/cHoN35k5ka55wrnNm6YU1GhPoxdVgbalc3w5kNo7IqMtmIiJuqZgPXAn8XkX1AKtYkLaqqnUopxrLDboePh1vL9ds4N5YyKjUjm1e+3YW7q/Dk0LamcKZhGEDxZzZRQCdgZCnFUk4ohNwEHW9zdiBlzrrd8UxevJUjSWe5o0ez3LMbwzCM4pKNAKjqvlKKpWzb8gUc32otezcH80c0V1JaFs99Hc3CjbEE1rMKZ3ZpZgpnGoaRp7hkU09EHi1qp6q+5oB4yq6vH7XK0rhXh3qtnB1NmZKQmsE3W4/yQJ/mPBhhCmcahnGh4pKNK+BJzhlOpad2a1DAwBecHUmZcCI5nS83H+GeXoG5hTPrmHpmhmEUobhkc1RVny21SMqyNdOtsxoDVWXRn3E8tzyas1k2Ito0IKBuDZNoDMMo1kWv2RjA729bP5v3c24cThZzMo0pS7by054EwprW4cUbTOFMwzBKprhkE1FqUZR1Lm7Q5R4IqrwfSbbNzs3v/8ap1EyeGxHMuG5NcTGFMw3DKKEik42qnizNQIyy6WBCKo29q+Pm6sLLo63Cmf51TD0zwzAujSlXfDEbPoS0RGdHUeqybHZmrdnLgNfX5RbO7Nm8rkk0hmFclsuZYqBy+fFl62eTHs6NoxRti0viiYVbiD56hqHtGzEsxNfZIRmGUc6ZZFOU7Uut6s7pSdDxVmg/2tkRlYqPfjnA81/vwLtGFd65tTOD2jV0dkiGYVQAJtkUZtdK+OIOa7lGffALc248peBcaZlgXy+u7+jHv4e2xau6u7PDMgyjgjDJJj9VyDoLa6db6xFPQa8iiyhUCCkZ2by8cidVXF3497C2dA3wpmuAKTVjGMbVZZJNfssfho1zrOVWQyp8olm76wRPLtnGkaSzjL8mwBTONAzDYUyyOSduo5VovJpAl7shqL+zI3KYU6mZPPd1NIv/jCOovicL7+9J56Z1nB2WYRgVmEk256ybYf0M6gfXPuzcWBzsVFomq7Yf58F+QfyzXxBV3UzhTMMwHMuh99mIyCAR2SUie0VkUiH7HxWRaBHZIiKrRaSpI+Mplt0GjULhb286LQRHOnEmnffW7UNVCaznyS8T+/HogFYm0RiGUSoclmxExBWYBQwG2gI3i0jb85ptAsJUNQRYCLzsqHgqK1VlwR8xRLz2I6+u2s3BxDQAM9LMMIxS5chutK7AXlXdDyAikcAIIPpcA1Vdk6/9b8CtDoyn0ok5mcbkxVv5eW8CXQO8/7+9u4+Oqr7zOP7+AvL8YHlSnkJAUALyIETEeqoiYhGPoECFigIeuqyoMFzG5QAAEEtJREFU61bWVnrc49NayuqiaMVFVFTYqihWxQKHtRZFKURYUBAEg4AQREEEBAQM5Lt/3EsdQzATkjuTmfm8zsmZmXt/M/f7myTzze/eX74/Jg7qrMKZIpIUUSabFsDWmMcFwHk/0n40ML+kHWY2BhgDkJWVVVHxpbVjhTP3fFvI/VedzbU9s1Q4U0SSJspkU9Inm5fY0Ow6IBe4qKT97j4NmAaQm5tb4muUy6cLIX8BNOta4S+daJu+OkBWWDjzwSFdad2oNs1PrZXssEQkw0U5QaAAaBXzuCXwefFGZnYpcCcwwN0PRxjPiS2fHtym8Ho1hUeL+ONb+fz84UU89/fNAJx/RiMlGhGpFKIc2SwD2ptZG2AbMAy4NraBmZ0DPAH0c/cdEcZyYitmwsdzoEkHuPSepIRQXqsK9vDb2atY98U+ruzanAHdVDhTRCqXyJKNux8xs1uABUBVYLq7rzGz+4Dl7j4HeBCoC7wc/uf6FncfEFVMJdq0KLg9/5aEHraiTH9vE/fPXUuTejV4ckQufTueluyQRESOE+k/dbr7PGBesW13xdyvHP+m/5M20P36ZEdRJsdKy3Rp2YCh57Zi/OU5NKil6cwiUjmpgkCK2XeokInz11GjWlXuurIjudkNyc1W4UwRqdwye6XOneth9UvgRcmOJC4L1+3gsocX8cL7W6hW1XCv+Il5IiJRyNyRzdcbYUrP4H7T4oUNKpevD3zHfW+s4bUPPufM0+ry+PCfck6WCmeKSOrI3GST90Rwm/0zuPbF5MZSir0HC3nr4x38a5/23Ny7HdWrZfaAVERST+Ymm6KjUKM+jHwj2ZGU6Iu9h3jtg23884VtadO4Du+Nv0QTAEQkZWVmsikqgl35gEElWyzM3Xlx2VYmzP2YwqIi+nU6nezGdZRoRCSlZWayee8h2Pg21G+R7Eh+4LNdBxj/ymqWbNxFr7YNmTioC9kqnCkiaSAzk83B3cHttbOSG0eMI0eLuPbJPPYeLGTC1Z0Zdm4rFc4UkbSRmckGoHpdOL1zsqPg0537aR0Wzpx0TVA4s1kD1TMTkfSiaU1J8t2RIib/9RP6TV7EjCWfAdCrbSMlGhFJS5k7skmiD7bu4Y7Zq1j/5T4GdmvOVedUrmtHIiIVTckmwZ5+bxO/n7uWpvVq8vTIXPrkqHCmiKQ/JZsEOVY4s1urBgzrmcX4yztQv6amM4tIZlCyidg3hwr5w7x11DylCndf2YkerRvSo7UKZ4pIZsmsCQJHC2Heb2HJYwkpvvnXtV/S96F3mLVsC9WrVVHhTBHJWJk1sln2FLwf1kQbOCWyw+zaf5h731jLnA8/p8Pp9Zh2fS5dW50a2fFERCq7zEo2h/cFtzcthaY5kR1m36EjLFy/g9suPZOxF5+hwpkikvEyK9kc0/jMCn/Jz/cc5NWV27jp4jPIblyHxeMv0QQAEZFQZiabClRU5Dz//hYmzl/H0SLnis7NyG5cR4lGRCSGkk05bPrqAONfWUXepq+5oF0j/nB1F7Ia1U52WCIilU5mJZtvd1XYSx05WsR1T+XxzaFCHhjchV/ktsQq2XIFIiKVReYkm1UvQd7Ucr/Mhh37yG5Uh2pVq/Dw0G60blSb0+rXrIAARUTSV+ZMk9q3Pbgd+j9QpWqZn374yFEeevMT+k1+l+fCwpk92zRUohERiUPmjGyOOeOSMj9lxZbd3DF7Ffk79jPonBYMUuFMEZEyybxkU0ZPLtrIhPkf06x+TZ654Vx6n9U02SGJiKQcJZsTKCpyqlQxurc+leHnZXFHvw7U03RmEZGTomRTzN6Dhfx+7lpqnVKVeweercKZIiIVIHMmCMRhwZov6PvQO7yyYht1alRT4UwRkQqikQ3w1f7D3P36Guau3k7HZvWZPupczm7RINlhiYikDSUbYP+hI7ybv5Pf/PwsxlzYllOqasAnIlKRMjbZbNtzkFdXFHBz73ZkN67D33/Xh7o1MvbtEBGJVKR/wptZPzNbb2YbzGx8CftrmNmscH+emWVHGQ8Es8xmLtnMZQ+9w5SFn/LZrm8BlGhERCIU2SesmVUFpgB9gQJgmZnNcfe1Mc1GA7vdvZ2ZDQP+ExgaVUwAI6cv490t3/Kz9o2ZcHVnWjVU4UwRkahF+ed8T2CDu28EMLMXgYFAbLIZCNwT3p8NPGZm5hFMAzta5FQFPtnxDQ8O6c6QHiqcKSKSKFEmmxbA1pjHBcB5J2rj7kfMbC/QCPgqtpGZjQHGAGRlZZ1UMFWbtOfr1pfzxsCLaNpQSzSLiCRSlNdsSho2FB+xxNMGd5/m7rnuntukSZOTi6bDFTS84UUOH9hH7969ycnJoVOnTjzyyCPHB+DOrbfeSrt27ejSpQsrVqw4uWOKiAgQ7cimAGgV87gl8PkJ2hSYWTWgAfB1hDFRrVo1Jk2aRPfu3dm3bx89evSgb9++dOzY8R9t5s+fT35+Pvn5+eTl5TF27Fjy8vKiDEtEJK1FObJZBrQ3szZmVh0YBswp1mYOMDK8PwT4WxTXa2I1a9aM7t27A1CvXj1ycnLYtm3bD9q8/vrrjBgxAjOjV69e7Nmzh+3bt0cZlohIWoss2bj7EeAWYAHwMfCSu68xs/vMbEDY7GmgkZltAMYBx02PjtLmzZtZuXIl5533w0tJ27Zto1Wr7wdlLVu2PC4hiYhI/CL95xJ3nwfMK7btrpj7h4BfRBnDiezfv5/BgwczefJk6tev/4N9JQ2uNHNNROTkZWRdlsLCQgYPHszw4cMZNGjQcftbtmzJ1q3fT6QrKCigefPmiQxRRCStZFyycXdGjx5NTk4O48aNK7HNgAEDmDFjBu7O0qVLadCgAc2aNUtwpCIi6SPjarQsXryYmTNn0rlzZ7p16wbAhAkT2LJlCwA33ngj/fv3Z968ebRr147atWvzzDPPJDNkEZGUZ6m2Zktubq4vX7482WGIiKQUM/s/d89N2vFTLdmY2U7gs5N8emOKVSfIAOpzZlCfM0N5+tza3U/yv+LLL+WSTXmY2fJkZvZkUJ8zg/qcGVK5zxk3QUBERBJPyUZERCKXaclmWrIDSAL1OTOoz5khZfucUddsREQkOTJtZCMiIkmgZCMiIpFLy2RjZv3MbL2ZbTCz4ypJm1kNM5sV7s8zs+zER1mx4ujzODNba2arzOwtM2udjDgrUml9jmk3xMzczFJyymisePpsZteE3+s1ZvZ8omOsaHH8bGeZ2UIzWxn+fPdPRpwVxcymm9kOM/voBPvNzB4N349VZtY90TGeFHdPqy+gKvAp0BaoDnwIdCzW5iZganh/GDAr2XEnoM+9gdrh/bGZ0OewXT1gEbAUyE123An4PrcHVgI/CR83TXbcCejzNGBseL8jsDnZcZezzxcC3YGPTrC/PzCfYKXjXkBesmOO5ysdRzY9gQ3uvtHdvwNeBAYWazMQeC68PxvoY6m9hkCpfXb3he7+bfhwKcHKqaksnu8zwH8ADwCHEhlcROLp8z8BU9x9N4C770hwjBUtnj47cGydkAYcvyJwSnH3Rfz4isUDgRkeWAqcamaVvlJwOiabFsDWmMcF4bYS23iwyNteoFFCootGPH2ONZrgL6NUVmqfzewcoJW7/yWRgUUonu/zmcCZZrbYzJaaWb+ERReNePp8D3CdmRUQrJ/1L4kJLWnK+vteKaRj1eeSRijF53fH0yaVxN0fM7sOyAUuijSi6P1on82sCvAwMCpRASVAPN/nagSn0i4mGL2+a2Znu/ueiGOLSjx9/iXwrLtPMrPzgZlhn4uiDy8pUvLzKx1HNgVAq5jHLTl+WP2PNmZWjWDo/WPD1sounj5jZpcCdwID3P1wgmKLSml9rgecDbxtZpsJzm3PSfFJAvH+bL/u7oXuvglYT5B8UlU8fR4NvATg7kuAmgQFK9NVXL/vlU06JptlQHsza2Nm1QkmAMwp1mYOMDK8PwT4m4dX3lJUqX0OTyk9QZBoUv08PpTSZ3ff6+6N3T3b3bMJrlMNcPdUXp8inp/t1wgmg2BmjQlOq21MaJQVK54+bwH6AJhZDkGy2ZnQKBNrDjAinJXWC9jr7tuTHVRp0u40mrsfMbNbgAUEM1mmu/saM7sPWO7uc4CnCYbaGwhGNMOSF3H5xdnnB4G6wMvhXIgt7j4gaUGXU5x9Titx9nkBcJmZrQWOAr9x913Ji7p84uzzvwFPmtltBKeTRqXyH49m9gLBadDG4XWou4FTANx9KsF1qf7ABuBb4IbkRFo2KlcjIiKRS8fTaCIiUsko2YiISOSUbEREJHJKNiIiEjklGxERiZySjVQ6ZnbUzD6I+cr+kbbZJ6qOW8Zjvh1WFv4wLPVy1km8xo1mNiK8P8rMmsfse8rMOlZwnMvMrFscz/m1mdUu77FFykPJRiqjg+7eLeZrc4KOO9zduxIUaX2wrE9296nuPiN8OApoHrPvV+6+tkKi/D7Ox4kvzl8DSjaSVEo2khLCEcy7ZrYi/PppCW06mdn74WholZm1D7dfF7P9CTOrWsrhFgHtwuf2CddJWR2uM1Ij3D7Rvl8f6L/CbfeY2e1mNoSg/tyfwmPWCkckuWY21sweiIl5lJn98STjXEJMAUYz+28zW27BOjb3httuJUh6C81sYbjtMjNbEr6PL5tZ3VKOI1JuSjZSGdWKOYX2arhtB9DX3bsDQ4FHS3jejcAj7t6N4MO+ICxfMhS4INx+FBheyvGvBFabWU3gWWCou3cmqLgx1swaAlcDndy9C3B/7JPdfTawnGAE0s3dD8bsng0Mink8FJh1knH2IyhPc8yd7p4LdAEuMrMu7v4oQd2s3u7eOyxh8+/ApeF7uRwYV8pxRMot7crVSFo4GH7gxjoFeCy8RnGUoOZXcUuAO82sJfBnd883sz5AD2BZWKanFkHiKsmfzOwgsJmgTP1ZwCZ3/yTc/xxwM/AYwfo4T5nZXCDuJQzcfaeZbQxrWuWHx1gcvm5Z4qxDUL4ldpXGa8xsDMHvdTOChcRWFXtur3D74vA41QneN5FIKdlIqrgN+BLoSjAiP24xNHd/3szygCuABWb2K4Jy7M+5++/iOMbw2EKdZlbiGkdhva6eBMUfhwG3AJeUoS+zgGuAdcCr7u4WfPLHHSfBipUTgSnAIDNrA9wOnOvuu83sWYKClMUZ8Ka7/7IM8YqUm06jSapoAGwP1yi5nuCv+h8ws7bAxvDU0RyC00lvAUPMrGnYpqGZtY7zmOuAbDNrFz6+HngnvMbRwN3nEVx8L2lG2D6CZQ5K8mfgKoJ1WGaF28oUp7sXEpwO6xWegqsPHAD2mtlpwOUniGUpcMGxPplZbTMraZQoUqGUbCRVPA6MNLOlBKfQDpTQZijwkZl9AHQgWDp3LcGH8v+a2SrgTYJTTKVy90MEFXVfNrPVQBEwleCD+y/h671DMOoq7llg6rEJAsVedzewFmjt7u+H28ocZ3gtaBJwu7t/CKwE1gDTCU7NHTMNmG9mC919J8FMuRfC4ywleK9EIqWqzyIiEjmNbEREJHJKNiIiEjklGxERiZySjYiIRE7JRkREIqdkIyIikVOyERGRyP0/2vetCeXnJ/QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6532798484755735\n",
      "precision_score:\n",
      "0.6599532507066753\n",
      "accuracy_score:\n",
      "0.6746323529411765\n",
      "Confusion Matrix:\n",
      "[[232  82]\n",
      " [272 502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.74      0.57       314\n",
      "           1       0.86      0.65      0.74       774\n",
      "\n",
      "    accuracy                           0.67      1088\n",
      "   macro avg       0.66      0.69      0.65      1088\n",
      "weighted avg       0.74      0.67      0.69      1088\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6532798484755735,\n",
       " 0.6599532507066753,\n",
       " 0.6746323529411765,\n",
       " 0.7490351223687025)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_roc(y_test1, probs_nn, 'MLPClassifier')\n",
    "\n",
    "matrix_info(0.53, y_test1, probs_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "svc = LinearSVC(C = 5, loss = 'hinge', max_iter=10000)\n",
    "svc = CalibratedClassifierCV(svc)\n",
    "svc.fit(x_train1,y_train1)\n",
    "now = time.time()\n",
    "print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "\n",
    "probs_svm = svc.predict_proba(x_test1)[:,1]\n",
    "#probs_svm = svc.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(tpr - fpr) w/ th =  0.7193137849669783\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6822311368866025\n",
      "precision_score:\n",
      "0.683566894238831\n",
      "accuracy_score:\n",
      "0.7049632352941176\n",
      "Confusion Matrix:\n",
      "[[238  76]\n",
      " [245 529]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.76      0.60       314\n",
      "           1       0.87      0.68      0.77       774\n",
      "\n",
      "    accuracy                           0.70      1088\n",
      "   macro avg       0.68      0.72      0.68      1088\n",
      "weighted avg       0.76      0.70      0.72      1088\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6822311368866025, 0.683566894238831, 0.7049632352941176, 0.7829909972185192)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_roc(y_test1, probs_svm, 'SVM')\n",
    "\n",
    "matrix_info(0.4135, y_test1, probs_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  30 | elapsed:   52.3s remaining:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:   55.9s remaining:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  30 | elapsed:  1.2min remaining:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  1.3min remaining:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  30 | elapsed:  1.4min remaining:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.7min remaining:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.9min finished\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=10000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [1, 3, 5], 'loss': ['hinge', 'squared_hinge'],\n",
       "                         'max_iter': [10000]},\n",
       "             pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "             return_train_score=False, scoring='accuracy', verbose=20)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [1,3,5],\n",
    "    'loss':['hinge','squared_hinge'],\n",
    "    'max_iter': [10000]\n",
    "}\n",
    "\n",
    "svc = LinearSVC(max_iter=10000)\n",
    "cv = GridSearchCV(svc, param_grid=params, scoring='accuracy', n_jobs=-1, verbose=20, refit='accuracy', cv=5)\n",
    "cv.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 5, 'loss': 'hinge', 'max_iter': 10000}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59.361901</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 3, 'loss': 'squared_hinge', 'max_iter': ...</td>\n",
       "      <td>0.739380</td>\n",
       "      <td>0.737084</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.739080</td>\n",
       "      <td>0.755172</td>\n",
       "      <td>0.747243</td>\n",
       "      <td>0.011211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.138992</td>\n",
       "      <td>0.213413</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>5</td>\n",
       "      <td>hinge</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 5, 'loss': 'hinge', 'max_iter': 10000}</td>\n",
       "      <td>0.739380</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.756322</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.749425</td>\n",
       "      <td>0.747243</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>42.481627</td>\n",
       "      <td>5.296950</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 5, 'loss': 'squared_hinge', 'max_iter': ...</td>\n",
       "      <td>0.739380</td>\n",
       "      <td>0.738232</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>0.739080</td>\n",
       "      <td>0.755172</td>\n",
       "      <td>0.747243</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32.855332</td>\n",
       "      <td>8.214355</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 1, 'loss': 'squared_hinge', 'max_iter': ...</td>\n",
       "      <td>0.739380</td>\n",
       "      <td>0.738232</td>\n",
       "      <td>0.763218</td>\n",
       "      <td>0.739080</td>\n",
       "      <td>0.755172</td>\n",
       "      <td>0.747013</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.680700</td>\n",
       "      <td>0.599281</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>3</td>\n",
       "      <td>hinge</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 3, 'loss': 'hinge', 'max_iter': 10000}</td>\n",
       "      <td>0.743972</td>\n",
       "      <td>0.743972</td>\n",
       "      <td>0.754023</td>\n",
       "      <td>0.745977</td>\n",
       "      <td>0.745977</td>\n",
       "      <td>0.746783</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.468918</td>\n",
       "      <td>0.170807</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'C': 1, 'loss': 'hinge', 'max_iter': 10000}</td>\n",
       "      <td>0.740528</td>\n",
       "      <td>0.743972</td>\n",
       "      <td>0.755172</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.743678</td>\n",
       "      <td>0.745634</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "3      59.361901      0.832500         0.001197        0.000978       3   \n",
       "4      10.138992      0.213413         0.005599        0.002582       5   \n",
       "5      42.481627      5.296950         0.001404        0.000484       5   \n",
       "1      32.855332      8.214355         0.001523        0.000774       1   \n",
       "2       7.680700      0.599281         0.002821        0.002653       3   \n",
       "0       3.468918      0.170807         0.001398        0.000488       1   \n",
       "\n",
       "      param_loss param_max_iter  \\\n",
       "3  squared_hinge          10000   \n",
       "4          hinge          10000   \n",
       "5  squared_hinge          10000   \n",
       "1  squared_hinge          10000   \n",
       "2          hinge          10000   \n",
       "0          hinge          10000   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "3  {'C': 3, 'loss': 'squared_hinge', 'max_iter': ...           0.739380   \n",
       "4       {'C': 5, 'loss': 'hinge', 'max_iter': 10000}           0.739380   \n",
       "5  {'C': 5, 'loss': 'squared_hinge', 'max_iter': ...           0.739380   \n",
       "1  {'C': 1, 'loss': 'squared_hinge', 'max_iter': ...           0.739380   \n",
       "2       {'C': 3, 'loss': 'hinge', 'max_iter': 10000}           0.743972   \n",
       "0       {'C': 1, 'loss': 'hinge', 'max_iter': 10000}           0.740528   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.737084           0.765517           0.739080           0.755172   \n",
       "4           0.746269           0.756322           0.744828           0.749425   \n",
       "5           0.738232           0.764368           0.739080           0.755172   \n",
       "1           0.738232           0.763218           0.739080           0.755172   \n",
       "2           0.743972           0.754023           0.745977           0.745977   \n",
       "0           0.743972           0.755172           0.744828           0.743678   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.747243        0.011211                1  \n",
       "4         0.747243        0.005582                1  \n",
       "5         0.747243        0.010637                1  \n",
       "1         0.747013        0.010270                4  \n",
       "2         0.746783        0.003728                5  \n",
       "0         0.745634        0.004985                6  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "print(\"best params: \", cv_results.sort_values('rank_test_score').reset_index()['params'][1])\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:  2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 237 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 239 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 242 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 243 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 247 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 253 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 254 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 255 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 262 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 263 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  5.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_sta...\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'activation': ['relu'],\n",
       "                         'alpha': array([0.1   , 0.01  , 0.001 , 0.0001]),\n",
       "                         'hidden_layer_sizes': [(10, 1), (16, 16), (10, 10),\n",
       "                                                (64, 1), (64, 64), (32, 32),\n",
       "                                                (32, 16)],\n",
       "                         'max_iter': [10000], 'solver': ['adam', 'lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=20)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'solver': ['adam','lbfgs'], \n",
    "              'activation': ['relu'],\n",
    "              'max_iter': [10000], \n",
    "              'alpha': 10.0 ** -np.arange(1, 5), \n",
    "              'hidden_layer_sizes':[(10,1),(16,16),(10,10),(64,1),(64,64),(32,32),(32,16)]}\n",
    "cv = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv = 5, verbose = 20)\n",
    "cv.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (64, 1), 'max_iter': 10000, 'solver': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>25.687581</td>\n",
       "      <td>4.223082</td>\n",
       "      <td>0.007302</td>\n",
       "      <td>3.660675e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.728211</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.732184</td>\n",
       "      <td>0.729090</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>21.868452</td>\n",
       "      <td>1.776571</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>7.967244e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.707569</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.740230</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>18.713199</td>\n",
       "      <td>4.808166</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>1.954627e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.731651</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.732184</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.724954</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>26.303027</td>\n",
       "      <td>7.800243</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>3.990414e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.735092</td>\n",
       "      <td>0.726437</td>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.726437</td>\n",
       "      <td>0.724954</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.483259</td>\n",
       "      <td>0.713659</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>3.992568e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.732798</td>\n",
       "      <td>0.739080</td>\n",
       "      <td>0.686207</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.020788</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.374847</td>\n",
       "      <td>0.276855</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>3.990653e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.713303</td>\n",
       "      <td>0.720690</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.725287</td>\n",
       "      <td>0.719439</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>24.382633</td>\n",
       "      <td>8.476643</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>1.354829e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.702982</td>\n",
       "      <td>0.728736</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.728736</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.718980</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>8.117996</td>\n",
       "      <td>0.607840</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>3.025196e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.705275</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.722989</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>9.035406</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>1.092016e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.716092</td>\n",
       "      <td>0.729885</td>\n",
       "      <td>0.713235</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>11.309465</td>\n",
       "      <td>1.736745</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>2.630431e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.714943</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.732184</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.553584</td>\n",
       "      <td>0.163739</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>8.998329e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.708716</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.709559</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.772425</td>\n",
       "      <td>0.648059</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>1.023872e-02</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.692661</td>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.722989</td>\n",
       "      <td>0.709559</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>4.695358</td>\n",
       "      <td>3.600183</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>7.688227e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.701835</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.704598</td>\n",
       "      <td>0.725287</td>\n",
       "      <td>0.709329</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.448322</td>\n",
       "      <td>0.754275</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>8.921242e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.720690</td>\n",
       "      <td>0.704598</td>\n",
       "      <td>0.708410</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>11.519149</td>\n",
       "      <td>13.509404</td>\n",
       "      <td>0.010771</td>\n",
       "      <td>6.806068e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.707950</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>6.807164</td>\n",
       "      <td>0.720099</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>1.609566e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.711009</td>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.707950</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>18.887553</td>\n",
       "      <td>3.224606</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>3.982325e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.712156</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.707950</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.379906</td>\n",
       "      <td>1.402602</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>4.059668e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.716743</td>\n",
       "      <td>0.704598</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.714943</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.776502</td>\n",
       "      <td>2.651980</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>4.693768e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706801</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.790399</td>\n",
       "      <td>0.396578</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>4.652280e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.706801</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.915771</td>\n",
       "      <td>2.095449</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>8.311829e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.722477</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.683908</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.706572</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.264333</td>\n",
       "      <td>0.499561</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>1.261389e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.698394</td>\n",
       "      <td>0.713793</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.713793</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.706342</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.989849</td>\n",
       "      <td>0.777606</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>4.249320e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.683486</td>\n",
       "      <td>0.720690</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.704598</td>\n",
       "      <td>0.705193</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>15.909182</td>\n",
       "      <td>3.532636</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>1.161930e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.682339</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.713793</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.705193</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>11.110620</td>\n",
       "      <td>1.509448</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>1.827742e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.689220</td>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.704733</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.030948</td>\n",
       "      <td>6.829717</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>3.996857e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.694954</td>\n",
       "      <td>0.742529</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.704504</td>\n",
       "      <td>0.022940</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.283285</td>\n",
       "      <td>3.243081</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>4.887529e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.704504</td>\n",
       "      <td>0.020552</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>9.058498</td>\n",
       "      <td>1.410923</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>4.259969e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.702982</td>\n",
       "      <td>0.719540</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.702665</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>16.866379</td>\n",
       "      <td>2.581560</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>4.886759e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.707569</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.702436</td>\n",
       "      <td>0.007878</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>6.676677</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>7.688978e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.719037</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.701746</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.937001</td>\n",
       "      <td>0.267672</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>3.511927e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.705747</td>\n",
       "      <td>0.701517</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.004035</td>\n",
       "      <td>0.627734</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>2.522778e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.704128</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.722989</td>\n",
       "      <td>0.701057</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.003393</td>\n",
       "      <td>0.430273</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>2.130389e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.700688</td>\n",
       "      <td>0.713793</td>\n",
       "      <td>0.691954</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.700368</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>5.769225</td>\n",
       "      <td>0.245063</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>4.834397e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.702982</td>\n",
       "      <td>0.683908</td>\n",
       "      <td>0.690805</td>\n",
       "      <td>0.713793</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.394279</td>\n",
       "      <td>0.099435</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>8.986850e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>0.714943</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.716092</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.857905</td>\n",
       "      <td>0.200436</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>5.792563e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.714450</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.670115</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.696921</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>16.784552</td>\n",
       "      <td>4.107634</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>1.321591e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.714943</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.687356</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.695772</td>\n",
       "      <td>0.012378</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>10.539870</td>\n",
       "      <td>1.107665</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>7.715140e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.690367</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.694393</td>\n",
       "      <td>0.008435</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.078503</td>\n",
       "      <td>1.787133</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>4.505012e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.689220</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.694164</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>6.885557</td>\n",
       "      <td>0.992286</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>1.016542e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.693704</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>23.082206</td>\n",
       "      <td>3.180796</td>\n",
       "      <td>0.008778</td>\n",
       "      <td>1.058206e-02</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.705747</td>\n",
       "      <td>0.693015</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.426030</td>\n",
       "      <td>0.269178</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>4.330450e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.701835</td>\n",
       "      <td>0.704598</td>\n",
       "      <td>0.674713</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.686207</td>\n",
       "      <td>0.692325</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.157181</td>\n",
       "      <td>0.982877</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>1.323559e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.673563</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.692096</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.445661</td>\n",
       "      <td>0.173226</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>1.400449e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.672018</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.690805</td>\n",
       "      <td>0.690717</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>11.336489</td>\n",
       "      <td>1.747231</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>1.321503e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.691514</td>\n",
       "      <td>0.716092</td>\n",
       "      <td>0.656322</td>\n",
       "      <td>0.691954</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.690487</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.501166</td>\n",
       "      <td>0.196570</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>4.891426e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.690257</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.356555</td>\n",
       "      <td>0.659599</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>2.777510e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.690805</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.688419</td>\n",
       "      <td>0.016554</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.409248</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>3.681750e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.698851</td>\n",
       "      <td>0.687730</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14.976625</td>\n",
       "      <td>3.012437</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>7.454737e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.674312</td>\n",
       "      <td>0.663218</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.683908</td>\n",
       "      <td>0.687040</td>\n",
       "      <td>0.018930</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>13.372593</td>\n",
       "      <td>1.309432</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>1.739725e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.669725</td>\n",
       "      <td>0.680460</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.677011</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.686121</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.426044</td>\n",
       "      <td>2.941720</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>1.620382e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.683486</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.708046</td>\n",
       "      <td>0.673563</td>\n",
       "      <td>0.684513</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>21.042969</td>\n",
       "      <td>4.957978</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>2.630157e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.674312</td>\n",
       "      <td>0.667816</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.693103</td>\n",
       "      <td>0.683134</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8.257127</td>\n",
       "      <td>1.019794</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>7.168434e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.670872</td>\n",
       "      <td>0.668966</td>\n",
       "      <td>0.688506</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.683908</td>\n",
       "      <td>0.681756</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>4.187155</td>\n",
       "      <td>2.336362</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>3.052021e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.666284</td>\n",
       "      <td>0.674713</td>\n",
       "      <td>0.685057</td>\n",
       "      <td>0.680460</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.681526</td>\n",
       "      <td>0.011642</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>4.054535</td>\n",
       "      <td>1.069834</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>3.957463e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.680046</td>\n",
       "      <td>0.673563</td>\n",
       "      <td>0.670115</td>\n",
       "      <td>0.671264</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.678309</td>\n",
       "      <td>0.009746</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.568589</td>\n",
       "      <td>1.987813</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>7.986079e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.675459</td>\n",
       "      <td>0.690805</td>\n",
       "      <td>0.659770</td>\n",
       "      <td>0.673563</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "48      25.687581      4.223082         0.007302    3.660675e-03   \n",
       "8       21.868452      1.776571         0.007581    7.967244e-04   \n",
       "20      18.713199      4.808166         0.007381    1.954627e-03   \n",
       "6       26.303027      7.800243         0.005786    3.990414e-04   \n",
       "15       2.483259      0.713659         0.002793    3.992568e-04   \n",
       "9        3.374847      0.276855         0.008178    3.990653e-04   \n",
       "34      24.382633      8.476643         0.006584    1.354829e-03   \n",
       "22       8.117996      0.607840         0.009974    3.025196e-03   \n",
       "50       9.035406      0.570909         0.007978    1.092016e-03   \n",
       "14      11.309465      1.736745         0.003790    2.630431e-03   \n",
       "41       1.553584      0.163739         0.011371    8.998329e-03   \n",
       "37       3.772425      0.648059         0.015911    1.023872e-02   \n",
       "21       4.695358      3.600183         0.009575    7.688227e-03   \n",
       "43       1.448322      0.754275         0.003990    8.921242e-04   \n",
       "7       11.519149     13.509404         0.010771    6.806068e-03   \n",
       "52       6.807164      0.720099         0.005214    1.609566e-03   \n",
       "10      18.887553      3.224606         0.004189    3.982325e-04   \n",
       "40       9.379906      1.402602         0.007182    4.059668e-03   \n",
       "49       1.776502      2.651980         0.012170    4.693768e-03   \n",
       "23       2.790399      0.396578         0.009774    4.652280e-03   \n",
       "35       2.915771      2.095449         0.012366    8.311829e-03   \n",
       "13       2.264333      0.499561         0.004987    1.261389e-03   \n",
       "29       2.989849      0.777606         0.007781    4.249320e-03   \n",
       "42      15.909182      3.532636         0.003191    1.161930e-03   \n",
       "36      11.110620      1.509448         0.009175    1.827742e-03   \n",
       "1        8.030948      6.829717         0.002792    3.996857e-04   \n",
       "0       13.283285      3.243081         0.002593    4.887529e-04   \n",
       "38       9.058498      1.410923         0.007579    4.259969e-03   \n",
       "12      16.866379      2.581560         0.003590    4.886759e-04   \n",
       "24       6.676677      0.789272         0.008576    7.688978e-03   \n",
       "51       2.937001      0.267672         0.009974    3.511927e-03   \n",
       "27       2.004035      0.627734         0.005984    2.522778e-03   \n",
       "11       2.003393      0.430273         0.005784    2.130389e-03   \n",
       "54       5.769225      0.245063         0.002401    4.834397e-04   \n",
       "25       1.394279      0.099435         0.008976    8.986850e-03   \n",
       "39       1.857905      0.200436         0.009774    5.792563e-03   \n",
       "28      16.784552      4.107634         0.004290    1.321591e-03   \n",
       "44      10.539870      1.107665         0.007582    7.715140e-03   \n",
       "2       10.078503      1.787133         0.004986    4.505012e-03   \n",
       "26       6.885557      0.992286         0.004388    1.016542e-03   \n",
       "32      23.082206      3.180796         0.008778    1.058206e-02   \n",
       "17       1.426030      0.269178         0.006991    4.330450e-03   \n",
       "45       2.157181      0.982877         0.004786    1.323559e-03   \n",
       "55       1.445661      0.173226         0.005130    1.400449e-03   \n",
       "30      11.336489      1.747231         0.004785    1.321503e-03   \n",
       "3        1.501166      0.196570         0.003391    4.891426e-04   \n",
       "31       2.356555      0.659599         0.006779    2.777510e-03   \n",
       "53       1.409248      0.115388         0.006828    3.681750e-03   \n",
       "4       14.976625      3.012437         0.002792    7.454737e-04   \n",
       "18      13.372593      1.309432         0.003590    1.739725e-03   \n",
       "5        5.426044      2.941720         0.002593    1.620382e-03   \n",
       "46      21.042969      4.957978         0.004787    2.630157e-03   \n",
       "16       8.257127      1.019794         0.002992    7.168434e-07   \n",
       "47       4.187155      2.336362         0.006185    3.052021e-03   \n",
       "33       4.054535      1.069834         0.008176    3.957463e-03   \n",
       "19       3.568589      1.987813         0.003391    7.986079e-04   \n",
       "\n",
       "   param_activation param_alpha param_hidden_layer_sizes param_max_iter  \\\n",
       "48             relu      0.0001                  (64, 1)          10000   \n",
       "8              relu         0.1                 (64, 64)          10000   \n",
       "20             relu        0.01                  (64, 1)          10000   \n",
       "6              relu         0.1                  (64, 1)          10000   \n",
       "15             relu        0.01                  (10, 1)          10000   \n",
       "9              relu         0.1                 (64, 64)          10000   \n",
       "34             relu       0.001                  (64, 1)          10000   \n",
       "22             relu        0.01                 (64, 64)          10000   \n",
       "50             relu      0.0001                 (64, 64)          10000   \n",
       "14             relu        0.01                  (10, 1)          10000   \n",
       "41             relu       0.001                 (32, 16)          10000   \n",
       "37             relu       0.001                 (64, 64)          10000   \n",
       "21             relu        0.01                  (64, 1)          10000   \n",
       "43             relu      0.0001                  (10, 1)          10000   \n",
       "7              relu         0.1                  (64, 1)          10000   \n",
       "52             relu      0.0001                 (32, 32)          10000   \n",
       "10             relu         0.1                 (32, 32)          10000   \n",
       "40             relu       0.001                 (32, 16)          10000   \n",
       "49             relu      0.0001                  (64, 1)          10000   \n",
       "23             relu        0.01                 (64, 64)          10000   \n",
       "35             relu       0.001                  (64, 1)          10000   \n",
       "13             relu         0.1                 (32, 16)          10000   \n",
       "29             relu       0.001                  (10, 1)          10000   \n",
       "42             relu      0.0001                  (10, 1)          10000   \n",
       "36             relu       0.001                 (64, 64)          10000   \n",
       "1              relu         0.1                  (10, 1)          10000   \n",
       "0              relu         0.1                  (10, 1)          10000   \n",
       "38             relu       0.001                 (32, 32)          10000   \n",
       "12             relu         0.1                 (32, 16)          10000   \n",
       "24             relu        0.01                 (32, 32)          10000   \n",
       "51             relu      0.0001                 (64, 64)          10000   \n",
       "27             relu        0.01                 (32, 16)          10000   \n",
       "11             relu         0.1                 (32, 32)          10000   \n",
       "54             relu      0.0001                 (32, 16)          10000   \n",
       "25             relu        0.01                 (32, 32)          10000   \n",
       "39             relu       0.001                 (32, 32)          10000   \n",
       "28             relu       0.001                  (10, 1)          10000   \n",
       "44             relu      0.0001                 (16, 16)          10000   \n",
       "2              relu         0.1                 (16, 16)          10000   \n",
       "26             relu        0.01                 (32, 16)          10000   \n",
       "32             relu       0.001                 (10, 10)          10000   \n",
       "17             relu        0.01                 (16, 16)          10000   \n",
       "45             relu      0.0001                 (16, 16)          10000   \n",
       "55             relu      0.0001                 (32, 16)          10000   \n",
       "30             relu       0.001                 (16, 16)          10000   \n",
       "3              relu         0.1                 (16, 16)          10000   \n",
       "31             relu       0.001                 (16, 16)          10000   \n",
       "53             relu      0.0001                 (32, 32)          10000   \n",
       "4              relu         0.1                 (10, 10)          10000   \n",
       "18             relu        0.01                 (10, 10)          10000   \n",
       "5              relu         0.1                 (10, 10)          10000   \n",
       "46             relu      0.0001                 (10, 10)          10000   \n",
       "16             relu        0.01                 (16, 16)          10000   \n",
       "47             relu      0.0001                 (10, 10)          10000   \n",
       "33             relu       0.001                 (10, 10)          10000   \n",
       "19             relu        0.01                 (10, 10)          10000   \n",
       "\n",
       "   param_solver                                             params  \\\n",
       "48         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "8          adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "20         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "6          adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "15        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "9         lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "34         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "22         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "50         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "14         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "41        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "37        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "21        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "43        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "7         lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "52         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "10         adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "40         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "49        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "23        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "35        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "13        lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "29        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "42         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "36         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "1         lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "0          adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "38         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "12         adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "24         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "51        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "27        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "11        lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "54         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "25        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "39        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "28         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "44         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "2          adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "26         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "32         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "17        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "45        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "55        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "30         adam  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "3         lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "31        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "53        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "4          adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "18         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "5         lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "46         adam  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "16         adam  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "47        lbfgs  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "33        lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "19        lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "48           0.728211           0.724138           0.729885   \n",
       "8            0.707569           0.734483           0.719540   \n",
       "20           0.731651           0.727586           0.700000   \n",
       "6            0.735092           0.726437           0.709195   \n",
       "15           0.732798           0.739080           0.686207   \n",
       "9            0.713303           0.720690           0.706897   \n",
       "34           0.702982           0.728736           0.698851   \n",
       "22           0.705275           0.703448           0.722989   \n",
       "50           0.709862           0.708046           0.702299   \n",
       "14           0.706422           0.685057           0.714943   \n",
       "41           0.708716           0.710345           0.693103   \n",
       "37           0.692661           0.709195           0.711494   \n",
       "21           0.701835           0.706897           0.708046   \n",
       "43           0.706422           0.712644           0.697701   \n",
       "7            0.706422           0.711494           0.708046   \n",
       "52           0.711009           0.709195           0.688506   \n",
       "10           0.712156           0.712644           0.700000   \n",
       "40           0.716743           0.704598           0.697701   \n",
       "49           0.706422           0.706897           0.706897   \n",
       "23           0.693807           0.724138           0.702299   \n",
       "35           0.722477           0.712644           0.683908   \n",
       "13           0.698394           0.713793           0.697701   \n",
       "29           0.683486           0.720690           0.698851   \n",
       "42           0.682339           0.702299           0.713793   \n",
       "36           0.689220           0.709195           0.698851   \n",
       "1            0.694954           0.742529           0.681609   \n",
       "0            0.693807           0.701149           0.688506   \n",
       "38           0.702982           0.719540           0.672414   \n",
       "12           0.707569           0.708046           0.688506   \n",
       "24           0.719037           0.697701           0.697701   \n",
       "51           0.699541           0.709195           0.682759   \n",
       "27           0.704128           0.694253           0.672414   \n",
       "11           0.700688           0.713793           0.691954   \n",
       "54           0.702982           0.683908           0.690805   \n",
       "25           0.693807           0.714943           0.667816   \n",
       "39           0.714450           0.694253           0.670115   \n",
       "28           0.678899           0.714943           0.702299   \n",
       "44           0.690367           0.698851           0.681609   \n",
       "2            0.689220           0.724138           0.678161   \n",
       "26           0.699541           0.696552           0.681609   \n",
       "32           0.669725           0.711494           0.675862   \n",
       "17           0.701835           0.704598           0.674713   \n",
       "45           0.693807           0.697701           0.673563   \n",
       "55           0.672018           0.698851           0.689655   \n",
       "30           0.691514           0.716092           0.656322   \n",
       "3            0.688073           0.698851           0.671264   \n",
       "31           0.669725           0.685057           0.690805   \n",
       "53           0.688073           0.694253           0.668966   \n",
       "4            0.674312           0.663218           0.718391   \n",
       "18           0.669725           0.680460           0.695402   \n",
       "5            0.683486           0.688506           0.668966   \n",
       "46           0.674312           0.667816           0.695402   \n",
       "16           0.670872           0.668966           0.688506   \n",
       "47           0.666284           0.674713           0.685057   \n",
       "33           0.680046           0.673563           0.670115   \n",
       "19           0.675459           0.690805           0.659770   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "48           0.731034           0.732184         0.729090        0.002802   \n",
       "8            0.729885           0.740230         0.726333        0.011584   \n",
       "20           0.732184           0.733333         0.724954        0.012623   \n",
       "6            0.727586           0.726437         0.724954        0.008515   \n",
       "15           0.706897           0.737931         0.720588        0.020788   \n",
       "9            0.731034           0.725287         0.719439        0.008545   \n",
       "34           0.728736           0.735632         0.718980        0.015026   \n",
       "22           0.729885           0.712644         0.714844        0.010186   \n",
       "50           0.716092           0.729885         0.713235        0.009414   \n",
       "14           0.712644           0.732184         0.710248        0.015216   \n",
       "41           0.717241           0.718391         0.709559        0.009044   \n",
       "37           0.711494           0.722989         0.709559        0.009736   \n",
       "21           0.704598           0.725287         0.709329        0.008255   \n",
       "43           0.720690           0.704598         0.708410        0.007769   \n",
       "7            0.706897           0.706897         0.707950        0.001851   \n",
       "52           0.718391           0.712644         0.707950        0.010196   \n",
       "10           0.693103           0.721839         0.707950        0.010159   \n",
       "40           0.701149           0.714943         0.707031        0.007544   \n",
       "49           0.706897           0.706897         0.706801        0.000190   \n",
       "23           0.701149           0.712644         0.706801        0.010544   \n",
       "35           0.706897           0.706897         0.706572        0.012680   \n",
       "13           0.713793           0.708046         0.706342        0.007096   \n",
       "29           0.718391           0.704598         0.705193        0.013614   \n",
       "42           0.717241           0.710345         0.705193        0.012467   \n",
       "36           0.695402           0.731034         0.704733        0.014656   \n",
       "1            0.718391           0.685057         0.704504        0.022940   \n",
       "0            0.744828           0.694253         0.704504        0.020552   \n",
       "38           0.718391           0.700000         0.702665        0.017051   \n",
       "12           0.698851           0.709195         0.702436        0.007878   \n",
       "24           0.693103           0.701149         0.701746        0.009025   \n",
       "51           0.710345           0.705747         0.701517        0.010103   \n",
       "27           0.711494           0.722989         0.701057        0.017120   \n",
       "11           0.710345           0.685057         0.700368        0.010815   \n",
       "54           0.713793           0.706897         0.699678        0.010858   \n",
       "25           0.700000           0.716092         0.698529        0.017578   \n",
       "39           0.711494           0.694253         0.696921        0.015828   \n",
       "28           0.687356           0.695402         0.695772        0.012378   \n",
       "44           0.706897           0.694253         0.694393        0.008435   \n",
       "2            0.694253           0.685057         0.694164        0.015883   \n",
       "26           0.697701           0.693103         0.693704        0.006400   \n",
       "32           0.702299           0.705747         0.693015        0.016894   \n",
       "17           0.694253           0.686207         0.692325        0.010884   \n",
       "45           0.688506           0.706897         0.692096        0.011041   \n",
       "55           0.702299           0.690805         0.690717        0.010504   \n",
       "30           0.691954           0.696552         0.690487        0.019298   \n",
       "3            0.693103           0.700000         0.690257        0.010413   \n",
       "31           0.678161           0.718391         0.688419        0.016554   \n",
       "53           0.688506           0.698851         0.687730        0.010186   \n",
       "4            0.695402           0.683908         0.687040        0.018930   \n",
       "18           0.677011           0.708046         0.686121        0.013791   \n",
       "5            0.708046           0.673563         0.684513        0.013653   \n",
       "46           0.685057           0.693103         0.683134        0.010639   \n",
       "16           0.696552           0.683908         0.681756        0.010499   \n",
       "47           0.680460           0.701149         0.681526        0.011642   \n",
       "33           0.671264           0.696552         0.678309        0.009746   \n",
       "19           0.673563           0.682759         0.676471        0.010326   \n",
       "\n",
       "    rank_test_score  \n",
       "48                1  \n",
       "8                 2  \n",
       "20                3  \n",
       "6                 3  \n",
       "15                5  \n",
       "9                 6  \n",
       "34                7  \n",
       "22                8  \n",
       "50                9  \n",
       "14               10  \n",
       "41               11  \n",
       "37               11  \n",
       "21               13  \n",
       "43               14  \n",
       "7                15  \n",
       "52               15  \n",
       "10               15  \n",
       "40               18  \n",
       "49               19  \n",
       "23               19  \n",
       "35               21  \n",
       "13               22  \n",
       "29               23  \n",
       "42               23  \n",
       "36               25  \n",
       "1                26  \n",
       "0                26  \n",
       "38               28  \n",
       "12               29  \n",
       "24               30  \n",
       "51               31  \n",
       "27               32  \n",
       "11               33  \n",
       "54               34  \n",
       "25               35  \n",
       "39               36  \n",
       "28               37  \n",
       "44               38  \n",
       "2                39  \n",
       "26               40  \n",
       "32               41  \n",
       "17               42  \n",
       "45               43  \n",
       "55               44  \n",
       "30               45  \n",
       "3                46  \n",
       "31               47  \n",
       "53               48  \n",
       "4                49  \n",
       "18               50  \n",
       "5                51  \n",
       "46               52  \n",
       "16               53  \n",
       "47               54  \n",
       "33               55  \n",
       "19               56  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "print(\"best params: \", cv_results.sort_values('rank_test_score').reset_index()['params'][0])\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

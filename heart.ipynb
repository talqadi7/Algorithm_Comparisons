{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score, f1_score, precision_score\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/SPECT.train')\n",
    "df_test = pd.read_csv('Data/SPECT.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>1.4</th>\n",
       "      <th>...</th>\n",
       "      <th>0.7</th>\n",
       "      <th>1.6</th>\n",
       "      <th>1.7</th>\n",
       "      <th>1.8</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>1.9</th>\n",
       "      <th>1.10</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  1.1  0  0.1  1.2  1.3  0.2  0.3  0.4  1.4  ...  0.7  1.6  1.7  1.8  \\\n",
       "0    1    1  0    0    1    1    0    0    0    0  ...    1    0    0    0   \n",
       "1    1    0  0    0    1    0    1    0    0    1  ...    0    1    1    0   \n",
       "2    1    0  1    1    1    0    0    1    0    1  ...    1    1    0    1   \n",
       "3    1    0  0    1    0    0    0    0    1    0  ...    1    1    0    1   \n",
       "4    1    0  0    1    1    0    1    0    0    1  ...    1    0    0    1   \n",
       "..  ..  ... ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "181  0    0  0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "182  0    1  1    0    0    0    1    0    0    0  ...    0    0    0    1   \n",
       "183  0    1  0    1    0    1    0    0    1    0  ...    1    0    1    1   \n",
       "184  0    1  0    1    0    1    0    0    1    1  ...    0    1    0    1   \n",
       "185  0    0  0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "     0.8  0.9  1.9  1.10  0.10  0.11  \n",
       "0      0    0    0     0     0     0  \n",
       "1      0    0    0     0     0     1  \n",
       "2      0    0    0     0     1     0  \n",
       "3      0    0    0     0     0     1  \n",
       "4      0    0    0     0     1     1  \n",
       "..   ...  ...  ...   ...   ...   ...  \n",
       "181    0    0    0     0     0     0  \n",
       "182    0    0    0     0     0     0  \n",
       "183    0    0    0     0     0     0  \n",
       "184    0    0    0     0     0     0  \n",
       "185    0    0    0     0     0     0  \n",
       "\n",
       "[186 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>...</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.12</th>\n",
       "      <th>0.13</th>\n",
       "      <th>0.14</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1  0  0.1  0.2  1.1  0.3  0.4  0.5  1.2  1.3  ...  1.4  1.5  0.9  0.10  \\\n",
       "0   1  0    0    1    1    0    0    0    1    1  ...    1    1    0     0   \n",
       "1   1  1    0    1    0    1    0    0    1    0  ...    1    0    0     0   \n",
       "2   1  0    0    0    0    0    0    0    0    0  ...    0    0    0     0   \n",
       "3   1  0    0    0    0    0    0    0    1    0  ...    1    0    1     1   \n",
       "4   1  0    0    0    1    0    0    0    0    1  ...    1    1    0     1   \n",
       ".. .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "74  0  1    0    0    0    1    0    0    0    0  ...    0    0    0     0   \n",
       "75  0  1    0    0    0    1    1    0    0    1  ...    0    1    0     0   \n",
       "76  0  1    0    0    0    1    0    0    0    0  ...    0    0    0     0   \n",
       "77  0  0    0    1    1    0    0    1    0    0  ...    1    1    0     0   \n",
       "78  0  1    0    0    0    1    0    0    0    0  ...    0    0    0     0   \n",
       "\n",
       "    0.11  0.12  0.13  0.14  0.15  0.16  \n",
       "0      0     0     0     0     0     1  \n",
       "1      0     0     0     0     0     0  \n",
       "2      0     0     0     1     1     1  \n",
       "3      0     0     0     0     0     0  \n",
       "4      0     0     0     1     0     1  \n",
       "..   ...   ...   ...   ...   ...   ...  \n",
       "74     0     0     0     0     0     0  \n",
       "75     0     0     1     1     0     0  \n",
       "76     0     0     1     0     0     0  \n",
       "77     0     0     0     0     1     1  \n",
       "78     0     0     0     0     0     0  \n",
       "\n",
       "[79 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  f1  f2  f3  f4  f5  f6  f7  f8  f9  ...  f13  f14  f15  f16  f17  \\\n",
       "0         1   0   0   1   1   0   0   0   1   1  ...    1    1    0    0    0   \n",
       "1         1   1   0   1   0   1   0   0   1   0  ...    1    0    0    0    0   \n",
       "2         1   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0   \n",
       "3         1   0   0   0   0   0   0   0   1   0  ...    1    0    1    1    0   \n",
       "4         1   0   0   0   1   0   0   0   0   1  ...    1    1    0    1    0   \n",
       "..      ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "260       0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0   \n",
       "261       0   1   1   0   0   0   1   0   0   0  ...    0    0    0    1    0   \n",
       "262       0   1   0   1   0   1   0   0   1   0  ...    1    0    1    1    0   \n",
       "263       0   1   0   1   0   1   0   0   1   1  ...    0    1    0    1    0   \n",
       "264       0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0    0   \n",
       "\n",
       "     f18  f19  f20  f21  f22  \n",
       "0      0    0    0    0    1  \n",
       "1      0    0    0    0    0  \n",
       "2      0    0    1    1    1  \n",
       "3      0    0    0    0    0  \n",
       "4      0    0    1    0    1  \n",
       "..   ...  ...  ...  ...  ...  \n",
       "260    0    0    0    0    0  \n",
       "261    0    0    0    0    0  \n",
       "262    0    0    0    0    0  \n",
       "263    0    0    0    0    0  \n",
       "264    0    0    0    0    0  \n",
       "\n",
       "[265 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.vstack((df_train,df_test)), columns=df_train.columns)\n",
    "df.columns = ['target', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9',\n",
    "       'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18',\n",
    "       'f19', 'f20', 'f21', 'f22']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    210\n",
       "0     55\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    clf = ensemble.RandomForestClassifier(n_jobs = -1, n_estimators=200, random_state=42)\n",
    "    clf.fit(x_train1, y_train1)\n",
    "    probs = clf.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.6651,y_test1, probs)\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    mlp = MLPClassifier(solver='lbfgs', activation='relu', alpha=0.1, hidden_layer_sizes = (16,16), max_iter = 10000)\n",
    "    mlp.fit(x_train1, y_train1)\n",
    "    probs = mlp.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.77, y_test1, probs)\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMfunc(x_train1, x_test1, y_train1, y_test1):\n",
    "    svc = SVC(C = 0.1, degree = 2, gamma = 0.04, kernel = 'rbf', max_iter =  100000, probability = True)\n",
    "    svc.fit(x_train1, y_train1)\n",
    "    probs = svc.predict_proba(x_test1)[:,1]\n",
    "    f1, apr, acc, auc = matrix_info(0.7521,y_test1, probs)\n",
    "    return round(f1,3), round(apr,3), round(acc,3), round(auc,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df)[:,1:]\n",
    "Y_train = df['target'].values\n",
    "X_train,Y_train = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.7579908675799087\n",
      "precision_score:\n",
      "0.7446969696969697\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[11  2]\n",
      " [ 9 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.85      0.67        13\n",
      "           1       0.94      0.78      0.85        40\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.74      0.81      0.76        53\n",
      "weighted avg       0.84      0.79      0.80        53\n",
      "\n",
      "f1_score:\n",
      "0.7948387096774194\n",
      "precision_score:\n",
      "0.776984126984127\n",
      "accuracy_score:\n",
      "0.8301886792452831\n",
      "Confusion Matrix:\n",
      "[[11  2]\n",
      " [ 7 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71        13\n",
      "           1       0.94      0.82      0.88        40\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.78      0.84      0.79        53\n",
      "weighted avg       0.86      0.83      0.84        53\n",
      "\n",
      "f1_score:\n",
      "0.7401960784313726\n",
      "precision_score:\n",
      "0.7306547619047619\n",
      "accuracy_score:\n",
      "0.7735849056603774\n",
      "Confusion Matrix:\n",
      "[[11  2]\n",
      " [10 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.85      0.65        13\n",
      "           1       0.94      0.75      0.83        40\n",
      "\n",
      "    accuracy                           0.77        53\n",
      "   macro avg       0.73      0.80      0.74        53\n",
      "weighted avg       0.84      0.77      0.79        53\n",
      "\n",
      "f1_score:\n",
      "0.7644444444444445\n",
      "precision_score:\n",
      "0.8535353535353536\n",
      "accuracy_score:\n",
      "0.8301886792452831\n",
      "Confusion Matrix:\n",
      "[[ 8  8]\n",
      " [ 1 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.50      0.64        16\n",
      "           1       0.82      0.97      0.89        37\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.85      0.74      0.76        53\n",
      "weighted avg       0.84      0.83      0.81        53\n",
      "\n",
      "f1_score:\n",
      "0.736318407960199\n",
      "precision_score:\n",
      "0.7326086956521739\n",
      "accuracy_score:\n",
      "0.7547169811320755\n",
      "Confusion Matrix:\n",
      "[[13  3]\n",
      " [10 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.81      0.67        16\n",
      "           1       0.90      0.73      0.81        37\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.73      0.77      0.74        53\n",
      "weighted avg       0.80      0.75      0.76        53\n",
      "\n",
      "f1_score:\n",
      "0.8058608058608059\n",
      "precision_score:\n",
      "0.8434959349593496\n",
      "accuracy_score:\n",
      "0.8490566037735849\n",
      "Confusion Matrix:\n",
      "[[10  6]\n",
      " [ 2 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71        16\n",
      "           1       0.85      0.95      0.90        37\n",
      "\n",
      "    accuracy                           0.85        53\n",
      "   macro avg       0.84      0.79      0.81        53\n",
      "weighted avg       0.85      0.85      0.84        53\n",
      "\n",
      "f1_score:\n",
      "0.7120987654320987\n",
      "precision_score:\n",
      "0.7569767441860464\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[ 7  8]\n",
      " [ 3 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56        15\n",
      "           1       0.81      0.92      0.86        38\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.76      0.69      0.71        53\n",
      "weighted avg       0.78      0.79      0.78        53\n",
      "\n",
      "f1_score:\n",
      "0.7087912087912088\n",
      "precision_score:\n",
      "0.7201923076923077\n",
      "accuracy_score:\n",
      "0.7735849056603774\n",
      "Confusion Matrix:\n",
      "[[ 8  7]\n",
      " [ 5 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57        15\n",
      "           1       0.82      0.87      0.85        38\n",
      "\n",
      "    accuracy                           0.77        53\n",
      "   macro avg       0.72      0.70      0.71        53\n",
      "weighted avg       0.77      0.77      0.77        53\n",
      "\n",
      "f1_score:\n",
      "0.6946045049764276\n",
      "precision_score:\n",
      "0.775\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[ 6  9]\n",
      " [ 2 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.40      0.52        15\n",
      "           1       0.80      0.95      0.87        38\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.78      0.67      0.69        53\n",
      "weighted avg       0.79      0.79      0.77        53\n",
      "\n",
      "f1_score:\n",
      "0.6868421052631579\n",
      "precision_score:\n",
      "0.6834045584045584\n",
      "accuracy_score:\n",
      "0.7443609022556391\n",
      "Confusion Matrix:\n",
      "[[21  3]\n",
      " [31 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.88      0.55        24\n",
      "           1       0.96      0.72      0.82       109\n",
      "\n",
      "    accuracy                           0.74       133\n",
      "   macro avg       0.68      0.80      0.69       133\n",
      "weighted avg       0.86      0.74      0.77       133\n",
      "\n",
      "f1_score:\n",
      "0.6684210526315789\n",
      "precision_score:\n",
      "0.6676163342830009\n",
      "accuracy_score:\n",
      "0.7293233082706767\n",
      "Confusion Matrix:\n",
      "[[20  4]\n",
      " [32 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.83      0.53        24\n",
      "           1       0.95      0.71      0.81       109\n",
      "\n",
      "    accuracy                           0.73       133\n",
      "   macro avg       0.67      0.77      0.67       133\n",
      "weighted avg       0.85      0.73      0.76       133\n",
      "\n",
      "f1_score:\n",
      "0.7495291902071564\n",
      "precision_score:\n",
      "0.726530612244898\n",
      "accuracy_score:\n",
      "0.8270676691729323\n",
      "Confusion Matrix:\n",
      "[[18  6]\n",
      " [17 92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.75      0.61        24\n",
      "           1       0.94      0.84      0.89       109\n",
      "\n",
      "    accuracy                           0.83       133\n",
      "   macro avg       0.73      0.80      0.75       133\n",
      "weighted avg       0.86      0.83      0.84       133\n",
      "\n",
      "f1_score:\n",
      "0.7655502392344498\n",
      "precision_score:\n",
      "0.7511068943706515\n",
      "accuracy_score:\n",
      "0.8421052631578947\n",
      "Confusion Matrix:\n",
      "[[18  8]\n",
      " [13 94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63        26\n",
      "           1       0.92      0.88      0.90       107\n",
      "\n",
      "    accuracy                           0.84       133\n",
      "   macro avg       0.75      0.79      0.77       133\n",
      "weighted avg       0.85      0.84      0.85       133\n",
      "\n",
      "f1_score:\n",
      "0.7265970904490828\n",
      "precision_score:\n",
      "0.7087628865979381\n",
      "accuracy_score:\n",
      "0.8045112781954887\n",
      "Confusion Matrix:\n",
      "[[18  8]\n",
      " [18 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.69      0.58        26\n",
      "           1       0.92      0.83      0.87       107\n",
      "\n",
      "    accuracy                           0.80       133\n",
      "   macro avg       0.71      0.76      0.73       133\n",
      "weighted avg       0.84      0.80      0.82       133\n",
      "\n",
      "f1_score:\n",
      "0.7358199073052306\n",
      "precision_score:\n",
      "0.7164082687338501\n",
      "accuracy_score:\n",
      "0.7969924812030075\n",
      "Confusion Matrix:\n",
      "[[21  5]\n",
      " [22 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.81      0.61        26\n",
      "           1       0.94      0.79      0.86       107\n",
      "\n",
      "    accuracy                           0.80       133\n",
      "   macro avg       0.72      0.80      0.74       133\n",
      "weighted avg       0.86      0.80      0.81       133\n",
      "\n",
      "f1_score:\n",
      "0.6907672691817296\n",
      "precision_score:\n",
      "0.6775777414075286\n",
      "accuracy_score:\n",
      "0.7669172932330827\n",
      "Confusion Matrix:\n",
      "[[18 10]\n",
      " [21 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.64      0.54        28\n",
      "           1       0.89      0.80      0.84       105\n",
      "\n",
      "    accuracy                           0.77       133\n",
      "   macro avg       0.68      0.72      0.69       133\n",
      "weighted avg       0.80      0.77      0.78       133\n",
      "\n",
      "f1_score:\n",
      "0.6305555555555555\n",
      "precision_score:\n",
      "0.6502726033621081\n",
      "accuracy_score:\n",
      "0.6691729323308271\n",
      "Confusion Matrix:\n",
      "[[23  5]\n",
      " [39 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.82      0.51        28\n",
      "           1       0.93      0.63      0.75       105\n",
      "\n",
      "    accuracy                           0.67       133\n",
      "   macro avg       0.65      0.72      0.63       133\n",
      "weighted avg       0.81      0.67      0.70       133\n",
      "\n",
      "f1_score:\n",
      "0.7354111405835544\n",
      "precision_score:\n",
      "0.7299352750809062\n",
      "accuracy_score:\n",
      "0.8195488721804511\n",
      "Confusion Matrix:\n",
      "[[17 11]\n",
      " [13 92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59        28\n",
      "           1       0.89      0.88      0.88       105\n",
      "\n",
      "    accuracy                           0.82       133\n",
      "   macro avg       0.73      0.74      0.74       133\n",
      "weighted avg       0.82      0.82      0.82       133\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.690171720862258\n",
      "precision_score:\n",
      "0.6744086021505377\n",
      "accuracy_score:\n",
      "0.7735849056603774\n",
      "Confusion Matrix:\n",
      "[[ 27  13]\n",
      " [ 35 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.68      0.53        40\n",
      "           1       0.91      0.80      0.85       172\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.67      0.74      0.69       212\n",
      "weighted avg       0.82      0.77      0.79       212\n",
      "\n",
      "f1_score:\n",
      "0.6945713147166109\n",
      "precision_score:\n",
      "0.678265117793942\n",
      "accuracy_score:\n",
      "0.7783018867924528\n",
      "Confusion Matrix:\n",
      "[[ 27  13]\n",
      " [ 34 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.68      0.53        40\n",
      "           1       0.91      0.80      0.85       172\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.68      0.74      0.69       212\n",
      "weighted avg       0.82      0.78      0.79       212\n",
      "\n",
      "f1_score:\n",
      "0.7197115384615385\n",
      "precision_score:\n",
      "0.7005912162162162\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[ 30  10]\n",
      " [ 34 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.75      0.58        40\n",
      "           1       0.93      0.80      0.86       172\n",
      "\n",
      "    accuracy                           0.79       212\n",
      "   macro avg       0.70      0.78      0.72       212\n",
      "weighted avg       0.84      0.79      0.81       212\n",
      "\n",
      "f1_score:\n",
      "0.7437424452371827\n",
      "precision_score:\n",
      "0.7306414091060153\n",
      "accuracy_score:\n",
      "0.8066037735849056\n",
      "Confusion Matrix:\n",
      "[[ 33  15]\n",
      " [ 26 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62        48\n",
      "           1       0.90      0.84      0.87       164\n",
      "\n",
      "    accuracy                           0.81       212\n",
      "   macro avg       0.73      0.76      0.74       212\n",
      "weighted avg       0.82      0.81      0.81       212\n",
      "\n",
      "f1_score:\n",
      "0.7266760431317393\n",
      "precision_score:\n",
      "0.7140350877192982\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[ 32  16]\n",
      " [ 28 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59        48\n",
      "           1       0.89      0.83      0.86       164\n",
      "\n",
      "    accuracy                           0.79       212\n",
      "   macro avg       0.71      0.75      0.73       212\n",
      "weighted avg       0.81      0.79      0.80       212\n",
      "\n",
      "f1_score:\n",
      "0.6418918918918919\n",
      "precision_score:\n",
      "0.6393939393939394\n",
      "accuracy_score:\n",
      "0.6981132075471698\n",
      "Confusion Matrix:\n",
      "[[ 32  16]\n",
      " [ 48 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50        48\n",
      "           1       0.88      0.71      0.78       164\n",
      "\n",
      "    accuracy                           0.70       212\n",
      "   macro avg       0.64      0.69      0.64       212\n",
      "weighted avg       0.77      0.70      0.72       212\n",
      "\n",
      "f1_score:\n",
      "0.6893772893772894\n",
      "precision_score:\n",
      "0.6873385012919897\n",
      "accuracy_score:\n",
      "0.7358490566037735\n",
      "Confusion Matrix:\n",
      "[[ 37   7]\n",
      " [ 49 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.84      0.57        44\n",
      "           1       0.94      0.71      0.81       168\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.69      0.77      0.69       212\n",
      "weighted avg       0.84      0.74      0.76       212\n",
      "\n",
      "f1_score:\n",
      "0.6809879618098796\n",
      "precision_score:\n",
      "0.6820014662756598\n",
      "accuracy_score:\n",
      "0.7264150943396226\n",
      "Confusion Matrix:\n",
      "[[ 37   7]\n",
      " [ 51 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.84      0.56        44\n",
      "           1       0.94      0.70      0.80       168\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.68      0.77      0.68       212\n",
      "weighted avg       0.83      0.73      0.75       212\n",
      "\n",
      "f1_score:\n",
      "0.7007925306698513\n",
      "precision_score:\n",
      "0.6907768848067356\n",
      "accuracy_score:\n",
      "0.7547169811320755\n",
      "Confusion Matrix:\n",
      "[[ 35   9]\n",
      " [ 43 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.80      0.57        44\n",
      "           1       0.93      0.74      0.83       168\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.69      0.77      0.70       212\n",
      "weighted avg       0.83      0.75      0.78       212\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'now' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-604bfb6e1a6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mnow1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Elapsed Time: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'now' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = np.array(df)[:,1:]\n",
    "Y_train = df['target'].values\n",
    "X_train,Y_train = shuffle(X_train, Y_train)\n",
    "rf = np.empty([9, 7])\n",
    "mlp = np.empty([9, 7])\n",
    "svm = np.empty([9, 7])\n",
    "test_sizes = [0.2,0.5,0.8]\n",
    "j = 0\n",
    "start1 = time.time()\n",
    "for size in test_sizes:\n",
    "    for i in np.arange(3):\n",
    "        x_train1, x_test1, y_train1, y_test1 = train_test_split(X_train, Y_train, test_size=size)\n",
    "        \n",
    "        rf_time = time.time()\n",
    "        rf_f1, rf_apr, rf_acc, rf_auc = RFfunc(x_train1, x_test1, y_train1, y_test1)\n",
    "        rf_time = time.time() - rf_time\n",
    "        \n",
    "        mlp_time = time.time()\n",
    "        mlp_f1, mlp_apr, mlp_acc, mlp_auc = MLPfunc(x_train1, x_test1, y_train1, y_test1)\n",
    "        mlp_time = time.time() - mlp_time\n",
    "        \n",
    "        svm_time = time.time()\n",
    "        svm_f1, svm_apr, svm_acc, svm_auc = SVMfunc(x_train1, x_test1, y_train1, y_test1)\n",
    "        svm_time = time.time() - svm_time\n",
    "        \n",
    "        \n",
    "        rf[j] = [rf_f1, rf_apr, rf_acc, rf_auc, i, size, rf_time]\n",
    "        mlp[j] = [mlp_f1, mlp_apr, mlp_acc, mlp_auc, i, size, mlp_time]\n",
    "        svm[j] = [svm_f1, svm_apr, svm_acc, svm_auc, i, size, svm_time]\n",
    "        j = j + 1\n",
    "\n",
    "now1 = time.time()\n",
    "print('Elapsed Time: ' + str(int(now-start)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = pd.DataFrame(rf, columns = ['f1', 'apr', 'acc', 'auc', 'trial', 'test_size','time'])\n",
    "mlp_df = pd.DataFrame(mlp, columns = ['f1', 'apr', 'acc', 'auc', 'trial', 'test_size','time'])\n",
    "svm_df = pd.DataFrame(svm, columns = ['f1', 'apr', 'acc', 'auc', 'trial', 'test_size','time'])\n",
    "rf_df['avg'] = round(rf_df.drop(['trial','test_size','time'],axis=1).mean(axis=1),3).values\n",
    "mlp_df['avg'] = round(mlp_df.drop(['trial','test_size','time'],axis=1).mean(axis=1),3).values\n",
    "svm_df['avg'] = round(svm_df.drop(['trial','test_size','time'],axis=1).mean(axis=1),3).values\n",
    "mlp_mean = round(mlp_df.groupby('test_size').mean(),3).drop('trial', axis = 1)\n",
    "rf_mean = round(rf_df.groupby('test_size').mean(),3).drop('trial', axis = 1)\n",
    "svm_mean = round(svm_df.groupby('test_size').mean(),3).drop('trial', axis = 1)\n",
    "rf_mean['avg'] = round(rf_mean.drop('time',axis=1).mean(axis=1),3).values\n",
    "mlp_mean['avg'] = round(mlp_mean.drop('time',axis=1).mean(axis=1),3).values\n",
    "svm_mean['avg'] = round(svm_mean.drop('time',axis=1).mean(axis=1),3).values\n",
    "\n",
    "rf_mean['avg_std'] = round(rf_df.groupby('test_size').std(),3)['avg'].values\n",
    "mlp_mean['avg_std'] = round(mlp_df.groupby('test_size').std(),3)['avg'].values\n",
    "svm_mean['avg_std'] = round(svm_df.groupby('test_size').std(),3)['avg'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>time</th>\n",
       "      <th>avg</th>\n",
       "      <th>avg_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.220</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1    apr    acc    auc   time    avg  avg_std\n",
       "test_size                                                   \n",
       "0.2        0.747  0.743  0.786  0.761  0.698  0.759    0.040\n",
       "0.5        0.675  0.676  0.734  0.787  1.220  0.718    0.041\n",
       "0.8        0.701  0.691  0.765  0.795  0.333  0.738    0.020"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.038, 0.029, 0.03 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.698, 1.22 , 0.333])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_mean.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>time</th>\n",
       "      <th>avg</th>\n",
       "      <th>avg_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1    apr    acc    auc   time    avg  avg_std\n",
       "test_size                                                   \n",
       "0.2        0.747  0.783  0.805  0.784  0.038  0.656    0.049\n",
       "0.5        0.740  0.724  0.815  0.849  0.029  0.656    0.009\n",
       "0.8        0.688  0.677  0.748  0.769  0.030  0.605    0.053"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>time</th>\n",
       "      <th>avg</th>\n",
       "      <th>avg_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.2</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.8</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1    apr    acc    auc   time    avg  avg_std\n",
       "test_size                                                   \n",
       "0.2        0.745  0.785  0.805  0.748  0.667  0.754    0.034\n",
       "0.5        0.715  0.704  0.784  0.811  0.653  0.737    0.038\n",
       "0.8        0.708  0.697  0.772  0.823  0.783  0.756    0.025"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>trial</th>\n",
       "      <th>test_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.771</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc  trial  test_size\n",
       "0  0.795  0.790  0.830  0.801    0.0        0.2\n",
       "1  0.663  0.660  0.698  0.689    1.0        0.2\n",
       "2  0.768  0.749  0.811  0.819    2.0        0.2\n",
       "3  0.678  0.672  0.729  0.731    0.0        0.5\n",
       "4  0.571  0.618  0.632  0.741    1.0        0.5\n",
       "5  0.697  0.695  0.737  0.771    2.0        0.5\n",
       "6  0.550  0.625  0.575  0.700    0.0        0.8\n",
       "7  0.666  0.660  0.726  0.727    1.0        0.8\n",
       "8  0.722  0.759  0.840  0.700    2.0        0.8"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[0]/5)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[0]/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([ 55, 210], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.7132034632034632\n",
      "precision_score:\n",
      "0.7012195121951219\n",
      "accuracy_score:\n",
      "0.8113207547169812\n",
      "Confusion Matrix:\n",
      "[[ 6  4]\n",
      " [ 6 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55        10\n",
      "           1       0.90      0.86      0.88        43\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.70      0.73      0.71        53\n",
      "weighted avg       0.83      0.81      0.82        53\n",
      "\n",
      "f1_score:\n",
      "0.6102941176470588\n",
      "precision_score:\n",
      "0.632183908045977\n",
      "accuracy_score:\n",
      "0.660377358490566\n",
      "Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [16 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.80      0.47        10\n",
      "           1       0.93      0.63      0.75        43\n",
      "\n",
      "    accuracy                           0.66        53\n",
      "   macro avg       0.63      0.71      0.61        53\n",
      "weighted avg       0.82      0.66      0.70        53\n",
      "\n",
      "f1_score:\n",
      "0.7644444444444445\n",
      "precision_score:\n",
      "0.7403508771929824\n",
      "accuracy_score:\n",
      "0.8301886792452831\n",
      "Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 7 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.64        10\n",
      "           1       0.95      0.84      0.89        43\n",
      "\n",
      "    accuracy                           0.83        53\n",
      "   macro avg       0.74      0.82      0.76        53\n",
      "weighted avg       0.87      0.83      0.84        53\n",
      "\n",
      "Elapsed Time: 1 seconds\n",
      "f1_score:\n",
      "0.7531055900621118\n",
      "precision_score:\n",
      "0.7531055900621118\n",
      "accuracy_score:\n",
      "0.8867924528301887\n",
      "Confusion Matrix:\n",
      "[[ 4  3]\n",
      " [ 3 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57         7\n",
      "           1       0.93      0.93      0.93        46\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.75      0.75      0.75        53\n",
      "weighted avg       0.89      0.89      0.89        53\n",
      "\n",
      "f1_score:\n",
      "0.5225225225225225\n",
      "precision_score:\n",
      "0.6166666666666667\n",
      "accuracy_score:\n",
      "0.5660377358490566\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [23 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.38         7\n",
      "           1       1.00      0.50      0.67        46\n",
      "\n",
      "    accuracy                           0.57        53\n",
      "   macro avg       0.62      0.75      0.52        53\n",
      "weighted avg       0.90      0.57      0.63        53\n",
      "\n",
      "f1_score:\n",
      "0.6597530864197532\n",
      "precision_score:\n",
      "0.6523809523809524\n",
      "accuracy_score:\n",
      "0.7547169811320755\n",
      "Confusion Matrix:\n",
      "[[ 6  1]\n",
      " [12 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.86      0.48         7\n",
      "           1       0.97      0.74      0.84        46\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.65      0.80      0.66        53\n",
      "weighted avg       0.89      0.75      0.79        53\n",
      "\n",
      "Elapsed Time: 1 seconds\n",
      "f1_score:\n",
      "0.7451923076923077\n",
      "precision_score:\n",
      "0.7601626016260162\n",
      "accuracy_score:\n",
      "0.8113207547169812\n",
      "Confusion Matrix:\n",
      "[[ 8  6]\n",
      " [ 4 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        14\n",
      "           1       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.76      0.73      0.75        53\n",
      "weighted avg       0.80      0.81      0.81        53\n",
      "\n",
      "f1_score:\n",
      "0.7301214257735997\n",
      "precision_score:\n",
      "0.7275362318840579\n",
      "accuracy_score:\n",
      "0.7547169811320755\n",
      "Confusion Matrix:\n",
      "[[12  2]\n",
      " [11 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.86      0.65        14\n",
      "           1       0.93      0.72      0.81        39\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.73      0.79      0.73        53\n",
      "weighted avg       0.82      0.75      0.77        53\n",
      "\n",
      "f1_score:\n",
      "0.826066572902016\n",
      "precision_score:\n",
      "0.8346153846153846\n",
      "accuracy_score:\n",
      "0.8679245283018868\n",
      "Confusion Matrix:\n",
      "[[10  4]\n",
      " [ 3 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        14\n",
      "           1       0.90      0.92      0.91        39\n",
      "\n",
      "    accuracy                           0.87        53\n",
      "   macro avg       0.83      0.82      0.83        53\n",
      "weighted avg       0.87      0.87      0.87        53\n",
      "\n",
      "Elapsed Time: 1 seconds\n",
      "f1_score:\n",
      "0.7653923541247485\n",
      "precision_score:\n",
      "0.7544642857142857\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[12  2]\n",
      " [ 9 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69        14\n",
      "           1       0.94      0.77      0.85        39\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.75      0.81      0.77        53\n",
      "weighted avg       0.84      0.79      0.80        53\n",
      "\n",
      "f1_score:\n",
      "0.7834967320261438\n",
      "precision_score:\n",
      "0.7696969696969698\n",
      "accuracy_score:\n",
      "0.8113207547169812\n",
      "Confusion Matrix:\n",
      "[[12  2]\n",
      " [ 8 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71        14\n",
      "           1       0.94      0.79      0.86        39\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.77      0.83      0.78        53\n",
      "weighted avg       0.85      0.81      0.82        53\n",
      "\n",
      "f1_score:\n",
      "0.8404301075268817\n",
      "precision_score:\n",
      "0.8251633986928104\n",
      "accuracy_score:\n",
      "0.8679245283018868\n",
      "Confusion Matrix:\n",
      "[[12  2]\n",
      " [ 5 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77        14\n",
      "           1       0.94      0.87      0.91        39\n",
      "\n",
      "    accuracy                           0.87        53\n",
      "   macro avg       0.83      0.86      0.84        53\n",
      "weighted avg       0.88      0.87      0.87        53\n",
      "\n",
      "Elapsed Time: 0 seconds\n",
      "f1_score:\n",
      "0.7266760431317394\n",
      "precision_score:\n",
      "0.707516339869281\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 9 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.80      0.59        10\n",
      "           1       0.94      0.79      0.86        43\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.71      0.80      0.73        53\n",
      "weighted avg       0.86      0.79      0.81        53\n",
      "\n",
      "f1_score:\n",
      "0.7266760431317394\n",
      "precision_score:\n",
      "0.707516339869281\n",
      "accuracy_score:\n",
      "0.7924528301886793\n",
      "Confusion Matrix:\n",
      "[[ 8  2]\n",
      " [ 9 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.80      0.59        10\n",
      "           1       0.94      0.79      0.86        43\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.71      0.80      0.73        53\n",
      "weighted avg       0.86      0.79      0.81        53\n",
      "\n",
      "f1_score:\n",
      "0.8661616161616161\n",
      "precision_score:\n",
      "0.9041666666666667\n",
      "accuracy_score:\n",
      "0.9245283018867925\n",
      "Confusion Matrix:\n",
      "[[ 7  3]\n",
      " [ 1 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        10\n",
      "           1       0.93      0.98      0.95        43\n",
      "\n",
      "    accuracy                           0.92        53\n",
      "   macro avg       0.90      0.84      0.87        53\n",
      "weighted avg       0.92      0.92      0.92        53\n",
      "\n",
      "Elapsed Time: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "rf = np.empty([5, 4])\n",
    "mlp = np.empty([5, 4])\n",
    "svm = np.empty([5, 4])\n",
    "j = 0\n",
    "for train_index, test_index in kf.split(X_train, Y_train):\n",
    "    x_train = X_train[train_index]\n",
    "    y_train = Y_train[train_index]\n",
    "    \n",
    "    x_test = X_train[test_index]\n",
    "    y_test = Y_train[test_index]\n",
    "        \n",
    "    start = time.time()\n",
    "    rf_f1, rf_apr, rf_acc, rf_auc = RFfunc(x_train, x_test, y_train, y_test)\n",
    "    mlp_f1, mlp_apr, mlp_acc, mlp_auc = MLPfunc(x_train, x_test, y_train, y_test)\n",
    "    svm_f1, svm_apr, svm_acc, svm_auc = SVMfunc(x_train, x_test, y_train, y_test)\n",
    " \n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    rf[j] = [rf_f1, rf_apr, rf_acc, rf_auc]\n",
    "    mlp[j] = [mlp_f1, mlp_apr, mlp_acc, mlp_auc]\n",
    "    svm[j] = [svm_f1, svm_apr, svm_acc, svm_auc]\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_stats = pd.DataFrame(rf, columns = ['f1', 'apr', 'acc', 'auc'])\n",
    "mlp_stats = pd.DataFrame(mlp, columns = ['f1', 'apr', 'acc', 'auc'])\n",
    "svm_stats = pd.DataFrame(svm, columns = ['f1', 'apr', 'acc', 'auc'])\n",
    "rf_stats['avg'] = rf_stats.mean(axis=1).values\n",
    "mlp_stats['avg'] = mlp_stats.mean(axis=1).values\n",
    "svm_stats['avg'] = svm_stats.mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.73625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.77200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.75825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc      avg\n",
       "0  0.713  0.701  0.811  0.720  0.73625\n",
       "1  0.753  0.753  0.887  0.752  0.78625\n",
       "2  0.745  0.760  0.811  0.772  0.77200\n",
       "3  0.765  0.754  0.792  0.814  0.78125\n",
       "4  0.727  0.708  0.792  0.806  0.75825"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     0.741\n",
       "apr    0.735\n",
       "acc    0.819\n",
       "auc    0.773\n",
       "avg    0.767\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(rf_stats.mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.64300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.61975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.75175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.80175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.75525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc      avg\n",
       "0  0.610  0.632  0.660  0.670  0.64300\n",
       "1  0.523  0.617  0.566  0.773  0.61975\n",
       "2  0.730  0.728  0.755  0.794  0.75175\n",
       "3  0.783  0.770  0.811  0.843  0.80175\n",
       "4  0.727  0.708  0.792  0.794  0.75525"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     0.675\n",
       "apr    0.691\n",
       "acc    0.717\n",
       "auc    0.775\n",
       "avg    0.714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mlp_stats.mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>apr</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.79025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.71250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.85275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.85275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.89675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f1    apr    acc    auc      avg\n",
       "0  0.764  0.740  0.830  0.827  0.79025\n",
       "1  0.660  0.652  0.755  0.783  0.71250\n",
       "2  0.826  0.835  0.868  0.882  0.85275\n",
       "3  0.840  0.825  0.868  0.878  0.85275\n",
       "4  0.866  0.904  0.925  0.892  0.89675"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1     0.791\n",
       "apr    0.791\n",
       "acc    0.849\n",
       "auc    0.852\n",
       "avg    0.821\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(svm_stats.mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df)[:,1:]\n",
    "Y_train = df['target'].values\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X_train, Y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0 seconds\n",
      "max(tpr - fpr) w/ th =  0.66514010989011\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3gU5fbA8e9JQguE0BESQgihpBIgNEEkItIULChYUfRigWsvWC7XjgXB65UfdlGuAipVRUC6oEiRDtIDJCAdDIH08/tjlxBCCAtksynn8zz7uLPzzsyZGPbknXnnvKKqGGOMMQXBy9MBGGOMKTksqRhjjCkwllSMMcYUGEsqxhhjCowlFWOMMQXGkooxxpgCY0nFGGNMgbGkYkoUEYkXkZMiclxE/hKRMSJSKVeby0VkrogkicgxEfleRMJztaksIu+KyC7nvrY6l2uc47giIg+LyDoRSRaRBBH5VkSi3Hm+xhQ1llRMSXSdqlYCYoDmwLOnVohIO2AWMBWoCzQAVgOLRSTE2aYsMAeIALoBlYHLgUNA63Mc8z/AI8DDQDWgMTAF6HmhwYuIz4VuY0xRIfZEvSlJRCQeuE9VZzuX3wIiVLWnc/kXYK2qPpRru5+AA6p6l4jcB7wGNFTV4y4csxHwJ9BOVZeeo8184H+q+olz+W5nnB2cywoMBh4FfICZwHFVfTLHPqYCC1R1hIjUBf4LdASOAyNV9T0XfkTGuJX1VEyJJSKBQHdgq3PZF0eP49s8mn8DdHG+vxqY4UpCceoMJJwroVyA64E2QDjwNdBXRARARKoC1wDjRcQL+B5HDyvAefxHRaTrJR7fmEtmScWURFNEJAnYDewH/u38vBqO3/m9eWyzFzh1v6T6Odqcy4W2P5dhqnpYVU8CvwAKXOFc1wf4TVX3AK2Amqr6sqqmqep24GOgXwHEYMwlsaRiSqLrVdUP6AQ05XSyOAJkAXXy2KYOcND5/tA52pzLhbY/l92n3qjjuvR44FbnR7cBXznf1wfqisjRUy/gOaB2AcRgzCWxpGJKLFVdAIwBhjuXk4HfgJvzaH4LjpvzALOBriJS0cVDzQECRSQ2nzbJgG+O5cvyCjnX8jigj4jUx3FZbKLz893ADlWtkuPlp6o9XIzXGLexpGJKuneBLiIS41weAvR3Dv/1E5GqIvIq0A54ydlmLI4v7oki0lREvESkuog8JyJnfXGr6hbg/4BxItJJRMqKSHkR6SciQ5zNVgE3ioiviIQC954vcFVdCRwAPgFmqupR56qlwN8i8oyIVBARbxGJFJFWF/MDMqYgWVIxJZqqHgC+BP7lXF4EdAVuxHEfZCeOYccdnMkBVU3FcbP+T+Bn4G8cX+Q1gN/PcaiHgfeBUcBRYBtwA44b6gAjgTRgH/AFpy9lnc84Zyxf5zinTOA6HEOmd+C4bPcJ4O/iPo1xGxtSbIwxpsBYT8UYY0yBsaRijDGmwFhSMcYYU2AsqRhjjCkwxa5wXY0aNTQ4ONjTYRhjTLGyYsWKg6pa093HKXZJJTg4mOXLl3s6DGOMKVZEZGdhHMcufxljjCkwllSMMcYUGEsqxhhjCowlFWOMMQXGkooxxpgC47akIiKfich+EVl3jvUiIu+JyFYRWSMiLdwVizHGmMLhzp7KGKBbPuu7A42cr4HAaDfGYowxphC47TkVVV0oIsH5NOkNfOmc4W6JiFQRkTqqWhDTshpz6dZ+Bwc2eToKY0jPzOJEeib+za6DgJaeDidfnnz4MYAc06cCCc7PzkoqIjIQR2+GoKCgQgnOGKY8BJmpgHg6ElOKKeAN+AFZNerhZUnlnPL6l5rn5C6q+hHwEUBsbKxNAGMKh2bCFU9A56GejsSUQsdOpjNs+kbGL9tNcHVf3rgpmrYh1ZkxYwaPPPIImZmZ3HfffQwZMuSM7UaMGMEnn3yCj48PNWvW5LPPPqN+/foAiMhbQE8ctz5+Bh4BKgG/5NhFIPA/VX3Uuc0twIs4vp9Xq+pt+cXtyaSSANTLsRwI7PFQLMYYU2RkZik3jf6V7QeOc/+VITx2dWPKl/EmMzOTQYMG8fPPPxMYGEirVq3o1asX4eHh2ds2b96c5cuX4+vry+jRo3n66aeZMGECQEWgPRDtbLoIuFJV5+OYRRQAEVkBTHK+bwQ8C7RX1SMiUut8sXtySPE04C7nKLC2wDG7n2KMKc2OJKehqnh7CU9e04Qpg9rzbPcwypfxBmDp0qWEhoYSEhJC2bJl6devH1OnTj1jH3Fxcfj6+gLQtm1bEhIScq4uD5QFygFlcExvnc2ZRGpxuufyD2CUqh4BUNX95zsHdw4pHgf8BjQRkQQRuVdEHhCRB5xNpgPbga3Ax8BD7orFGGOKMlVl8soE4t6Zz/hljlvN3SIvIzqwyhntEhMTqVfv9AWewMBAEhMTz7nfTz/9lO7du59aTAbm4bhvvReYqaobc21yKzBBT88z3xhoLCKLRWSJiOQ3ohdw7+ivW8+zXoFB7jq+McYUB3uOnuT5yWuZt+kAzYOqEFu/6jnbnv6uP00k74Ek//vf/1i+fDkLFiw49VE5IAzHrQaAn0Wko6ouzLFZP+DOHMs+OB776OTc7hcRiVTVo+eKsdiVvjfGmJJi6qpEnp+8jswsZei14fS/PBhvr3OPNgwMDGT37tODZhMSEqhbt+5Z7WbPns1rr73GggULKFeu3KmPqwDfqOpxABH5CWgLLHQuNwN8VHVFjl0lAEtUNR3YISKbcCSZZeeK0cq0GGOMh/hXKENMvSrMeqwjAzo0yDehALRq1YotW7awY8cO0tLSGD9+PL169TqjzcqVK7n//vuZNm0atWqdcV89DbhSRHxEpAxwJZDz8tetwLhch5wCxAGISA0cl8O25xej9VSMMaaQZGRm8emiHaRnZjH4qkZ0alKLKxvXPOclrNx8fHx4//336dq1K5mZmQwYMICIiAiGDh1KbGwsvXr14qmnnuL48ePcfPPNgOPZvmnTpgEcAbYBa3EMD56hqt/n2P0tQI9ch5wJXCMiG4BM4ClVPZRfjJLXNbqiLDY2Vm3mR+M2WVlwaAskrnA8/HjF4/aciikQG/b8zTMT17A28Rg9o+vw/q3NXU4mBUFEVqhqrLuPYz0VU7r9vceRQLJfKyEtybGuXGWoa3VOzaVJzcjk/blbGT1/G1V8y/B/t7ege+RlhZpQCpMlFVN6pByDPSudyeMPx3+TnI9GeZWByyKhWT9HbaWAllA9FLzstqO5NPEHT/DBgm30iqnLv3qGU7ViWU+H5FaWVEzJlJEK+9adTh6JK+Dg5tPrq4dCg46nE0jtSChT3nPxmhIlOTWDnzfs4/rmATS5zI85j3ciqLqvp8MqFJZUTPGXlQWHt515GeuvtZCZ5lhfsRYExkL0LY4EUrc5VDj3swDGXIpfthzg2UlrSTx6ksiAyoTW8is1CQUsqRh3++NL2DzTfftP/Rv2rIbUY47lMhUdSaPNA6d7If6BUEKvX5ui49iJdF6bvoFvlicQUqMiEwa2I7SWn6fDKnSWVIx7Lf0YDu+AKm6assCnHETeeDqB1GwCXt7uOZYx55CZpdz0wa/sOJjMQ50a8nDnRtn1ukodVS1Wr5YtW6opRkZ3UP2qr6qq/vTTT9q4cWNt2LChDhs2LM/mEyZM0LCwMA0PD9dbb71VVVXj4+O1RYsW2qxZMw0PD9fRo0erqmpycrL26NFDmzRpouHh4frMM8+cPuzo0RoZGanNmjXT9u3b6/r161VVddasWdqiRQuNjIzUFi1a6Jw5c9x59qaEO3Q8VTMzs1RVdca6vbo24aiHIzo3YLkWwne0x5PEhb4sqRQzzqSSkZGhISEhum3bNk1NTdXo6OjsL/pTNm/erDExMXr48GFVVd23b5+qqqampmpKSoqqqiYlJWn9+vU1MTFRk5OTde7cudltOnTooNOnT1dV1WPHjmXvd+rUqdq1a1dVVf3jjz80MTFRVVXXrl2rdevWdePJm5IqKytLv1u+W6NfnKlfLdnp6XBcUlhJxS5/mUKRs2Q3kF2yO+c8EB9//DGDBg2ialXHTfRTJSbKlj09BDM1NZWsrCwAfH19iYuLy27TokWL7DLflStXzt4mOTk5+5mA5s2bZ38eERFBSkoKqampOesjGZOvhCMneG7yOhZuPkDL+lVp3aCap0MqUiypmEKRV8nu33///Yw2mzc7hvy2b9+ezMxMXnzxRbp1c1Ta3r17Nz179mTr1q28/fbbZxXRO3r0KN9//z2PPPJI9mejRo1ixIgRpKWlMXfu3LNimjhxIs2bN7eEYlw2eWUCL0xehwIv9Yrgzrb18TpPva7Sxp7sMoXC0fs+U+4nijMyMtiyZQvz589n3Lhx3HfffRw96qiwXa9ePdasWcPWrVv54osv2Ldv3xnb3XrrrTz88MPZPSGAQYMGsW3bNt58801effXVM461fv16nnnmGT788MOCPE1TwlWrWI6WwdWY9VhH+l8ebAklD5ZUTKFwpWR3YGAgvXv3pkyZMjRo0IAmTZqwZcuWM9rUrVuXiIgIfvnl9JTaAwcOpFGjRjz66KN5Hrtfv35MmTLljGPfcMMNfPnllzRs2LAgTs+UUOmZWfzf/K28N8fxe3hl45p8cU8rAquWnudOLpQlFVMoXCnZff311zNv3jwADh48yObNmwkJCSEhIYGTJ08CcOTIERYvXkyTJk0AeOGFFzh27BjvvvvuGfvKmYx+/PFHGjVqBDguk/Xs2ZNhw4bRvn17t52vKf7WJR7j+lGLeWvGJrbsP57d2y6pNbsKit1TMYXClZLdXbt2ZdasWYSHh+Pt7c3bb79N9erV+fnnn3niiScQEVSVJ598kqioKBISEnjttddo2rQpLVo4Cj8OHjyY++67j/fff5/Zs2dTpkwZqlatyhdffAHA+++/z9atW3nllVd45ZVXAJg1a1bueSdMKZaSnsl7c7bw4cLtVPUtywd3tKBbZB1Ph1VsWOn70u7EYfjmLkhNcs/+D2yCkE5w23j37N+YArbprySu/e8vXB8TwAs9w/H3LePpkAqElb43hePQNoj/xVHivWLNgt9/pdoQc2vB79eYApScmsHM9X9xY4tAmlzmx9wnOlGvmt03uRiWVIxD3PPQ6GpPR2FMoVuw+QDPTVrLnmMniQ70J7SWnyWUS2BJxRhTKh1JTuOVHzcw6Y9EGtasyLf3l84CkAXNkooxptQ5VQBy56ETDI4LZfBVoaW3AGQBs6RijCk1Dh1PpapvWby9hCHdmhJQtQIRdf09HVaJYs+pGGNKPFXlm+W7iRs+n3HLdgFwTcRlllDcwHoqxpgSbffhEzw3eS2/bDlI6+BqtAup7umQSjRLKsaYEmvSHwm8MGUdArxyfSS3tw6yel1uZknFGFNi1ahUjtYNqvHaDVEEVKng6XBKBUsqxpgSIz0ziw8XbCMzCx65uhEdG9ekY2M3PNRrzsmSijGmRFiXeIynvlvDxr1/0zumLqpqxR89wJKKMaZYS0nP5N3ZW/j4l+1Uq1iWD+9sSdeIyzwdVqnl1iHFItJNRDaJyFYRGZLH+iARmSciK0VkjYj0cGc8xpiSZ9fhE3y6aDt9WgQy+7ErLaF4mNt6KiLiDYwCugAJwDIRmaaqG3I0ewH4RlVHi0g4MB0IdldMxpiSISklnRnr/uLm2Ho0ru3HvCc72cRZRYQ7L3+1Braq6nYAERkP9AZyJhUFKjvf+wN73BiPMaYEmPfnfp6fvJa//k6heVAVQmv5WUIpQtyZVAKA3TmWE4A2udq8CMwSkX8CFYE8y+SKyEBgIEBQUFCBB2qMKfoOJ6fxyg8bmLwykUa1KvHdg5dbAcgiyJ1JJa9hF7lnBLsVGKOq74hIO2CsiESqatYZG6l+BHwEjkm63BKtMabIysxS+oz+lV2HT/Bw50YMimtIOR8rAFkUuTOpJAD1ciwHcvblrXuBbgCq+puIlAdqAPvdGJcxppg4kJRK9YqOApDP9QgjoGoFwupUPv+GxmPcOfprGdBIRBqISFmgHzAtV5tdQGcAEQkDygMH3BiTMaYYUFUmLNvFVe/M5+uljgKQV4fXtoRSDLitp6KqGSIyGJgJeAOfqep6EXkZWK6q04AngI9F5DEcl8buVlW7vGVMKbbr0AmGTFrDr9sO0aZBNTqE1vB0SOYCuPXhR1WdjmOYcM7PhuZ4vwFo784YjDHFx3crEvjXlHV4ewmv3RDJra2sAGRxY0/UG2OKjNqVy3F5w+q8ekMkdfytAGRxZEnFGOMxaRlZjJ6/jSxVHuvSmCsa1eSKRlYAsjizpGKM8YjVu4/y9Hdr2LQviRubB1gByBLCkooxplCdTMtkxM+b+HTRDmr5leeTu2K5Ory2p8MyBcSSijGmUO0+coIvft1Jv9ZBDOnelMrly3g6JFOALKkYY9zub2cByFucBSDnP9WJujYTY4lkScUY41Zz/9zHc5PWsT8phRZBVQmtVckSSglmScUY4xaHjqfy8g8bmLpqD01q+/HBnS0JrVXJ02EZN7OkYowpcJlZys0f/MbuIyd47OrGPNipIWV93DonoCkiXEoqztpdQaq61c3xGGOKsf1JKdSoWA5vL+H5nmEEVvWlyWVWnr40Oe+fDiLSE1gL/OxcjhGRye4OzBhTfGRlKV/9vpOrhi/gK2cByM5htS2hlEKu9FRexjG51jwAVV0lIqFujcoYU2zEH0xmyKQ1LNl+mMsbVudKeyK+VHMlqaSr6tFcT7paJWFjDN8s382/pqyjrLcXb9wYRd9W9eyp+FLOlaSyUURuAbxEpAHwCLDEvWEZY4qDgCoV6Ni4Jq/0juQy//KeDscUAa4klcHAUCALmIRjfpRn3RmUMaZoSs3I5P/mbUNVefyaJrQPrUF7m+/E5OBKUumqqs8Az5z6QERuxJFgjDGlxMpdR3hm4ho27zvOTS0CrQCkyZMrSeUFzk4gz+fxmTGmBDqRlsE7szbz2eIdXFa5PJ/dHctVTa0ApMnbOZOKiHQFugEBIjIix6rKOC6FGWNKgcQjJxm7ZCe3twnimW5N8bMCkCYf+fVU9gPrgBRgfY7Pk4Ah7gzKGONZx06m89PavfRrHUSj2n4seKqTzcRoXHLOpKKqK4GVIvKVqqYUYkzGGA+atf4vXpiyjkPJacQGVyO0ViVLKMZlrtxTCRCR14BwIHvMoKo2dltUxphCd/B4Ki9OW88Pa/bS9DI/PukfawUgzQVzJamMAV4FhgPdgXuweyrGlCiZWUqf0b+y52gKT17TmPuvbEgZbysAaS6cK0nFV1VnishwVd0GvCAiv7g7MGOM++37O4WalRwFIP99XQSBVSvQqLbV6zIXz5U/RVLFMRh9m4g8ICLXAbXcHJcxxo2yspSxS3bS+Z0FfPX7TgDimtayhGIumSs9lceASsDDwGuAPzDAnUEZY9xn+4HjDJm0lqU7DtMhtAadmtjfiKbgnDepqOrvzrdJwJ0AIhLozqCMMe4xYdkuhk5dTzkfL97qE83NLQPtqXhToPJNKiLSCggAFqnqQRGJwFGu5SrAEosxxUxgVV86NXEUgKxV2QpAmoKX3xP1w4CbgNU4bs5PxlGh+E3ggcIJzxhzKVIzMvnvHMeErU92tQKQxv3y66n0Bpqp6kkRqQbscS5vKpzQjDGXYsXOwzz93Rq2HUjmllgrAGkKR35JJUVVTwKo6mER+dMSijFFX3JqBm/P3MQXv8VT178CXwxozZWNbTZGUzjySyohInKqErEAwTmWUdUbz7dzEekG/AfwBj5R1TfyaHML8CKO2SRXq+ptrodvjMltz9GTfL10F3e1rc9T3ZpSqZwrgzyNKRj5/bbdlGv5/QvZsYh4A6OALkACsExEpqnqhhxtGuGY8Ku9qh4RERvbaMxFOHYinR/X7uW2No4CkL88HUdtuxFvPCC/gpJzLnHfrYGtqrodQETG47hPsyFHm38Ao1T1iPOY+y/xmMaUOjPW/cW/pq7jcHIabUKq0bBmJUsoxmPcWdwnANidYznB+VlOjYHGIrJYRJY4L5edRUQGishyEVl+4MABN4VrTPGyPymFh75awQP/W0HNSuWYOqg9DWtaAUjjWe682JrXMBPN4/iNgE44nnv5RUQiVfXoGRupfgR8BBAbG5t7H8aUOplZyi0f/MaeYyk81bUJAzuGWAFIUyS4nFREpJyqpl7AvhOAejmWA3EMS87dZomqpgM7RGQTjiSz7AKOY0ypsffYSWr7lXcUgOwVQb2qvlae3hQp5/3TRkRai8haYItzuZmI/NeFfS8DGolIAxEpC/QDpuVqMwWIc+63Bo7LYdsvIH5jSoWsLGXM4h10fmcB/ztVALJJLUsopshxpafyHnAtjgSAqq4WkbjzbaSqGSIyGJiJY0jxZ6q6XkReBpar6jTnumtEZAOQCTylqocu8lyMKZG27j/OkIlrWL7zCB0b1+SqpjZI0hRdriQVL1XdmetJ3ExXdq6q04HpuT4bmuO9Ao87X8aYXMYv3cXQaeupUMabd25uxo0tAuypeFOkuZJUdotIa0Cdz578E9js3rCMMQBB1X25OqwWL/WKpKZfOU+HY8x5uZJUHsRxCSwI2AfMdn5mjClgKemZvDdnCwBPd2vK5Q1rcHlDKwBpig9XkkqGqvZzeyTGlHLL4w/z9MQ1bD+QTL9W9awApCmWXEkqy5xDfScAk1Q1yc0xGVOqHE/N4O0Zf/Llkp0EVKnAlwNa09EKQJpiypWZHxuKyOU4hgS/JCKrgPGqOt7t0RlTCvx17CTjl+2mf7tgnurahIpWANIUYy49gquqv6rqw0AL4G/gK7dGZUwJdyQ5jbFLHM+bhNZyFIB8sVeEJRRT7J33N1hEKuEoBNkPCAOmApe7OS5jSiRV5ad1fzF06jqOnkjn8obVaVizkk3ta0oMV/4sWgd8D7ylqr+4OR5jSqz9f6fwr6nrmLl+H1EB/nw5oI0VgDQljitJJURVs9weiTm3XUtg5Vj37Dv5oHv2a86QmaXc/OFv/HUshWe7N+XeDg3wsQKQpgQ6Z1IRkXdU9QlgooicVRnYlZkfTQFZ/jms/Qb86rhn/9UbQfWG7tl3Kbfn6Ekuq+woAPly70jqVa1AiPVOTAmWX09lgvO/FzTjo3ET/3rw6BpPR2FclJmlfPlbPG/N2MSzPZpyV7tgmyfelAr5zfy41Pk2TFXPSCzOQpGXOjOkMSXS1v1JPP3dGv7YdZROTWrSOay2p0MyptC4clF3QB6f3VvQgRhTEnz9+y56/GcROw4mM7JvMz6/uxUBVSp4OixjCk1+91T64hhG3EBEJuVY5QcczXsrY0q34Bq+XBNRmxd7RVCjkhWANKVPfvdUlgKHcMzYOCrH50nASncGZUxxkZKeycjZmxGEId2tAKQx+d1T2QHswFGV2BiTy+/bDzFk0lp2HEzm9jZBVgDSGPK//LVAVa8UkSNAziHFgmN+rWpuj86YIigpJZ03Z/zJ/5bsIqiaL1/f14bLQ613Ygzkf/nr1JTB9q/FmBz2/Z3KdysSuK9DAx6/pjG+Za1elzGn5Hf569RT9PWAPaqaJiIdgGjgfzgKSxpTKhxOTuPHNXu4s10wobUq8cvTV9lMjMbkwZUhxVNwTCXcEPgSR1HJr90alTFFhKry/eo9dBmxgJd/2MD2A8cBLKEYcw6u9NuzVDVdRG4E3lXV90TERn+ZEm/f3yk8P3kdszfuIzrQn6/6tLESK8ach0vTCYvIzcCdwPXOz8q4LyRjPC8zS7nFWQDy+R5h3NM+2ApAGuMCV5LKAOAhHKXvt4tIA2Cce8MyxjMSjpygjn8FvL2EV3pHElTNl+AaFT0dljHFxnn/9FLVdcDDwHIRaQrsVtXX3B6ZMYUoM0v55JftXD1iAf9zzsjYsXFNSyjGXCBXZn68AhgLJOJ4RuUyEblTVRe7OzhjCsOmv5J4euIaVu8+SuemtbgmwgpAGnOxXLn8NRLooaobAEQkDEeSiXVnYMYUhv8t2clL36/Hr3wZ/tMvhl7N6tpT8cZcAleSStlTCQVAVTeKSFk3xmSM250qqRJaqxI9ouow9NpwqlsBSGMumStJ5Q8R+RBH7wTgdqygpCmmTqZlMuLnTXh5Cc92D6NtSHXahlT3dFjGlBiujJF8ANgGPA08A2wH7ndnUMa4w2/bDtHtPwv5+JcdnEjNRPWsWbKNMZco356KiEQBDYHJqvpW4YRkTMH6OyWdYdP/ZNzSXdSv7svX/2hj5emNcZNz9lRE5DkcJVpuB34WkbxmgDSFbMaMGTRp0oTQ0FDeeOONs9bv3LmTzp07Ex0dTadOnUhISMhe5+3tTUxMDDExMfTq1Sv787vvvpsGDRpkr1u1alWhnEth2f93KlNWJjKwYwgzHuloCcUYd1LVPF/AeqCi831NYNm52uazj27AJmArMCSfdn1wlNePPd8+W7ZsqaXOxIGqI6M0IyNDQ0JCdNu2bZqamqrR0dG6fv36M5r26dNHx4wZo6qqc+bM0TvuuCN7XcWKFfPcff/+/fXbb791X/wecDApRT9ftP2MZWNKM2C5XuB3+MW88runkqqqyc7EcwDX7r9kExFvHDNGdgfCgVtFJDyPdn44Hq78/UL2XxotXbqU0NBQQkJCKFu2LP369WPq1KlntNmwYQOdO3cGIC4u7qz1JZ2qMnVVIlePWMBr0zdmF4C0kV3GFI78EkWIiExyviYDDXMsT8pnu1NaA1tVdbuqpgHjgd55tHsFeAtIueDoS5nExETq1auXvRwYGEhiYuIZbZo1a8bEiRMBmDx5MklJSRw6dAiAlJQUYmNjadu2LVOmTDlju+eff57o6Ggee+wxUlNT3Xwm7rHn6Enu/WI5j4xfRf3qFfnx4SusAKQxhSy/G/U35Vp+/wL3HQDszrGcALTJ2UBEmgP1VPUHEXnyXDsSkYHAQICgoKALDKPk0DxGK+V+UG/48OEMHjyYMWPG0LFjRwICAvDxcfxv3rVrF3Xr1mX79u1cddVVREVF0bBhQ4YNG8Zll11GWloaAwcO5M0332To0KGFck4FJSMzi34fLeFAUir/ujacuy8PxtvLHmI0prDlN0nXnEvcd17/orO/FUXEC3/Am+4AACAASURBVMfT+nefb0eq+hHwEUBsbGypHQcaGBjI7t2n83RCQgJ169Y9o03dunWZNMnRkTx+/DgTJ07E398/ex1ASEgInTp1YuXKlTRs2JA6deoAUK5cOe655x6GDx9eGKdTIHYfPkHdKhXw8fbi9RuiCKrmS1B1X0+HZUyp5c5a3gk4Zo08JRDYk2PZD4gE5otIPNAWmCYiVv7lHFq1asWWLVvYsWMHaWlpjB8//oxRXAAHDx4kK8sxaeewYcMYMMAxaO/IkSPZl7UOHjzI4sWLCQ933OLau3cv4OgJTZkyhcjIyMI6pYuWkZnFRwu3cfWIBYz9LR6ADo1qWEIxxsPcObn2MqCRs1R+ItAPuO3USlU9BmSP7RSR+cCTqrrcjTEVaz4+Prz//vt07dqVzMxMBgwYQEREBEOHDiU2NpZevXoxf/58nn32WUSEjh07MmrUKAA2btzI/fffj5eXF1lZWQwZMiQ7qdx+++0cOHAAVSUmJoYPPvjAk6d5Xhv3/s0zE9ewJuEYXcJr0z2qjqdDMsY4SV7X6fNsKFJOVS/oDq6I9ADeBbyBz1T1NRF5GcfQtmm52s7HhaQSGxury5cXsbyTlQmj28ORePfsPzMVqtSHR0rW8yMXY+xv8bz0/Qb8K5Thpd4R9IyqYwUgjXGBiKxQVbdfCXKl9H1r4FPAHwgSkWbAfar6z/Ntq6rTgem5PsvzDrCqdnIl4CIpIwUObIT6HSCghXuOUa/N+duUYOosANm4th/XNavLv64Np1pFq2tqTFHjyuWv94BrcTxdj6quFpE4t0ZVXDW+Bto/4ukoSpQTaRkMn7kZH2/huR5htAmpThsrAGlMkeXKjXovVd2Z67NMdwRjTE6Ltx6k67sL+WzxDtIysqwApDHFgCs9ld3OS2DqfEr+n8Bm94ZlSrNjJ9N5/ceNTFi+mwY1KvLN/e1o3aCap8MyxrjAlaTyII5LYEHAPmC28zNj3OLg8VS+X7OHB65syKNXN6J8GW9Ph2SMcdF5k4qq7scxHNgYtzmQlMr3q/cwoEMDGtasxKJnrrIb8cYUQ66M/vqYHE/Cn6KqA90SkSlVVJUpqxJ56fsNnEjNJK5pLRrUqGgJxZhiypXLX7NzvC8P3MCZNb2MuSiJR0/y/OS1zN90gBZBVXirTzQNalT0dFjGmEvgyuWvCTmXRWQs8LPbIjKlgqMA5G8cOp7Gi9eFc2c7KwBpTElwMWVaGgD1CzoQUzrsOnSCgKqOApBv3BhNUDVf6lWzel3GlBTnfU5FRI6IyGHn6yiOXspz7g/NlCQZmVmMnr+Nq0cu4Mvf4gFoH1rDEooxJUy+PRVxFFVqhqMgJECW2hNo5gKt33OMZyauYV3i33SNqE1PKwBpTImVb1JRVRWRyarasrACMiXLF7/G88oPG6jiW5bRt7ewisLGlHCu3FNZKiItVPUPt0djSoxTBSCbXuZH75gA/nVtGFV8bZiwMSXdOZOKiPioagbQAfiHiGwDknHM6Kiq6qZyvKY4S07N4O2ZmyjjLTzfM9wKQBpTyuTXU1kKtACuL6RYTDG3cPMBnp20lj3HTtK/XXB2b8UYU3rkl1QEQFW3FVIsppg6diKdV37cwHcrEgip6SgA2SrYCkAaUxrll1Rqisjj51qpqiPcEI8phg4mp/LT2r081KkhD3e2ApDGlGb5JRVvoBLOHosxOe1PSmHaqj3cd0VIdgHIqlavy5hSL7+ksldVXy60SEyxoKpM/CORV37YwMn0TDqH1aZBjYqWUIwxgAv3VIw5ZffhEzw3eS2/bDlIbP2qvHGTFYA0xpwpv6TSudCiMEVeRmYWt368hCPJabzSO4Lb29THywpAGmNyOWdSUdXDhRmIKZriDyZTr5ovPt5evNXHUQAysKrV6zLG5O28BSVN6ZSemcWoeVu5ZuTC7AKQlzesYQnFGJOviyl9b0q4dYnHePq7NWzY+zc9o+pwbXRdT4dkjCkmLKmYM3y+eAev/riRahXL8sEdLekWeZmnQzLGFCOWVAxwugBkRF1/bmwewAs9w/H3LePpsIwxxYwllVLueGoGb834k7LeXrxwbTitG1SjdQMrsWKMuTh2o74gaJanI7go8zftp+vIhYxdshPF0VsxxphLYT2VS3HyCKz8CpZ97Fgu5+fZeFx0JDmNV37cwKQ/EgmtVYnvHriclvWrejosY0wJYD2Vi/HXWpj2MLwTBrOeB786cNOn0KI/M2bMoEmTJoSGhvLGG2+ctenOnTvp3Lkz0dHRdOrUiYSEhOx1Tz/9NBEREYSFhfHwww9n9xw6depEkyZNiImJISYmhv37919S+EdOpDFr/T4eviqUHx/uYAnFGFNwVNVtL6AbsAnYCgzJY/3jwAZgDTAHqH++fbZs2VI9IiNNde1E1U+7qf67suortVWnDlbds/p0k4wMDQkJ0W3btmlqaqpGR0fr+vXrz9hNnz59dMyYMaqqOmfOHL3jjjtUVXXx4sV6+eWXa0ZGhmZkZGjbtm113rx5qqp65ZVX6rJlyy4p/H3HTuqHC7ZqVlaWqqoeTU67pP0ZY4oXYLm68fv+1Mttl79ExBsYBXQBEoBlIjJNVTfkaLYSiFXVEyLyIPAW0NddMV2UpH2wYgys+ByS9kKV+nDNqxBzO/ieeUN76dKlhIaGEhISAkC/fv2YOnUq4eHh2W02bNjAyJEjAYiLi+P66x1zoIkIKSkppKWloaqkp6dTu3btSw5fVfl2eQKv/LiBtIwsuoRfRoMaFW1klzHGLdx5+as1sFVVt6tqGjAe6J2zgarOU9UTzsUlQKAb43GdKuz6Hb67F0ZGwPzXoXYE3PYNPLwSLv/nWQkFIDExkXr16mUvBwYGkpiYeEabZs2aMXHiRAAmT55MUlIShw4dol27dsTFxVGnTh3q1KlD165dCQsLy97unnvuISYmhldeecXlG+q7D5/gzk+X8vTENYTVqcxPj1xhBSCNMW7lzhv1AcDuHMsJQJt82t8L/JTXChEZCAwECAoKKqj4zpZ+EtZ+57jxvnc1lKsMrf8BsfdCjdDzbp7Xl33u6XSHDx/O4MGDGTNmDB07diQgIAAfHx+2bt3Kxo0bs++xdOnShYULF9KxY0e++uorAgICSEpK4qabbmLs2LHcdddd+cZyqgDk0RPpvHp9JLe1DrICkMYYt3NnUsnrGyzPP7FF5A4gFrgyr/Wq+hHwEUBsbGzBj3s9shOWfwp/fOkY0VUzDK4dCVG3QLlKLu8mMDCQ3btP59GEhATq1j2zxEndunWZNGkSAMePH2fixIn4+/vz0Ucf0bZtWypVchyve/fuLFmyJDvxAPj5+XHbbbexdOnScyaVHQeTCXIWgHy7TzPqV/elbpUKF/TjMMaYi+XOy18JQL0cy4HAntyNRORq4Hmgl6qmujGeM6nCtrkw7lb4TzP49X0IvgL6/wAP/QaxAy4ooQC0atWKLVu2sGPHDtLS0hg/fjy9evU6o83BgwfJynI81zJs2DAGDBgAOHpgCxYsICMjg/T0dBYsWEBYWBgZGRkcPHgQgPT0dH744QciIyPPOnZ6Zhb/nbOFriMX8sWv8QC0a1jdEooxplC5s6eyDGgkIg2ARKAfcFvOBiLSHPgQ6KaqlzZO1lUpf8PqcbD0Yzi0BXxrwBVPQOw94H9pt3R8fHx4//336dq1K5mZmQwYMICIiAiGDh1KbGwsvXr1Yv78+Tz77LOICB07dmTUqFEA9OnTh7lz5xIVFYWI0K1bN6677jqSk5Pp2rUr6enpZGZmcvXVV/OPf/zjjOOuSTjK09+t4c+/kriuWV16xVgBSGOMZ4irN30vauciPYB3ccx3/5mqviYiL+MY2jZNRGYDUcBe5ya7VLXXOXYHOC5/LV++/MKDST7kuOG+ejykHYeAWGg9ECKuB59yF76/IuKzRTt49ccN1PQrx6vXR9El/NJHjBljSh4RWaGqse4+jlufqFfV6cD0XJ8NzfH+ance/wxrxsOyTyC6L7S5HwJaFtqh3UGdBSCjA/3p26oeQ7qH4V/BhgkbYzyr9JRpycpw/PfakVC2+A6rTUpJ542f/qScjzdDrwsnNrgascFWANIYUzRYmZZiZN6f+7lm5ELGLd2Fj7dYAUhjTJFTenoqxdjh5DRe/n49U1btoXHtSvzf7ZfTPMjqdRljih5LKsXAsZPpzNm4n0c6N2JQXChlfayDaYwpmiypFFF/HUthyqpE7u8YQoMaFVk05Cq7EW+MKfIsqRQxqsr4Zbt5/ceNpGdl0S3iMoJrVLSEYowpFiypFCE7DyUzZOJaftt+iLYh1XjjxmiCrQCkMaYYsaRSRGRkZnHbx79z7GQ6r98QRb9W9awApDGm2LGk4mHbDhynvrMA5Du3OApA1vG3el3GmOLJhhF5SFpGFu/O3ky3dxfy5W87AWgbUt0SijGmWLOeiges2n2UZ75bw6Z9SfSOqcv1zQM8HZIxxhQISyqF7NNFO3jtxw3U8ivPp/1j6RxmBSCNMSWHJZVCcqoAZEw9f/q1DmJI96ZULm/DhI0xJYslFTf7OyWdYdP/pHwZL/59XQQt61ejZX0rAGmMKZnsRr0bzd6wjy4jFjBh2S7K+nhZAUhjTIlnPRU3OHQ8lZe+38C01XtoepkfH90ZS7N6VTwdljHGuJ0lFTdISslg3qb9PHZ1Yx7s1NAKQBpjSg1LKgVkz9GTTF6ZyEOdGhJcoyKLh1xlN+KNMaWOJZVLlJWlfL10F2/89CeZWUrPqDoE16hoCcUYUypZUrkEOw4mM2TiGn7fcZj2odUZdkM0QdV9PR2WMcZ4jCWVi5SRmcUdn/zO3ynpvHVTNDfHBiJiBSCNMaWbJZULtHV/EsHVK+Lj7cXIvjHUr+5L7crlPR2W8bD09HQSEhJISUnxdCimlCtfvjyBgYGUKeOZS/CWVFyUmpHJqHnb+L95W3m2Rxj3dmhA6wb2EKNxSEhIwM/Pj+DgYOuxGo9RVQ4dOkRCQgINGjTwSAyWVFzwx64jPPPdGrbsP86NzQO40QpAmlxSUlIsoRiPExGqV6/OgQMHPBaDJZXz+Hjhdl7/aSN1Kpfn83taEdeklqdDMkWUJRRTFHj699CSyjlkZSleXkKL+lW4vU0Qz3Rrip8NEzbGmHzZo965HDuZztPfreal79cD0LJ+NV69PsoSiinyvL29iYmJITIykuuuu46jR48WyH7j4+OJjIwskH3l9OKLLxIQEEBMTAwxMTEMGTKkwI9xyqpVq5g+fXq+bR555BECAgLIyso6I8bhw4ef0S44OJiDBw8C8Ndff9GvXz8aNmxIeHg4PXr0YPPmzfkeZ8eOHbRp04ZGjRrRt29f0tLSzmqTnp5O//79iYqKIiwsjGHDhgGOy6ytW7emWbNmRERE8O9//9ul8y9MllRymLn+L7qMWMDEPxKpWM7HCkCaYqVChQqsWrWKdevWUa1aNUaNGuXpkM7rscceY9WqVaxatYo33njD5e0yMzMv6DjnSypZWVlMnjyZevXqsXDhQpf2qarccMMNdOrUiW3btrFhwwZef/119u3bl+92zzzzDI899hhbtmyhatWqfPrpp2e1+fbbb0lNTWXt2rWsWLGCDz/8kPj4eMqVK8fcuXNZvXo1q1atYsaMGSxZssSleAuLXf4CDh5P5d9T1/Pj2r2E16nMZ3e3IjLA39NhmeLqpyHw19qC3edlUdDd9S/ddu3asWbNGgCOHz9O7969OXLkCOnp6bz66qv07t2b+Ph4unfvTocOHfj1118JCAhg6tSpVKhQgRUrVjBgwAB8fX3p0KFD9n5TUlJ48MEHWb58OT4+PowYMYK4uDjGjBnDlClTyMzMZN26dTzxxBOkpaUxduxYypUrx/Tp06lWzbXRknPmzOHJJ58kIyODVq1aMXr0aMqVK0dwcDADBgxg1qxZDB48mFatWjFo0CAOHDiAr68vH3/8MU2bNuXbb7/lpZdewtvbG39/f2bPns3QoUM5efIkixYt4tlnn6Vv375nHHPevHlERkbSt29fxo0bR6dOnc4b57x58yhTpgwPPPBA9mcxMTH5bqOqzJ07l6+//hqA/v378+KLL/Lggw+e0U5ESE5OJiMjg5MnT1K2bFkqV66MiFCpUiXA0ZtJT0/3+D2U3KynAhxPyeCXLQd4qmsTpg5ubwnFFGuZmZnMmTOHXr16AY7nFiZPnswff/zBvHnzeOKJJ7J74Vu2bGHQoEGsX7+eKlWqMHHiRADuuece3nvvPX777bcz9n2q97N27VrGjRtH//79s5/NWbduHV9//TVLly7l+eefx9fXl5UrV9KuXTu+/PLLPGMdOXJk9uWvmTNnkpKSwt13382ECRNYu3YtGRkZjB49Ort9+fLlWbRoEf369WPgwIH897//ZcWKFQwfPpyHHnoIgJdffpmZM2eyevVqpk2bRtmyZXn55Zfp27cvq1atOiuhAIwbN45bb72VG264gR9++IH09PTz/pzXrVtHy5Ytz7k+rwRz6NAhqlSpgo+P4+/5wMBAEhMTz2rXp08fKlasSJ06dQgKCuLJJ5/MTsqZmZnExMRQq1YtunTpQps2bc4ba2EqtT2VxKMnmfxHAoPiQgmuUZFfn+1MpXKl9sdhCtIF9CgK0smTJ4mJiSE+Pp6WLVvSpUsXwPHX8XPPPcfChQvx8vIiMTEx+xJNgwYNsr/8WrZsSXx8PMeOHePo0aNceeWVANx555389NNPACxatIh//vOfADRt2pT69etn30OIi4vDz88PPz8//P39ue666wCIiorK7jXl9thjj/Hkk09mL69evZoGDRrQuHFjwPGX/KhRo3j00UcBshPC8ePH+fXXX7n55puzt01NTQWgffv23H333dxyyy3ceOON5/25paWlMX36dEaOHImfnx9t2rRh1qxZ9OzZ85y9AFd6B6tWrTrrs7wuqee1r6VLl+Lt7c2ePXs4cuQIV1xxBVdffTUhISF4e3uzatUqjh49yg033MC6devccs/rYrm1pyIi3URkk4hsFZGz7sKJSDkRmeBc/7uIBLszHnCM6hr7WzzXjFjAqHnb2HnoBIAlFFPsnbqnsnPnTtLS0rJ7FV999RUHDhxgxYoVrFq1itq1a2f3LsqVK5e9vbe3NxkZGdlTX+clv/uMOffl5eWVvezl5UVGRoZL53C++5gVK1YEHPdAqlSpkn0/ZtWqVWzcuBGADz74gFdffZXdu3cTExPDoUOH8t3njBkzOHbsGFFRUQQHB7No0SLGjRsHQPXq1Tly5MgZ7ZOSkqhSpQoRERGsWLHCpfM6pUaNGhw9ejT755GQkEDdunXPavf111/TrVs3ypQpQ61atWjfvj3Lly8/o02VKlXo1KkTM2bMuKAY3M1tSUVEvIFRQHcgHLhVRMJzNbsXOKKqocBI4E13xXNK/8+W8a+p62lRvyqzHutIcI2K7j6kMYXK39+f9957j+HDh5Oens6xY8eoVasWZcqUYd68eezcuTPf7atUqYK/vz+LFi0CHEnplI4dO2Yvb968mV27dtGkSZMCi71p06bEx8ezdetWAMaOHZvdY8qpcuXKNGjQgG+//RZwJKPVq1cDsG3bNtq0acPLL79MjRo12L17N35+fiQlJeV5zHHjxvHJJ58QHx9PfHw8O3bsYNasWZw4cYKOHTsybdq07G0nTZpEs2bN8Pb25qqrriI1NZWPP/44e1/Lli1jwYIF5zw/ESEuLo7vvvsOgC+++ILevXuf1S4oKIi5c+eiqiQnJ7NkyRKaNm3KgQMHskf1nTx5ktmzZ9O0adPz/lwLkzt7Kq2Braq6XVXTgPFA7p9eb+AL5/vvgM7iprtOmVmOv4A27/+bt/tE8+WA1tSrZhWFTcnUvHlzmjVrxvjx47n99ttZvnw5sbGxfPXVVy59CX3++ecMGjSIdu3aUaFChezPH3roITIzM4mKiqJv376MGTPmjB7KpSpfvjyff/45N998M1FRUXh5eZ1xIzynr776ik8//TR7eO3UqVMBeOqpp4iKiiIyMpKOHTvSrFkz4uLi2LBhAzExMUyYMCF7HydOnGDmzJn07Nkz+7OKFSvSoUMHvv/+e6Kjoxk8eDAdOnQgJiaGDz74gE8++QRwJIjJkyfz888/07BhQyIiInjxxRezex7numn/5ptvMmLECEJDQzl06BD33nsvANOmTWPo0KEADBo0iOPHjxMZGUmrVq245557iI6OZu/evcTFxREdHU2rVq3o0qUL11577SX+1AuWuGvYrIj0Abqp6n3O5TuBNqo6OEebdc42Cc7lbc42B3PtayAwECAoKKjl+f7SytOfP3L4t7Fk9P6AWtVsal9TsDZu3EhYWJinwzAGyPv3UURWqGqsu4/tzp5KXj2O3BnMlTao6keqGquqsTVr1ry4aJr2pNo940lNTiIuLo6wsDAiIiL4z3/+c3YAqjz88MOEhoYSHR3NH3/8cXHHNMaYUsadd6cTgHo5lgOBPedokyAiPoA/cNiNMeHj48M777xDixYtSEpKyh4lEx5++nbPTz/9xJYtW9iyZQu///47Dz74IL///rs7wzLGmBLBnT2VZUAjEWkgImWBfsC0XG2mAf2d7/sAc9XNj7HXqVOHFi1aAODn50dYWNhZ48SnTp3KXXfdhYjQtm1bjh49yt69e90ZlikBrAKDKQo8/XvotqSiqhnAYGAmsBH4RlXXi8jLItLL2exToLqIbAUeB9xX/CcP8fHxrFy58qyHhxITE6lX73Qn61wPKBlzSvny5Tl06JDH/0Gb0u3UfCrly3tu4kC3PpyhqtOB6bk+G5rjfQpwc+7tCsPx48e56aabePfdd6lcufIZ61x9QMmYUwIDA0lISPDoPBbGwOmZHz2lVD7xl56ezk033cTtt9+e5xO3gYGB7N69O3v5XA8oGXNKmTJlPDbTnjFFSamr/aWq3HvvvYSFhfH444/n2aZXr158+eWXqCpLlizB39+fOnXqFHKkxhhT/JS6nsrixYsZO3YsUVFR2Q8nvf766+zatQuABx54gB49ejB9+nRCQ0Px9fXl888/92TIxhhTbLjt4Ud3iY2N1dw1cIwxxuSvsB5+LHZJRUQOABfxSD0ANYCD521Vstg5lw52zqXDpZxzfVW9yKfHXVfsksqlEJHlhZGpixI759LBzrl0KA7nXOpu1BtjjHEfSyrGGGMKTGlLKh95OgAPsHMuHeycS4cif86l6p6KMcYY9yptPRVjjDFuZEnFGGNMgSmRSUVEuonIJhHZKiJnVT4WkXIiMsG5/ncRCS78KAuWC+f8uIhsEJE1IjJHROp7Is6CdL5zztGuj4ioiBTpoZiucOWcReQW5//r9SLydWHHWNBc+N0OEpF5IrLS+fvdwxNxFhQR+UxE9jtnxs1rvYjIe86fxxoRaVHYMeZLVUvUC/AGtgEhQFlgNRCeq81DwAfO9/2ACZ6OuxDOOQ7wdb5/sDScs7OdH7AQWALEejruQvj/3AhYCVR1LtfydNyFcM4fAQ8634cD8Z6O+xLPuSPQAlh3jvU9gJ9wzJzbFvjd0zHnfJXEnkprYKuqblfVNGA80DtXm97AF8733wGdpXjXtj/vOavqPFU94VxcgmMmzuLMlf/PAK8AbwEphRmcm7hyzv8ARqnqEQBV3V/IMRY0V85ZgVPzV/hz9gyzxYqqLiT/GXB7A1+qwxKgiogUmYq3JTGpBAC7cywnOD/Ls406JhM7BlQvlOjcw5VzzuleHH/pFGfnPWcRaQ7UU9UfCjMwN3Ll/3NjoLGILBaRJSLSrdCicw9XzvlF4A4RScAxf9M/Cyc0j7nQf++FqiRWKc6rx5F73LQrbYoTl89HRO4AYoEr3RqR++V7ziLiBYwE7i6sgAqBK/+ffXBcAuuEozf6i4hEqupRN8fmLq6c863AGFV9R0TaAWOd55zl/vA8okh/f5XEnkoCUC/HciBnd4ez24iID44uc37dzaLOlXNGRK4Gngd6qWpqIcXmLuc7Zz8gEpgvIvE4rj1PK+Y361393Z6qqumqugPYhCPJFFeunPO9wDcAqvobUB5H4cWSyqV/755SEpPKMqCRiDQQkbI4bsRPy9VmGtDf+b4PMFedd8CKqfOes/NS0Ic4Ekpxv84O5zlnVT2mqjVUNVhVg3HcR+qlqsV53gRXfren4BiUgYjUwHE5bHuhRlmwXDnnXUBnABEJw5FUSvK8ztOAu5yjwNoCx1R1r6eDOqXEXf5S1QwRGQzMxDFy5DNVXS8iLwPLVXUa8CmOLvJWHD2Ufp6L+NK5eM5vA5WAb51jEnapai+PBX2JXDznEsXFc54JXCMiG4BM4ClVPeS5qC+Ni+f8BPCxiDyG4zLQ3cX5j0QRGYfj8mUN532ifwNlAFT1Axz3jXoAW4ETwD2eiTRvVqbFGGNMgSmJl7+MMcZ4iCUVY4wxBcaSijHGmAJjScUYY0yBsaRijDGmwFhSMUWOiGSKyKocr+B82gafq5rrBR5zvrMS7mpniZMmF7GPB0TkLuf7u0Wkbo51n4hIeAHHuUxEYlzY5lER8b3UYxvjCksqpig6qaoxOV7xhXTc21W1GY5io29f6Maq+oGqfulcvBuom2Pdfaq6oUCiPB3n/+FanI8CllRMobCkYooFZ4/kFxH5w/m6PI82ESKy1Nm7WSMijZyf35Hj8w9FxPs8h1sI/H979xNiVRnGcfz7W/RnKhJcFEJghlAQTVIWgoswM4oISsRbiNRCIjGCZDZhi4IWErXILCUixoXFoChEfyiJwYXMVLMox0QSzEUQ5UIkZIKwX4vnGTrdbsy9w1k08nx29733nPe9B+a8877n8nuW57Frs07HdNa5uCrbd+rv+jSvZ9vLkkYkbSDy1fZnn0O5wlgpaauk1xpjflrSW/Mc5wSNIEFJeyRNKeqovJJtzxOT27ik8Wx7UNJEXscDkq6bo59S+laTSvk/4l5h1wAAAopJREFUGmpsfR3Otl+BdbbvAjrArh7HPQu8aXsFcVP/KWM7OsDqbL8EbJqj/0eBaUlXA6NAx/YdRALFVkmLgceB220PA682D7Z9EJgiVhQrbM803j4IrG+87gBj8xznQ0Qsy6wdtlcCw8B9koZt7yJyodbYXpPRLS8BD+S1nAK2z9FPKX277GJaymVhJm+sTVcAu/MZwiUi06rbBLBD0k3AIdunJa0F7ga+yXiaIWKC6mW/pBngLBGffivwo+0f8v19wDZgN1Gf5T1JnwB9R+vbPifpTGY2nc4+juV5BxnntURsSbPq30ZJzxB/10uIglXHu45dle3Hsp8rietWSitqUikLxQvAL8CdxAr7X0W3bH8g6SvgEeBzSVuImPB9tl/so49NzcBJST1r7GQe1b1EiOETwHPA/QN8lzFgI3AKOGzbijt83+MkKiDuBN4G1ktaBowA99g+L2mUCFbsJuCI7ScHGG8pfavtr7JQLAJ+zhoZm4n/0v9B0i3Amdzy+YjYBvoS2CDphvzMYklL++zzFHCzpOX5ejNwNJ9BLLL9KfEQvNcvsH4j4vd7OQQ8RtQBGcu2gcZp+w9iG2tVbp1dD1wELki6EXj4P8YyCaye/U6SrpHUa9VXyrzUpFIWineApyRNEltfF3t8pgOckPQtcBtRcvUkcfP9QtJx4AixNTQn278TCbAHJE0DfwJ7iRv0x3m+o8QqqtsosHf2QX3Xec8DJ4Gltr/OtoHHmc9q3gBGbH9H1Kb/Hnif2FKb9S7wmaRx2+eIX6Z9mP1MEteqlFZUSnEppZTW1EqllFJKa2pSKaWU0pqaVEoppbSmJpVSSimtqUmllFJKa2pSKaWU0pqaVEoppbTmL4S3S4mIbBxOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = ensemble.RandomForestClassifier(n_jobs = -1, n_estimators=200, random_state=42)\n",
    "clf.fit(x_train1, y_train1)\n",
    "\n",
    "now = time.time()\n",
    "print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "\n",
    "x_train1.shape\n",
    "\n",
    "probs = clf.predict_proba(x_test1)[:,1]\n",
    "\n",
    "plot_roc(y_test1, probs, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.8058608058608059\n",
      "precision_score:\n",
      "0.7938596491228069\n",
      "accuracy_score:\n",
      "0.8490566037735849\n",
      "Confusion Matrix:\n",
      "[[10  3]\n",
      " [ 5 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.71        13\n",
      "           1       0.92      0.88      0.90        40\n",
      "\n",
      "    accuracy                           0.85        53\n",
      "   macro avg       0.79      0.82      0.81        53\n",
      "weighted avg       0.86      0.85      0.85        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix_info(0.6651,y_test1, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X_train, Y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df)[:,1:]\n",
    "Y_train = df['target'].values\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X_train, Y_train, test_size=0.5)\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', activation='relu', alpha=0.1, hidden_layer_sizes = (1,10), max_iter = 10000)\n",
    "mlp.fit(x_train1, y_train1)\n",
    "\n",
    "probs_nn = mlp.predict_proba(x_test1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(tpr - fpr) w/ th =  0.9788439869349386\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.6114736776679719\n",
      "precision_score:\n",
      "0.6588541666666666\n",
      "accuracy_score:\n",
      "0.6466165413533834\n",
      "Confusion Matrix:\n",
      "[[23  1]\n",
      " [46 63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.96      0.49        24\n",
      "           1       0.98      0.58      0.73       109\n",
      "\n",
      "    accuracy                           0.65       133\n",
      "   macro avg       0.66      0.77      0.61       133\n",
      "weighted avg       0.87      0.65      0.69       133\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6114736776679719, 0.6588541666666666, 0.6466165413533834, 0.76815749235474)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_roc(y_test1, probs_nn, 'MLPClassifier')\n",
    "\n",
    "matrix_info(0.4, y_test1, probs_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "svc = SVC(C = 0.1, degree = 2, gamma = 0.04, kernel = 'rbf', max_iter =  100000, probability = True)\n",
    "svc.fit(x_train1,y_train1)\n",
    "now = time.time()\n",
    "print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "\n",
    "probs_svm = svc.predict_proba(x_test1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(tpr - fpr) w/ th =  0.7521644435045628\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:\n",
      "0.826066572902016\n",
      "precision_score:\n",
      "0.8186813186813187\n",
      "accuracy_score:\n",
      "0.8679245283018868\n",
      "Confusion Matrix:\n",
      "[[10  3]\n",
      " [ 4 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74        13\n",
      "           1       0.92      0.90      0.91        40\n",
      "\n",
      "    accuracy                           0.87        53\n",
      "   macro avg       0.82      0.83      0.83        53\n",
      "weighted avg       0.87      0.87      0.87        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_roc(y_test1, probs_svm, 'SVM')\n",
    "\n",
    "matrix_info(0.7521, y_test1, probs_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200,500,1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [None,1,10,50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 1, 10, 50, 100],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200, 500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "             return_train_score=False, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200,500,1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [None,1,10,50,100]\n",
    "}\n",
    "\n",
    "clf = ensemble.RandomForestClassifier(n_jobs = -1, random_state=42)\n",
    "cv = GridSearchCV(clf, param_grid=params, scoring='accuracy', n_jobs=-1, verbose=10, refit='accuracy', cv=5)\n",
    "cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.018810</td>\n",
       "      <td>0.073388</td>\n",
       "      <td>0.143128</td>\n",
       "      <td>0.058547</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'auto', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.002154</td>\n",
       "      <td>0.126105</td>\n",
       "      <td>0.114892</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.738938</td>\n",
       "      <td>0.070334</td>\n",
       "      <td>0.216327</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.940424</td>\n",
       "      <td>0.211519</td>\n",
       "      <td>0.121947</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>50</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.775289</td>\n",
       "      <td>0.154974</td>\n",
       "      <td>0.223256</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>50</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.063565</td>\n",
       "      <td>0.219058</td>\n",
       "      <td>0.152061</td>\n",
       "      <td>0.049702</td>\n",
       "      <td>50</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.948044</td>\n",
       "      <td>0.167009</td>\n",
       "      <td>0.223195</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>50</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.740923</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.214445</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'auto', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.808949</td>\n",
       "      <td>0.091319</td>\n",
       "      <td>0.228399</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.736423</td>\n",
       "      <td>0.182941</td>\n",
       "      <td>0.219172</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>100</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.987080</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.124952</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.850490</td>\n",
       "      <td>0.094454</td>\n",
       "      <td>0.211785</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.679211</td>\n",
       "      <td>0.023909</td>\n",
       "      <td>0.109016</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.910699</td>\n",
       "      <td>0.104495</td>\n",
       "      <td>0.216518</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.012717</td>\n",
       "      <td>0.063531</td>\n",
       "      <td>0.115404</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.523913</td>\n",
       "      <td>0.124919</td>\n",
       "      <td>0.214515</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.028768</td>\n",
       "      <td>0.274705</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.906861</td>\n",
       "      <td>0.220134</td>\n",
       "      <td>0.117445</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>100</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.051465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.964004</td>\n",
       "      <td>0.104256</td>\n",
       "      <td>0.119416</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.741397</td>\n",
       "      <td>0.050322</td>\n",
       "      <td>0.226150</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.333658</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.343821</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.554055</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.421426</td>\n",
       "      <td>0.084699</td>\n",
       "      <td>50</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.325656</td>\n",
       "      <td>0.119720</td>\n",
       "      <td>0.396247</td>\n",
       "      <td>0.064173</td>\n",
       "      <td>50</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.753487</td>\n",
       "      <td>0.102261</td>\n",
       "      <td>0.216451</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>3.289815</td>\n",
       "      <td>0.224155</td>\n",
       "      <td>0.428115</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'auto', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.372270</td>\n",
       "      <td>0.111443</td>\n",
       "      <td>0.415205</td>\n",
       "      <td>0.036122</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.057836</td>\n",
       "      <td>0.144020</td>\n",
       "      <td>0.117818</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.931163</td>\n",
       "      <td>0.196965</td>\n",
       "      <td>0.365375</td>\n",
       "      <td>0.053570</td>\n",
       "      <td>100</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.630506</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.219804</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.760289</td>\n",
       "      <td>0.059447</td>\n",
       "      <td>0.113723</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.427636</td>\n",
       "      <td>0.182012</td>\n",
       "      <td>0.424194</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.383834</td>\n",
       "      <td>0.114062</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.420518</td>\n",
       "      <td>0.157789</td>\n",
       "      <td>0.369409</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833962</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.307213</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0.120908</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto', 'n...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.330619</td>\n",
       "      <td>0.045710</td>\n",
       "      <td>0.120618</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'auto', 'n_...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.345795</td>\n",
       "      <td>0.021121</td>\n",
       "      <td>0.116454</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>50</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.333443</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>0.112006</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.316342</td>\n",
       "      <td>0.066350</td>\n",
       "      <td>0.115768</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'log2', 'n...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.364195</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>0.111839</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.282221</td>\n",
       "      <td>0.217373</td>\n",
       "      <td>0.348269</td>\n",
       "      <td>0.046599</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.112210</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'sqrt', 'n...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.339998</td>\n",
       "      <td>0.036245</td>\n",
       "      <td>0.116278</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>100</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.222482</td>\n",
       "      <td>0.163649</td>\n",
       "      <td>0.329650</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.296956</td>\n",
       "      <td>0.118759</td>\n",
       "      <td>0.326806</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.381794</td>\n",
       "      <td>0.031176</td>\n",
       "      <td>0.110293</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>50</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.387689</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.112473</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.826415</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.372421</td>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.110758</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.826415</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.345616</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>0.108713</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.826415</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.893884</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>0.325571</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.725700</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>0.214568</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.582336</td>\n",
       "      <td>0.094111</td>\n",
       "      <td>0.212670</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.896039</td>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.366322</td>\n",
       "      <td>0.038367</td>\n",
       "      <td>0.116869</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.898328</td>\n",
       "      <td>0.106707</td>\n",
       "      <td>0.333303</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.329345</td>\n",
       "      <td>0.032519</td>\n",
       "      <td>0.113511</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.768822</td>\n",
       "      <td>0.047774</td>\n",
       "      <td>0.130290</td>\n",
       "      <td>0.017013</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.630777</td>\n",
       "      <td>0.071952</td>\n",
       "      <td>0.229264</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.999717</td>\n",
       "      <td>0.072272</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.345670</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.109918</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.785370</td>\n",
       "      <td>0.094897</td>\n",
       "      <td>0.110863</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "49       1.018810      0.073388         0.143128        0.058547   \n",
       "37       1.002154      0.126105         0.114892        0.004420   \n",
       "38       1.738938      0.070334         0.216327        0.006622   \n",
       "41       0.940424      0.211519         0.121947        0.007526   \n",
       "42       1.775289      0.154974         0.223256        0.007041   \n",
       "45       1.063565      0.219058         0.152061        0.049702   \n",
       "46       1.948044      0.167009         0.223195        0.004700   \n",
       "50       1.740923      0.030529         0.214445        0.004103   \n",
       "10       1.808949      0.091319         0.228399        0.014376   \n",
       "58       1.736423      0.182941         0.219172        0.004713   \n",
       "53       0.987080      0.101767         0.124952        0.010584   \n",
       "54       1.850490      0.094454         0.211785        0.003103   \n",
       "1        0.679211      0.023909         0.109016        0.002471   \n",
       "6        1.910699      0.104495         0.216518        0.004406   \n",
       "5        1.012717      0.063531         0.115404        0.009033   \n",
       "2        1.523913      0.124919         0.214515        0.001707   \n",
       "9        1.028768      0.274705         0.117200        0.008809   \n",
       "57       0.906861      0.220134         0.117445        0.007240   \n",
       "33       0.964004      0.104256         0.119416        0.007715   \n",
       "34       1.741397      0.050322         0.226150        0.011021   \n",
       "55       3.333658      0.067444         0.343821        0.047100   \n",
       "43       3.554055      0.147200         0.421426        0.084699   \n",
       "47       3.325656      0.119720         0.396247        0.064173   \n",
       "30       1.753487      0.102261         0.216451        0.004287   \n",
       "51       3.289815      0.224155         0.428115        0.004313   \n",
       "39       3.372270      0.111443         0.415205        0.036122   \n",
       "29       1.057836      0.144020         0.117818        0.006162   \n",
       "59       2.931163      0.196965         0.365375        0.053570   \n",
       "26       1.630506      0.032967         0.219804        0.004516   \n",
       "25       0.760289      0.059447         0.113723        0.003358   \n",
       "3        3.427636      0.182012         0.424194        0.046266   \n",
       "11       3.383834      0.114062         0.403568        0.039721   \n",
       "7        3.420518      0.157789         0.369409        0.049093   \n",
       "0        0.307213      0.058601         0.120908        0.006523   \n",
       "48       0.330619      0.045710         0.120618        0.011401   \n",
       "40       0.345795      0.021121         0.116454        0.007662   \n",
       "52       0.333443      0.041178         0.112006        0.002474   \n",
       "8        0.316342      0.066350         0.115768        0.003759   \n",
       "36       0.364195      0.019233         0.111839        0.003897   \n",
       "35       3.282221      0.217373         0.348269        0.046599   \n",
       "4        0.384605      0.024795         0.112210        0.003046   \n",
       "56       0.339998      0.036245         0.116278        0.011113   \n",
       "31       3.222482      0.163649         0.329650        0.018338   \n",
       "27       3.296956      0.118759         0.326806        0.006103   \n",
       "44       0.381794      0.031176         0.110293        0.003086   \n",
       "28       0.387689      0.028463         0.112473        0.004952   \n",
       "24       0.372421      0.027002         0.110758        0.002021   \n",
       "32       0.345616      0.011030         0.108713        0.002392   \n",
       "15       2.893884      0.026817         0.325571        0.006726   \n",
       "14       1.725700      0.068022         0.214568        0.002156   \n",
       "18       1.582336      0.094111         0.212670        0.002440   \n",
       "13       0.896039      0.169896         0.116147        0.006662   \n",
       "12       0.366322      0.038367         0.116869        0.009497   \n",
       "19       2.898328      0.106707         0.333303        0.012431   \n",
       "20       0.329345      0.032519         0.113511        0.005675   \n",
       "21       0.768822      0.047774         0.130290        0.017013   \n",
       "22       1.630777      0.071952         0.229264        0.011186   \n",
       "23       2.999717      0.072272         0.325492        0.006564   \n",
       "16       0.345670      0.017620         0.109918        0.003592   \n",
       "17       0.785370      0.094897         0.110863        0.003415   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  \\\n",
       "49             100               auto                200   \n",
       "37              50               auto                200   \n",
       "38              50               auto                500   \n",
       "41              50               sqrt                200   \n",
       "42              50               sqrt                500   \n",
       "45              50               log2                200   \n",
       "46              50               log2                500   \n",
       "50             100               auto                500   \n",
       "10            None               log2                500   \n",
       "58             100               log2                500   \n",
       "53             100               sqrt                200   \n",
       "54             100               sqrt                500   \n",
       "1             None               auto                200   \n",
       "6             None               sqrt                500   \n",
       "5             None               sqrt                200   \n",
       "2             None               auto                500   \n",
       "9             None               log2                200   \n",
       "57             100               log2                200   \n",
       "33              10               log2                200   \n",
       "34              10               log2                500   \n",
       "55             100               sqrt               1000   \n",
       "43              50               sqrt               1000   \n",
       "47              50               log2               1000   \n",
       "30              10               sqrt                500   \n",
       "51             100               auto               1000   \n",
       "39              50               auto               1000   \n",
       "29              10               sqrt                200   \n",
       "59             100               log2               1000   \n",
       "26              10               auto                500   \n",
       "25              10               auto                200   \n",
       "3             None               auto               1000   \n",
       "11            None               log2               1000   \n",
       "7             None               sqrt               1000   \n",
       "0             None               auto                100   \n",
       "48             100               auto                100   \n",
       "40              50               sqrt                100   \n",
       "52             100               sqrt                100   \n",
       "8             None               log2                100   \n",
       "36              50               auto                100   \n",
       "35              10               log2               1000   \n",
       "4             None               sqrt                100   \n",
       "56             100               log2                100   \n",
       "31              10               sqrt               1000   \n",
       "27              10               auto               1000   \n",
       "44              50               log2                100   \n",
       "28              10               sqrt                100   \n",
       "24              10               auto                100   \n",
       "32              10               log2                100   \n",
       "15               1               auto               1000   \n",
       "14               1               auto                500   \n",
       "18               1               sqrt                500   \n",
       "13               1               auto                200   \n",
       "12               1               auto                100   \n",
       "19               1               sqrt               1000   \n",
       "20               1               log2                100   \n",
       "21               1               log2                200   \n",
       "22               1               log2                500   \n",
       "23               1               log2               1000   \n",
       "16               1               sqrt                100   \n",
       "17               1               sqrt                200   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "49  {'max_depth': 100, 'max_features': 'auto', 'n_...           0.811321   \n",
       "37  {'max_depth': 50, 'max_features': 'auto', 'n_e...           0.811321   \n",
       "38  {'max_depth': 50, 'max_features': 'auto', 'n_e...           0.811321   \n",
       "41  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...           0.811321   \n",
       "42  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...           0.811321   \n",
       "45  {'max_depth': 50, 'max_features': 'log2', 'n_e...           0.811321   \n",
       "46  {'max_depth': 50, 'max_features': 'log2', 'n_e...           0.811321   \n",
       "50  {'max_depth': 100, 'max_features': 'auto', 'n_...           0.811321   \n",
       "10  {'max_depth': None, 'max_features': 'log2', 'n...           0.811321   \n",
       "58  {'max_depth': 100, 'max_features': 'log2', 'n_...           0.811321   \n",
       "53  {'max_depth': 100, 'max_features': 'sqrt', 'n_...           0.811321   \n",
       "54  {'max_depth': 100, 'max_features': 'sqrt', 'n_...           0.811321   \n",
       "1   {'max_depth': None, 'max_features': 'auto', 'n...           0.811321   \n",
       "6   {'max_depth': None, 'max_features': 'sqrt', 'n...           0.811321   \n",
       "5   {'max_depth': None, 'max_features': 'sqrt', 'n...           0.811321   \n",
       "2   {'max_depth': None, 'max_features': 'auto', 'n...           0.811321   \n",
       "9   {'max_depth': None, 'max_features': 'log2', 'n...           0.811321   \n",
       "57  {'max_depth': 100, 'max_features': 'log2', 'n_...           0.811321   \n",
       "33  {'max_depth': 10, 'max_features': 'log2', 'n_e...           0.792453   \n",
       "34  {'max_depth': 10, 'max_features': 'log2', 'n_e...           0.792453   \n",
       "55  {'max_depth': 100, 'max_features': 'sqrt', 'n_...           0.811321   \n",
       "43  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...           0.811321   \n",
       "47  {'max_depth': 50, 'max_features': 'log2', 'n_e...           0.811321   \n",
       "30  {'max_depth': 10, 'max_features': 'sqrt', 'n_e...           0.792453   \n",
       "51  {'max_depth': 100, 'max_features': 'auto', 'n_...           0.811321   \n",
       "39  {'max_depth': 50, 'max_features': 'auto', 'n_e...           0.811321   \n",
       "29  {'max_depth': 10, 'max_features': 'sqrt', 'n_e...           0.792453   \n",
       "59  {'max_depth': 100, 'max_features': 'log2', 'n_...           0.811321   \n",
       "26  {'max_depth': 10, 'max_features': 'auto', 'n_e...           0.792453   \n",
       "25  {'max_depth': 10, 'max_features': 'auto', 'n_e...           0.792453   \n",
       "3   {'max_depth': None, 'max_features': 'auto', 'n...           0.811321   \n",
       "11  {'max_depth': None, 'max_features': 'log2', 'n...           0.811321   \n",
       "7   {'max_depth': None, 'max_features': 'sqrt', 'n...           0.811321   \n",
       "0   {'max_depth': None, 'max_features': 'auto', 'n...           0.773585   \n",
       "48  {'max_depth': 100, 'max_features': 'auto', 'n_...           0.773585   \n",
       "40  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...           0.773585   \n",
       "52  {'max_depth': 100, 'max_features': 'sqrt', 'n_...           0.773585   \n",
       "8   {'max_depth': None, 'max_features': 'log2', 'n...           0.773585   \n",
       "36  {'max_depth': 50, 'max_features': 'auto', 'n_e...           0.773585   \n",
       "35  {'max_depth': 10, 'max_features': 'log2', 'n_e...           0.811321   \n",
       "4   {'max_depth': None, 'max_features': 'sqrt', 'n...           0.773585   \n",
       "56  {'max_depth': 100, 'max_features': 'log2', 'n_...           0.773585   \n",
       "31  {'max_depth': 10, 'max_features': 'sqrt', 'n_e...           0.811321   \n",
       "27  {'max_depth': 10, 'max_features': 'auto', 'n_e...           0.811321   \n",
       "44  {'max_depth': 50, 'max_features': 'log2', 'n_e...           0.773585   \n",
       "28  {'max_depth': 10, 'max_features': 'sqrt', 'n_e...           0.792453   \n",
       "24  {'max_depth': 10, 'max_features': 'auto', 'n_e...           0.792453   \n",
       "32  {'max_depth': 10, 'max_features': 'log2', 'n_e...           0.792453   \n",
       "15  {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.792453   \n",
       "14  {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.792453   \n",
       "18  {'max_depth': 1, 'max_features': 'sqrt', 'n_es...           0.792453   \n",
       "13  {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.792453   \n",
       "12  {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.792453   \n",
       "19  {'max_depth': 1, 'max_features': 'sqrt', 'n_es...           0.792453   \n",
       "20  {'max_depth': 1, 'max_features': 'log2', 'n_es...           0.792453   \n",
       "21  {'max_depth': 1, 'max_features': 'log2', 'n_es...           0.792453   \n",
       "22  {'max_depth': 1, 'max_features': 'log2', 'n_es...           0.792453   \n",
       "23  {'max_depth': 1, 'max_features': 'log2', 'n_es...           0.792453   \n",
       "16  {'max_depth': 1, 'max_features': 'sqrt', 'n_es...           0.792453   \n",
       "17  {'max_depth': 1, 'max_features': 'sqrt', 'n_es...           0.792453   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "49           0.849057           0.905660           0.754717   \n",
       "37           0.849057           0.905660           0.754717   \n",
       "38           0.867925           0.905660           0.754717   \n",
       "41           0.849057           0.905660           0.754717   \n",
       "42           0.867925           0.905660           0.754717   \n",
       "45           0.849057           0.905660           0.754717   \n",
       "46           0.867925           0.905660           0.754717   \n",
       "50           0.867925           0.905660           0.754717   \n",
       "10           0.867925           0.905660           0.754717   \n",
       "58           0.867925           0.905660           0.754717   \n",
       "53           0.849057           0.905660           0.754717   \n",
       "54           0.867925           0.905660           0.754717   \n",
       "1            0.849057           0.905660           0.754717   \n",
       "6            0.867925           0.905660           0.754717   \n",
       "5            0.849057           0.905660           0.754717   \n",
       "2            0.867925           0.905660           0.754717   \n",
       "9            0.849057           0.905660           0.754717   \n",
       "57           0.849057           0.905660           0.754717   \n",
       "33           0.886792           0.886792           0.735849   \n",
       "34           0.886792           0.886792           0.735849   \n",
       "55           0.867925           0.886792           0.754717   \n",
       "43           0.867925           0.886792           0.754717   \n",
       "47           0.867925           0.886792           0.754717   \n",
       "30           0.886792           0.886792           0.735849   \n",
       "51           0.867925           0.886792           0.754717   \n",
       "39           0.867925           0.886792           0.754717   \n",
       "29           0.886792           0.886792           0.735849   \n",
       "59           0.867925           0.886792           0.754717   \n",
       "26           0.886792           0.886792           0.735849   \n",
       "25           0.886792           0.886792           0.735849   \n",
       "3            0.867925           0.886792           0.754717   \n",
       "11           0.867925           0.886792           0.754717   \n",
       "7            0.867925           0.886792           0.754717   \n",
       "0            0.867925           0.905660           0.735849   \n",
       "48           0.867925           0.905660           0.735849   \n",
       "40           0.867925           0.905660           0.735849   \n",
       "52           0.867925           0.905660           0.735849   \n",
       "8            0.867925           0.905660           0.735849   \n",
       "36           0.867925           0.905660           0.735849   \n",
       "35           0.867925           0.886792           0.735849   \n",
       "4            0.867925           0.905660           0.735849   \n",
       "56           0.867925           0.905660           0.735849   \n",
       "31           0.867925           0.886792           0.735849   \n",
       "27           0.867925           0.886792           0.735849   \n",
       "44           0.867925           0.905660           0.735849   \n",
       "28           0.867925           0.886792           0.735849   \n",
       "24           0.867925           0.886792           0.735849   \n",
       "32           0.867925           0.886792           0.735849   \n",
       "15           0.792453           0.792453           0.792453   \n",
       "14           0.792453           0.792453           0.792453   \n",
       "18           0.792453           0.792453           0.792453   \n",
       "13           0.792453           0.792453           0.792453   \n",
       "12           0.792453           0.792453           0.792453   \n",
       "19           0.792453           0.792453           0.792453   \n",
       "20           0.792453           0.792453           0.792453   \n",
       "21           0.792453           0.792453           0.792453   \n",
       "22           0.792453           0.792453           0.792453   \n",
       "23           0.792453           0.792453           0.792453   \n",
       "16           0.792453           0.792453           0.792453   \n",
       "17           0.792453           0.792453           0.792453   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "49           0.867925         0.837736        0.051465                1  \n",
       "37           0.867925         0.837736        0.051465                1  \n",
       "38           0.849057         0.837736        0.051465                1  \n",
       "41           0.867925         0.837736        0.051465                1  \n",
       "42           0.849057         0.837736        0.051465                1  \n",
       "45           0.867925         0.837736        0.051465                1  \n",
       "46           0.849057         0.837736        0.051465                1  \n",
       "50           0.849057         0.837736        0.051465                1  \n",
       "10           0.849057         0.837736        0.051465                1  \n",
       "58           0.849057         0.837736        0.051465                1  \n",
       "53           0.867925         0.837736        0.051465                1  \n",
       "54           0.849057         0.837736        0.051465                1  \n",
       "1            0.867925         0.837736        0.051465                1  \n",
       "6            0.849057         0.837736        0.051465                1  \n",
       "5            0.867925         0.837736        0.051465                1  \n",
       "2            0.849057         0.837736        0.051465                1  \n",
       "9            0.867925         0.837736        0.051465                1  \n",
       "57           0.867925         0.837736        0.051465                1  \n",
       "33           0.867925         0.833962        0.060141               19  \n",
       "34           0.867925         0.833962        0.060141               19  \n",
       "55           0.849057         0.833962        0.046829               19  \n",
       "43           0.849057         0.833962        0.046829               19  \n",
       "47           0.849057         0.833962        0.046829               19  \n",
       "30           0.867925         0.833962        0.060141               19  \n",
       "51           0.849057         0.833962        0.046829               19  \n",
       "39           0.849057         0.833962        0.046829               19  \n",
       "29           0.867925         0.833962        0.060141               19  \n",
       "59           0.849057         0.833962        0.046829               19  \n",
       "26           0.867925         0.833962        0.060141               19  \n",
       "25           0.867925         0.833962        0.060141               19  \n",
       "3            0.849057         0.833962        0.046829               19  \n",
       "11           0.849057         0.833962        0.046829               19  \n",
       "7            0.849057         0.833962        0.046829               19  \n",
       "0            0.867925         0.830189        0.064262               34  \n",
       "48           0.867925         0.830189        0.064262               34  \n",
       "40           0.867925         0.830189        0.064262               34  \n",
       "52           0.867925         0.830189        0.064262               34  \n",
       "8            0.867925         0.830189        0.064262               34  \n",
       "36           0.867925         0.830189        0.064262               34  \n",
       "35           0.849057         0.830189        0.053367               34  \n",
       "4            0.867925         0.830189        0.064262               34  \n",
       "56           0.867925         0.830189        0.064262               34  \n",
       "31           0.849057         0.830189        0.053367               34  \n",
       "27           0.849057         0.830189        0.053367               34  \n",
       "44           0.867925         0.830189        0.064262               34  \n",
       "28           0.849057         0.826415        0.055203               46  \n",
       "24           0.849057         0.826415        0.055203               46  \n",
       "32           0.849057         0.826415        0.055203               46  \n",
       "15           0.792453         0.792453        0.000000               49  \n",
       "14           0.792453         0.792453        0.000000               49  \n",
       "18           0.792453         0.792453        0.000000               49  \n",
       "13           0.792453         0.792453        0.000000               49  \n",
       "12           0.792453         0.792453        0.000000               49  \n",
       "19           0.792453         0.792453        0.000000               49  \n",
       "20           0.792453         0.792453        0.000000               49  \n",
       "21           0.792453         0.792453        0.000000               49  \n",
       "22           0.792453         0.792453        0.000000               49  \n",
       "23           0.792453         0.792453        0.000000               49  \n",
       "16           0.792453         0.792453        0.000000               49  \n",
       "17           0.792453         0.792453        0.000000               49  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "print(\"best params: \", cv_results.sort_values('rank_test_score')['params'][0])\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0336s.) Setting batch_size=10.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 286 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 316 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 326 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 336 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 346 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 356 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 366 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 396 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 406 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 476 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 486 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 506 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 516 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 526 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 556 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 566 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 576 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 586 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 596 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 626 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 636 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 646 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 666 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 676 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 686 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 696 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 716 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 726 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 746 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 756 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 766 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 786 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 806 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 826 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 836 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 846 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 856 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 886 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 906 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 916 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 926 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 946 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 956 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 966 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 986 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 996 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1006 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1016 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1036 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1046 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1056 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1066 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1076 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1086 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1106 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1116 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1126 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1146 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1156 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1166 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1196 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1206 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1216 tasks      | elapsed:    4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1236 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1256 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1276 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1286 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1306 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1316 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1326 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1336 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1356 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1366 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1376 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1386 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1396 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1406 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1416 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1436 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1446 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1456 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 0.5, 1, 5], 'degree': [2, 3, 7, 10],\n",
       "                         'gamma': array([4.00000000e-02, 1.39863157e-01, 4.89042570e-01, 1.70997595e+00,\n",
       "       5.97906587e+00, 2.09062758e+01, 7.31004435e+01, 2.55601471e+02,\n",
       "       8.93730718e+02, 3.12500000e+03]),\n",
       "                         'kernel': ['rbf', 'linear'], 'max_iter': [100000]},\n",
       "             pre_dispatch='2*n_jobs', refit='accuracy',\n",
       "             return_train_score=False, scoring='accuracy', verbose=20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.1, 0.5, 1, 5], \n",
    "    'kernel': ['rbf', 'linear'], \n",
    "    'degree': [2, 3, 7, 10],\n",
    "    'gamma': np.power(5, np.linspace(-2,5, 10)),\n",
    "    'max_iter': [100000]\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "cv = GridSearchCV(svc, param_grid=params, scoring='accuracy', n_jobs=-1, verbose=20, refit='accuracy', cv=5)\n",
    "cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 0.1, 'degree': 2, 'gamma': 0.04, 'kernel': 'rbf', 'max_iter': 100000}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.70998</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 1, 'degree': 10, 'gamma': 1.709975946676...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>73.1004</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 73.1004434553...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.048619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.70998</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 1.7099759466766...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>20.9063</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 20.9062757737...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.048619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5.97907</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 5.97906587250...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.841509</td>\n",
       "      <td>0.048619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>73.1004</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.1, 'degree': 7, 'gamma': 73.1004434553...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>20.9063</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.1, 'degree': 10, 'gamma': 20.906275773...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>73.1004</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.1, 'degree': 10, 'gamma': 73.100443455...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>73.1004</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 73.1004434553...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.97907</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'C': 0.1, 'degree': 10, 'gamma': 5.9790658725...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "226       0.006472      0.001552         0.000843        0.000724       1   \n",
       "92        0.013638      0.001110         0.003944        0.002598     0.5   \n",
       "166       0.007785      0.001040         0.001684        0.000586       1   \n",
       "90        0.008969      0.001088         0.002383        0.001353     0.5   \n",
       "88        0.010198      0.001829         0.002096        0.000525     0.5   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "52        0.012134      0.002148         0.002368        0.000566     0.1   \n",
       "70        0.008082      0.001803         0.003068        0.002109     0.1   \n",
       "72        0.011067      0.002669         0.002981        0.001821     0.1   \n",
       "32        0.010544      0.003878         0.003096        0.001840     0.1   \n",
       "68        0.008871      0.001243         0.002986        0.002659     0.1   \n",
       "\n",
       "    param_degree param_gamma param_kernel param_max_iter  \\\n",
       "226           10     1.70998          rbf         100000   \n",
       "92             2     73.1004          rbf         100000   \n",
       "166            2     1.70998          rbf         100000   \n",
       "90             2     20.9063          rbf         100000   \n",
       "88             2     5.97907          rbf         100000   \n",
       "..           ...         ...          ...            ...   \n",
       "52             7     73.1004          rbf         100000   \n",
       "70            10     20.9063          rbf         100000   \n",
       "72            10     73.1004          rbf         100000   \n",
       "32             3     73.1004          rbf         100000   \n",
       "68            10     5.97907          rbf         100000   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "226  {'C': 1, 'degree': 10, 'gamma': 1.709975946676...           0.792453   \n",
       "92   {'C': 0.5, 'degree': 2, 'gamma': 73.1004434553...           0.773585   \n",
       "166  {'C': 1, 'degree': 2, 'gamma': 1.7099759466766...           0.792453   \n",
       "90   {'C': 0.5, 'degree': 2, 'gamma': 20.9062757737...           0.773585   \n",
       "88   {'C': 0.5, 'degree': 2, 'gamma': 5.97906587250...           0.773585   \n",
       "..                                                 ...                ...   \n",
       "52   {'C': 0.1, 'degree': 7, 'gamma': 73.1004434553...           0.773585   \n",
       "70   {'C': 0.1, 'degree': 10, 'gamma': 20.906275773...           0.773585   \n",
       "72   {'C': 0.1, 'degree': 10, 'gamma': 73.100443455...           0.773585   \n",
       "32   {'C': 0.1, 'degree': 3, 'gamma': 73.1004434553...           0.773585   \n",
       "68   {'C': 0.1, 'degree': 10, 'gamma': 5.9790658725...           0.773585   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "226           0.867925           0.905660           0.773585   \n",
       "92            0.886792           0.886792           0.792453   \n",
       "166           0.867925           0.905660           0.773585   \n",
       "90            0.886792           0.886792           0.792453   \n",
       "88            0.886792           0.886792           0.792453   \n",
       "..                 ...                ...                ...   \n",
       "52            0.792453           0.792453           0.792453   \n",
       "70            0.792453           0.792453           0.792453   \n",
       "72            0.792453           0.792453           0.792453   \n",
       "32            0.792453           0.792453           0.792453   \n",
       "68            0.792453           0.792453           0.792453   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "226           0.867925         0.841509        0.050062                1  \n",
       "92            0.867925         0.841509        0.048619                1  \n",
       "166           0.867925         0.841509        0.050062                1  \n",
       "90            0.867925         0.841509        0.048619                1  \n",
       "88            0.867925         0.841509        0.048619                1  \n",
       "..                 ...              ...             ...              ...  \n",
       "52            0.792453         0.788679        0.007547              293  \n",
       "70            0.792453         0.788679        0.007547              293  \n",
       "72            0.792453         0.788679        0.007547              293  \n",
       "32            0.792453         0.788679        0.007547              293  \n",
       "68            0.792453         0.788679        0.007547              293  \n",
       "\n",
       "[320 rows x 18 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "print(\"best params: \", cv_results.sort_values('rank_test_score')['params'][0])\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 189 candidates, totalling 945 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 945 out of 945 | elapsed:  2.9min finished\n",
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_sta...\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'activation': ['relu'],\n",
       "                         'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07, 1.e-08,\n",
       "       1.e-09]),\n",
       "                         'hidden_layer_sizes': [(10, 1), (16, 16), (10, 10),\n",
       "                                                (8, 8), (8, 1), (1, 8),\n",
       "                                                (1, 10)],\n",
       "                         'max_iter': [10000],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'solver': ['lbfgs','sgd','adam'], \n",
    "              'activation': ['relu'],\n",
    "              'max_iter': [10000], \n",
    "              'alpha': 10.0 ** -np.arange(1, 10), \n",
    "              'hidden_layer_sizes':[(10,1),(16,16),(10,10),(8,8),(8,1),(1,8),(1,10)]}\n",
    "cv = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv = 5, verbose = 10)\n",
    "cv.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (16, 16), 'max_iter': 10000, 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>3.057564</td>\n",
       "      <td>0.364244</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.992320e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>10000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.024039</td>\n",
       "      <td>1.266820</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>5.352484e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-05, 'hidden...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.339873</td>\n",
       "      <td>0.399924</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>3.021056e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>2.489046</td>\n",
       "      <td>0.533186</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>4.741114e-06</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-08, 'hidden...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.039787</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>1.850755</td>\n",
       "      <td>0.420271</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>6.031566e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-06, 'hidden...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.039787</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.138268</td>\n",
       "      <td>0.483264</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>7.539457e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>1.933659e-03</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.674573</td>\n",
       "      <td>1.134970</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>9.772819e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(1, 8)</td>\n",
       "      <td>10000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.665472</td>\n",
       "      <td>0.715264</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>4.101908e-07</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-08, 'hidden...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>3.998997e-04</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.01, 'hidden_...</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.734848</td>\n",
       "      <td>0.066263</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "52        3.057564      0.364244         0.001197    3.992320e-04   \n",
       "98        3.024039      1.266820         0.000997    5.352484e-07   \n",
       "3         1.339873      0.399924         0.000999    3.021056e-06   \n",
       "151       2.489046      0.533186         0.000995    4.741114e-06   \n",
       "113       1.850755      0.420271         0.000997    6.031566e-07   \n",
       "..             ...           ...              ...             ...   \n",
       "64        1.138268      0.483264         0.000997    7.539457e-07   \n",
       "0         0.039308      0.005731         0.002194    1.933659e-03   \n",
       "79        1.674573      1.134970         0.001197    9.772819e-04   \n",
       "160       0.665472      0.715264         0.000997    4.101908e-07   \n",
       "33        0.020344      0.009723         0.001198    3.998997e-04   \n",
       "\n",
       "    param_activation param_alpha param_hidden_layer_sizes param_max_iter  \\\n",
       "52              relu       0.001                   (8, 8)          10000   \n",
       "98              relu       1e-05                   (8, 1)          10000   \n",
       "3               relu         0.1                 (16, 16)          10000   \n",
       "151             relu       1e-08                 (16, 16)          10000   \n",
       "113             relu       1e-06                 (10, 10)          10000   \n",
       "..               ...         ...                      ...            ...   \n",
       "64              relu      0.0001                  (10, 1)          10000   \n",
       "0               relu         0.1                  (10, 1)          10000   \n",
       "79              relu      0.0001                   (1, 8)          10000   \n",
       "160             relu       1e-08                   (8, 1)          10000   \n",
       "33              relu        0.01                   (8, 1)          10000   \n",
       "\n",
       "    param_solver                                             params  \\\n",
       "52           sgd  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "98          adam  {'activation': 'relu', 'alpha': 1e-05, 'hidden...   \n",
       "3          lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "151          sgd  {'activation': 'relu', 'alpha': 1e-08, 'hidden...   \n",
       "113         adam  {'activation': 'relu', 'alpha': 1e-06, 'hidden...   \n",
       "..           ...                                                ...   \n",
       "64           sgd  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "0          lbfgs  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "79           sgd  {'activation': 'relu', 'alpha': 0.0001, 'hidde...   \n",
       "160          sgd  {'activation': 'relu', 'alpha': 1e-08, 'hidden...   \n",
       "33         lbfgs  {'activation': 'relu', 'alpha': 0.01, 'hidden_...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "52            0.892857           0.846154           0.923077   \n",
       "98            0.892857           0.884615           0.846154   \n",
       "3             0.892857           0.884615           0.846154   \n",
       "151           0.892857           0.807692           0.923077   \n",
       "113           0.892857           0.807692           0.846154   \n",
       "..                 ...                ...                ...   \n",
       "64            0.750000           0.769231           0.769231   \n",
       "0             0.750000           0.769231           0.769231   \n",
       "79            0.750000           0.769231           0.730769   \n",
       "160           0.750000           0.769231           0.769231   \n",
       "33            0.607143           0.769231           0.769231   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "52            0.884615           0.884615         0.886364        0.024374   \n",
       "98            0.884615           0.884615         0.878788        0.016487   \n",
       "3             0.884615           0.884615         0.878788        0.016487   \n",
       "151           0.846154           0.884615         0.871212        0.039787   \n",
       "113           0.923077           0.884615         0.871212        0.039787   \n",
       "..                 ...                ...              ...             ...   \n",
       "64            0.769231           0.769231         0.765152        0.007862   \n",
       "0             0.769231           0.769231         0.765152        0.007862   \n",
       "79            0.769231           0.769231         0.757576        0.015297   \n",
       "160           0.769231           0.692308         0.750000        0.029566   \n",
       "33            0.769231           0.769231         0.734848        0.066263   \n",
       "\n",
       "     rank_test_score  \n",
       "52                 1  \n",
       "98                 2  \n",
       "3                  2  \n",
       "151                4  \n",
       "113                4  \n",
       "..               ...  \n",
       "64               173  \n",
       "0                173  \n",
       "79               187  \n",
       "160              188  \n",
       "33               189  \n",
       "\n",
       "[189 rows x 18 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "print(\"best params: \", cv_results.sort_values('rank_test_score').reset_index()['params'][2])\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (1, 10), 'max_iter': 10000, 'solver': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.637229</td>\n",
       "      <td>0.229419</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-06, 'hidden...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.856604</td>\n",
       "      <td>0.054161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.911424</td>\n",
       "      <td>0.554456</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-08, 'hidden...</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.852830</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.110193</td>\n",
       "      <td>0.206377</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.046217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.857217</td>\n",
       "      <td>0.697603</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>relu</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1e-09, 'hidden...</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.845283</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.538059</td>\n",
       "      <td>0.216539</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>10000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1, 'hidden_l...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.845283</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>1.069682</td>\n",
       "      <td>1.091389</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(8, 8)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'h...</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.758491</td>\n",
       "      <td>0.080405</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.234216</td>\n",
       "      <td>0.097450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(1, 8)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.107398</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.356208</td>\n",
       "      <td>0.287544</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'h...</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.750943</td>\n",
       "      <td>0.087202</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.107687</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>logistic</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 1e-09, 'hi...</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.750943</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.093002</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>logistic</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 1e-07, 'hi...</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.743396</td>\n",
       "      <td>0.063817</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "125       0.637229      0.229419         0.002403        0.004805   \n",
       "149       0.911424      0.554456         0.000201        0.000401   \n",
       "20        1.110193      0.206377         0.001116        0.001579   \n",
       "179       1.857217      0.697603         0.001007        0.001563   \n",
       "8         1.538059      0.216539         0.001201        0.001474   \n",
       "..             ...           ...              ...             ...   \n",
       "261       1.069682      1.091389         0.000801        0.001602   \n",
       "57        0.234216      0.097450         0.000000        0.000000   \n",
       "264       0.356208      0.287544         0.000200        0.000399   \n",
       "357       0.107687      0.039689         0.001335        0.001389   \n",
       "327       0.093002      0.034794         0.001215        0.001496   \n",
       "\n",
       "    param_activation param_alpha param_hidden_layer_sizes param_max_iter  \\\n",
       "125             relu       1e-06                  (1, 10)          10000   \n",
       "149             relu       1e-08                  (10, 1)          10000   \n",
       "20              relu         0.1                  (1, 10)          10000   \n",
       "179             relu       1e-09                   (8, 8)          10000   \n",
       "8               relu         0.1                 (10, 10)          10000   \n",
       "..               ...         ...                      ...            ...   \n",
       "261         logistic      0.0001                   (8, 8)          10000   \n",
       "57              relu       0.001                   (1, 8)          10000   \n",
       "264         logistic      0.0001                   (8, 1)          10000   \n",
       "357         logistic       1e-09                  (10, 1)          10000   \n",
       "327         logistic       1e-07                   (8, 1)          10000   \n",
       "\n",
       "    param_solver                                             params  \\\n",
       "125         adam  {'activation': 'relu', 'alpha': 1e-06, 'hidden...   \n",
       "149         adam  {'activation': 'relu', 'alpha': 1e-08, 'hidden...   \n",
       "20          adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "179         adam  {'activation': 'relu', 'alpha': 1e-09, 'hidden...   \n",
       "8           adam  {'activation': 'relu', 'alpha': 0.1, 'hidden_l...   \n",
       "..           ...                                                ...   \n",
       "261        lbfgs  {'activation': 'logistic', 'alpha': 0.0001, 'h...   \n",
       "57         lbfgs  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
       "264        lbfgs  {'activation': 'logistic', 'alpha': 0.0001, 'h...   \n",
       "357        lbfgs  {'activation': 'logistic', 'alpha': 1e-09, 'hi...   \n",
       "327        lbfgs  {'activation': 'logistic', 'alpha': 1e-07, 'hi...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "125           0.792453           0.924528           0.886792   \n",
       "149           0.811321           0.867925           0.924528   \n",
       "20            0.792453           0.886792           0.886792   \n",
       "179           0.773585           0.849057           0.924528   \n",
       "8             0.792453           0.867925           0.905660   \n",
       "..                 ...                ...                ...   \n",
       "261           0.716981           0.849057           0.849057   \n",
       "57            0.792453           0.849057           0.679245   \n",
       "264           0.679245           0.830189           0.849057   \n",
       "357           0.735849           0.811321           0.773585   \n",
       "327           0.754717           0.773585           0.754717   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "125           0.792453           0.886792         0.856604        0.054161   \n",
       "149           0.792453           0.867925         0.852830        0.046829   \n",
       "20            0.792453           0.886792         0.849057        0.046217   \n",
       "179           0.792453           0.886792         0.845283        0.056478   \n",
       "8             0.773585           0.886792         0.845283        0.052560   \n",
       "..                 ...                ...              ...             ...   \n",
       "261           0.641509           0.735849         0.758491        0.080405   \n",
       "57            0.584906           0.867925         0.754717        0.107398   \n",
       "264           0.622642           0.773585         0.750943        0.087202   \n",
       "357           0.641509           0.792453         0.750943        0.060141   \n",
       "327           0.622642           0.811321         0.743396        0.063817   \n",
       "\n",
       "     rank_test_score  \n",
       "125                1  \n",
       "149                2  \n",
       "20                 3  \n",
       "179                4  \n",
       "8                  4  \n",
       "..               ...  \n",
       "261              374  \n",
       "57               375  \n",
       "264              376  \n",
       "357              376  \n",
       "327              378  \n",
       "\n",
       "[378 rows x 18 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "print(\"best params: \", cv_results.sort_values('rank_test_score').reset_index()['params'][2])\n",
    "cv_results.sort_values('rank_test_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
